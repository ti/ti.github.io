{"date":"2017-12-02T00:00:00Z","html":"\u003cp\u003eKubernetes是一个开源系统，它可以被用于自动部署，扩展和管理容器化应用程序，提供跨主机集群的自动部署、扩展以及运行应用程序容器的平台。这篇文章洋洋洒洒地介绍了， kubenetes入门的基础组件和使用方式， 如果你之前没有上手过Kubernetes， 建议直接跳到最后，在自己本地快速搭建k8s和helm开发环境。\u003c/p\u003e\n\n\u003ch2 id=\"概念和共识一览\"\u003e概念和共识一览\u003c/h2\u003e\n\n\u003ch3 id=\"1-什么是-kubernetes\"\u003e1. 什么是 Kubernetes？\u003c/h3\u003e\n\n\u003ch4 id=\"kubernetes-所处的位置\"\u003eKubernetes 所处的位置\u003c/h4\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/k8s所在位置.jpg\" alt=\"k8s所在位置\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch4 id=\"什么是容器\"\u003e什么是容器\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003e容器是一堆孤立的进程\u003c/li\u003e\n\u003cli\u003e容器有自己的PID，User， UTS，Mount Points, Network, 文件系统。\u003c/li\u003e\n\u003cli\u003e和VM很像, 但是： 1.基于进程的隔离 2. 没有操作系统，基于宿主机系统\u003c/li\u003e\n\u003cli\u003e优势: 启动时间更小，只需要启动一个进程，甚至不需要启动OS， 加快资源利用率和可调度性\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/docker资源.png\" alt=\"Docker相关概念\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch4 id=\"什么是kubernetes\"\u003e什么是Kubernetes\u003c/h4\u003e\n\n\u003cp\u003e企业级容器编排技术\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e发布，管理，扩展集群应用\u003c/li\u003e\n\u003cli\u003e管理应用程序基础组件： 卷，网络，密钥，和其他操作系统所能提供的。\u003c/li\u003e\n\u003cli\u003e声明模型 应用程序状态保持和触发\u003c/li\u003e\n\u003cli\u003e名称：K8S，舵手\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4 id=\"kubernetes-的历史\"\u003eKubernetes 的历史\u003c/h4\u003e\n\n\u003cp\u003eGoogle的云端伸缩技术 （2014年6月宣布）\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBased on Google\u0026rsquo;s internal \u0026ldquo;Borg\u0026rdquo; project\u003c/li\u003e\n\u003cli\u003e开源且开放治理\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"2-kubernetes-工具程序集架构\"\u003e2. Kubernetes 工具程序集架构\u003c/h3\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/K8S工具程序集架构.jpg\" alt=\"k8s架构\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e从以上架构图可以看出：\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ekube-apiserver 提供统一接口\u003c/li\u003e\n\u003cli\u003ekube-scheduler  负责资源与POD匹配\u003c/li\u003e\n\u003cli\u003eKube-controller-manger 负责资源管理同步\u003c/li\u003e\n\u003cli\u003ekube-proxy 负责K8S网络配置\u003c/li\u003e\n\u003cli\u003ekubelet 管理Pod声明周期\u003c/li\u003e\n\u003cli\u003eKubectl 可以看作是基于kube-apiserver的客户端\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"3-kubernetes-组件一览\"\u003e3. Kubernetes 组件一览\u003c/h3\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/k8s组件.png\" alt=\"k8s组件\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePod 提供容器的抽象层\u003c/li\u003e\n\u003cli\u003eService 提供POD群和其他服务的交互途径。（避免动态销毁，动态IP问题）\u003c/li\u003e\n\u003cli\u003eLables 资源标识符\u003c/li\u003e\n\u003cli\u003eDeplyment 提供软件的部署生命周期\u003c/li\u003e\n\u003cli\u003eVolumes 数据持久化，生命周期可自由配置\u003c/li\u003e\n\u003cli\u003eStatefulSet （宠物）为有状态应用提供支持。（有状态的Set）\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"3-kubernetes-架构-部署流程\"\u003e3. Kubernetes 架构 - 部署流程\u003c/h3\u003e\n\n\u003cp\u003e从一行命令说起:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ekubectrl create -f deployment.yml\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003e上手详情：\u003ca href=\"https://kubernetes.io/docs/user-guide/walkthrough/\"\u003eKubernetes 101\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/k8s架构图.png\" alt=\"k8s组件\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003ekubectl 部署一个应用\u003c/li\u003e\n\u003cli\u003eAPI Server 收到一个请求后，存储到数据库（etcd）。\u003c/li\u003e\n\u003cli\u003e各种Wathers/controllers 收到资源变化，并开始一定的动作。\u003c/li\u003e\n\u003cli\u003eReplicaSet（副本集：具有一组稳定的容器组【pod】） wathers/controllers 收到一个新应用创建， 并创建一个新的 pod （容器组）\u003c/li\u003e\n\u003cli\u003eScheduler （调度器）绑定一个pod到各个子节点的kubelet （修改数据库，并不真正触发转移动作）(*)\u003c/li\u003e\n\u003cli\u003ekubelet 收到pod并部署运行在容器中。（docker）\u003c/li\u003e\n\u003cli\u003ekubeproxy 管理各个pod的网络\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"4-kubelet-架构-kubelet\"\u003e4. Kubelet 架构 - kubelet\u003c/h3\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/kubelet架构图.png\" alt=\"k8s组件\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003eKubelet 是部署在K8S子节点上的组件，从图中可以看出，Kubelet 就是创建和管理各种pod， 并与Master 交互。Kubelet 对 POD 处理方式，是现在云计算平台的关键技术之一。\u003c/p\u003e\n\n\u003cp\u003eKubelet的运行逻辑和原理，可通过以下两个特性进行总结：\u003c/p\u003e\n\n\u003ch4 id=\"kubelet-对资源的描述包括三个部分\"\u003eKubelet 对资源的描述包括三个部分：\u003c/h4\u003e\n\n\u003col\u003e\n\u003cli\u003emetadata 名字，命名空间， api version等。\u003c/li\u003e\n\u003cli\u003espec 描述配置等，例如L：pod 由哪些container 组成的。\u003c/li\u003e\n\u003cli\u003estate 资源的状态， 资源当前的状态和行为。\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"kubelet-几个共识\"\u003eKubelet 几个共识：\u003c/h4\u003e\n\n\u003col\u003e\n\u003cli\u003eKublet 跑在各个子节点\u003c/li\u003e\n\u003cli\u003eKublet 是子节点的主要 Agent\u003c/li\u003e\n\u003cli\u003eKuelet 管理各自独立的容器。\u003c/li\u003e\n\u003cli\u003eKubelet 创建和管理 pod （容器组），应用容器持久化存储。\u003c/li\u003e\n\u003cli\u003eKubelet 根据各个服务和容器的配置图送到Master\u003c/li\u003e\n\u003cli\u003eKubelet 监听端口， 命令行端口，http服务器接收pod的配置，一般情况下通过 API Server，获取 pod spec\u003c/li\u003e\n\u003cli\u003eKubelet 可以使用cAdvisor（容器监控）来监控各子节点。\u003c/li\u003e\n\u003cli\u003eKubelet 是通过 cgroups 和 linux 的 namespace 等技术来运行一个一个 pod.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"5-kubelet-架构-kube-proxy\"\u003e5. Kubelet 架构  kube-proxy\u003c/h3\u003e\n\n\u003cp\u003eKube-proxy 是实现 Service 的关键组件，kube-proxy 会在每台节点上执行，然后监听 API Server 的 Service 与 Endpoint 资源对象的改变，然后来依据变化执行 iptables 来实现网络的转发。\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/kube services.png\" alt=\"kube services\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003ekube-proxy 所在位置\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/kube-proxy.jpg\" alt=\"kube-proxy 所在位置\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch3 id=\"5-kubelet-架构-容器运行时\"\u003e5. Kubelet 架构  容器运行时\u003c/h3\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/容器运行时.png\" alt=\"容器运行时\"/\u003e\u003c/div\u003eKubenetes 支持所有继承了CNI洗衣的容器，和容器之间使用Containerd 进行通讯\u003c/p\u003e\n\n\u003ch2 id=\"kubernetes-网络\"\u003eKubernetes 网络\u003c/h2\u003e\n\n\u003ch3 id=\"1-网络基础\"\u003e1. 网络基础\u003c/h3\u003e\n\n\u003col\u003e\n\u003cli\u003e容器网络：\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cul\u003e\n\u003cli\u003e每个容器分配独立的IP\u003c/li\u003e\n\u003cli\u003e使用网络策略实现访问控制\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003col\u003e\n\u003cli\u003e负载均衡 （Service IP）\u003c/li\u003e\n\u003cli\u003e外部访问\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cul\u003e\n\u003cli\u003e外部负载均衡\u003c/li\u003e\n\u003cli\u003eIngress的反向代理\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e###2. 网络架构\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/k8s网络.png\" alt=\"k8s网络\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003epause: kubenets 基础组件，在pod启动之前，为所有的pod设置网络\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"3-container-network-interface-cni-容器网络接口\"\u003e3. Container Network Interface (CNI) (容器网络接口)\u003c/h3\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/Chart_Container-Network-Interface-Drivers.png\" alt=\"Chart_Container-Network-Interface-Drivers\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eKubenetes 使用CNI来组建容器网络\u003c/li\u003e\n\u003cli\u003e当POD销毁是，kubernetes 将调用CNI来生成网络配置。\u003c/li\u003e\n\u003cli\u003eCNI将生成虚拟网卡(NIC), 将其挂在在网络之上\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e配置示例：\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e// 位置：/etc/cni/net.d/10-bridge.conf\n{\n  \u0026quot;name\u0026quot;:\u0026quot;net\u0026quot;,\n  \u0026quot;type\u0026quot;:\u0026quot;bridge\u0026quot;,\n  \u0026quot;bridge\u0026quot;:\u0026quot;br-int\u0026quot;,\n  \u0026quot;isGateway\u0026quot;:true,\n  \u0026quot;ipMasq\u0026quot;: false,\n  \u0026quot;ipam\u0026quot;:{\n   \t\t\u0026quot;type\u0026quot;:\u0026quot;host-local\u0026quot;,\n    \t\u0026quot;subnet\u0026quot;:\u0026quot;10.96.0.64.26/26\u0026quot;\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"3-虚拟网络实现概览\"\u003e3. 虚拟网络实现概览\u003c/h3\u003e\n\n\u003cp\u003e基础：网络七层结构和应用\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/网络七层结构.gif\" alt=\"网络七层结构\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch4 id=\"calico-网络\"\u003eCalico 网络\u003c/h4\u003e\n\n\u003cp\u003eCalico 网络组件\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/calico-components.png\" alt=\"calico-components\"/\u003e\u003c/div\u003eCalico\u003c/p\u003e\n\n\u003cp\u003e网络架构图\u003c/p\u003e\n\n\u003ch4 id=\"calico-img-net-calico-png\"\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/Calico.png\" alt=\"Calico\"/\u003e\u003c/div\u003e\u003c/h4\u003e\n\n\u003cp\u003e网络流程图\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/calico_流程图.png\" alt=\"calico_流程图\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e纯粹三层转发实现\u003c/li\u003e\n\u003cli\u003e通过BGP路由\u003c/li\u003e\n\u003cli\u003e使用IPTABLES 性能较好\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.projectcalico.org/v1.6/reference/without-docker-networking/docker-container-lifecycle\"\u003edocker-container-lifecycle\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4 id=\"flannel\"\u003eFlannel\u003c/h4\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/flannel.jpg\" alt=\"flannel\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e原理（Network Overlay）：\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e数据从源容器中发出后，经由所在主机的docker0虚拟网卡转发到flannel0虚拟网卡，这是个P2P的虚拟网卡，flanneld服务监听在网卡的另外一端。（Flannel 通过Etcd服务维护了一张节点的路由表）\u003c/li\u003e\n\u003cli\u003e源主机的flanneld服务静原本的数据内容UDP封装后，根据自己的路由表投递给目的节点的flanneld服务，数据到达后被\u003cstrong\u003e解包\u003c/strong\u003e， 然后直接进入目的节点的flnnel0虚拟网卡，然后被转发到目的主机的docker0虚拟网卡。\u003c/li\u003e\n\u003cli\u003e最后就像本地容器通信以下的有docker0路由到达目标容器，这样整个数据包传递就完成了\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e特性：\u003c/p\u003e\n\n\u003cp\u003e支持跨子网的组网，不需要中间网络设备的硬件需求。\u003c/p\u003e\n\n\u003ch4 id=\"nsx-t\"\u003eNSX-t\u003c/h4\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/NSX-t.jpg\" alt=\"NSX-t\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003eNSX-t 是 VMware 提取自vSphere的一种网络转发方式, NSX-t 采用\u003cstrong\u003e二层网络转发\u003c/strong\u003e的方式。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e每个节点有自己的网络交换机。（*Open vSwitch*）\u003c/li\u003e\n\u003cli\u003eNSX-t 的CNI Plugin也会分配IP地址给container， 并且把Container 的网络接入到 vSwitch上\u003c/li\u003e\n\u003cli\u003eNSX-t有控制器，可以通过打tag的形式做各种转发\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"network-policy-网络隔离\"\u003eNetwork Policy （网络隔离）\u003c/h4\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/network-policy.jpg\" alt=\"network-policy\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNetwork Policy  属于 Resource， 可以通过API创建。\u003c/li\u003e\n\u003cli\u003e用于网络隔离， 定义不同容器之间的访问模式。\u003c/li\u003e\n\u003cli\u003e通过lable进行指定，可以允许哪些容器访问哪些容器的端口。（相当于：防火墙）\u003c/li\u003e\n\u003cli\u003e实现上使用：iptables 和 修改 open vswitch 规则\u003c/li\u003e\n\n\u003cli\u003e\u003cp\u003e1.7 以前只支持ingress流入模式， 1.8 加入 egress 控制。控制流出模式。\u003c/p\u003e\n\n\u003ch4 id=\"负载均衡-ip\"\u003e负载均衡 IP\u003c/h4\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/service-iptables.jpg\" alt=\"负载均衡转发机制\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e通过Service来实现, Service 拥有（CLUSTER-IP）\u003c/li\u003e\n\u003cli\u003eKube-proxy 检测service改变，并更新iptables\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e问题：目前使用iptables的形式，可以解决大部分问题，使用NNAT进行进行负载， kube-proxy 运行在每个节点上， 就面临两个问题：\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eiptables 使用chain的方式， 如果services 非常多， 会导致reload性能问题。\u003c/li\u003e\n\u003cli\u003e无法保证ip地址头的一致性\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4 id=\"ipvs-组件-1-9-实验性\"\u003eIPVS 组件 （1.9 实验性）\u003c/h4\u003e\n\n\u003cp\u003eProxy-mode: ipvs\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/services-ipvs.svg\" alt=\"services-ipvs\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e解决iptables的性能问题\u003c/li\u003e\n\u003cli\u003e解决iptabels无法保留源ip地址头的问题\u003c/li\u003e\n\u003cli\u003e提供多种负载均衡算法, 最少链接，和加权路由的访问\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e使用示例\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/ipvs-mode.png\" alt=\"services-ipvs\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003eipvsadm -ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -\u0026gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.111.21.136:80 rr persistent 10800\n  -\u0026gt; 192.168.23.130:80            Masq    1      0          0\n  -\u0026gt; 192.168.23.134:80            Masq    1      0          0\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"4-kube-dns-介绍\"\u003e4. Kube-dns 介绍\u003c/h3\u003e\n\n\u003cp\u003ekube-dns为Kubernetes集群提供命名服务，一般通过addon的方式部署，从v1.3版本开始，成为了一个内建的自启动服务。\u003c/p\u003e\n\n\u003cp\u003e组件:“Kubedns、DNSmasq、exechealthz”三个\u003c/p\u003e\n\n\u003cp\u003eDNSmasq: 一个小巧且方便地用于配置DNS和DHCP的工具\u003c/p\u003e\n\n\u003cp\u003eExechealthz：健康检查\u003c/p\u003e\n\n\u003cp\u003eKubedns： 接入skydns， 进行缓存，检查等。\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/kubedns.png\" alt=\"kubedns\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003ekube-dns由三个容器构成：\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ekube-dns：DNS服务的核心组件，主要由KubeDNS和SkyDNS组成\n\n\u003cul\u003e\n\u003cli\u003eKubeDNS负责监听Service和Endpoint的变化情况，并将相关的信息更新到SkyDNS中\u003c/li\u003e\n\u003cli\u003eSkyDNS负责DNS解析，监听在10053端口(tcp/udp)，同时也监听在10055端口提供metrics\u003c/li\u003e\n\u003cli\u003ekube-dns还监听了8081端口，以供健康检查使用\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003ednsmasq-nanny：负责启动dnsmasq，并在配置发生变化时重启dnsmasq\n\n\u003cul\u003e\n\u003cli\u003ednsmasq的upstream为SkyDNS，即集群内部的DNS解析由SkyDNS负责\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003esidecar：负责健康检查和提供DNS metrics（监听在10054端口）\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/kube-dns工作原理.png\" alt=\"kube-dns工作原理\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch3 id=\"4-kubenetes-外部访问\"\u003e4. Kubenetes 外部访问\u003c/h3\u003e\n\n\u003cp\u003e目前提供三种方式：\u003c/p\u003e\n\n\u003cp\u003eNodePort：将服务暴露在节点Ip地址的特定端口范围内（30000， 32767），\u003c/p\u003e\n\n\u003cp\u003eLoadbalancer： 虚拟IP映射\u003c/p\u003e\n\n\u003cp\u003eIngress Controller： 七层反向代理，使用类似nginx的方式实现\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/Kubenetes ingress.jpg\" alt=\"Kubenetes ingress\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e附： service 定义方法\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/service-net1.png\" alt=\"ClusterIP 定义方式\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/service-net2.png\" alt=\"NodePort 定义方式\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/service-net3.png\" alt=\"负载均衡定义方式\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"image-package\"\u003e\u003cimg src=\"/开发/k8s/img/net/service-net4.png\" alt=\"ExternalIps定义方式\"/\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003ch2 id=\"kubernetes开发环境快速搭建\"\u003ekubernetes开发环境快速搭建\u003c/h2\u003e\n\n\u003ch3 id=\"install-minikube\"\u003einstall minikube\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode\u003ecurl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/darwin/amd64/kubectl  \u0026amp;\u0026amp; chmod +x /bin/darwin/amd64/kubectl\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.24.1/minikube-darwin-amd64 \u0026amp;\u0026amp; chmod +x minikube \u0026amp;\u0026amp; sudo mv minikube /usr/local/bin/\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003eminikube start\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003ekubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003ekubectl proxy\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003ehttp://127.0.0.1:8081/ui/\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"install-helm-ui\"\u003einstall helm ui\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode\u003ebrew install kubernetes-helm\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003ehelm init\nhelm repo update\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eInstall with Helm:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ehelm install stable/nginx-ingress\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eMinikube/Kubeadm:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ehelm install stable/nginx-ingress --set controller.hostNetwork=true\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eInstall monocular\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ehelm repo add monocular https://kubernetes-helm.github.io/monocular\nhelm install monocular/monocular\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003ekubectl get pods --watch\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003e等待大概十分钟\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ekubectl get ingress\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cpre\u003e\u003ccode\u003e## get serviceip\ncurl $(minikube service good-mite-nginx-ingress-controller --url)\neval $(minikube docker-env)\n\u003c/code\u003e\u003c/pre\u003e\n","location":"开发/k8s/kubernetes","picture":"/开发/k8s/img/cover.jpg","tags":["k8s","容器"],"title":"Kubernetes 生态实践"}