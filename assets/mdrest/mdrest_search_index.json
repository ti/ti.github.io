[{"location":"开发/faas/faas","tags":["架构","小程序"],"text":" 写在前面：本文旨在探索Serverless落地方案，与小程序•云开发的功能已经有很大的不同。文章内容会结合各种Serverless平台特性和实际开发中遇到的问题做说明，截图可能已不是原图，仅供参考。\n 自从K8S之后，各类*aaS的架构设计层出不穷，相信后端的小伙伴已经对各种架构耳熟能详，但是如果说有一个应用，真正让“Serverless（无服务架构）”得到大范围落地，那就是“小程序•云开发”（以下简称小程序），和其他Serverless架构相比，小程序的以下特性让我产生了浓厚的兴趣。\n 对大部分个人类应用，80%以上应用逻辑无需后端编码。 依托微信强大的账号生态，“真正实现低成本的软件开发”  本文就以“小程序•云开发”为启发，对“无服务架构”功能和愿景做补充和总结，重点介绍，如何综合公司SaaS和FaaS的能力，如何实现低成本的软件迭代。\n内容概要：\n FaaS平台的用户认证和授权 数据库存储功能 文件存储功能 云函数（cloud functions） 与其他架构模式相结合快速开发应用  小程序FaaS实践概览\n1. Serverless简介 如同许多新的概念一样，Serverless目前还没有一个普遍公认的权威的定义。 最新的一个定义是这样描述的：“无服务器架构是基于互联网的系统，其中应用开发不使用常规的服务进程。 目前看来，无服务器平台实质是将公共的的服务器端技术抽象，并开放函数计算接入的伸缩平台。常见的FaaS平台提供了以下基础能力：\n 用户授权和管理 数据库存取 （JSON数据的Restful抽象封装） 文件存取 云函数（类似：Fission）  可以看到FaaS平台实质是将我们常见的业务，归纳为“用户”，“数据”，“函数”， 将常见“用户数据的增删改查”，进一步抽象和封装。\n2. 用户认证和管理 其实这一块更多的是BaaS的内容， 账户认证是“无服务平台的基础”， 以下界面是一个BaaS平台所提供的用户管理界面，包含登录，登录方法配置，和消息模板。\n用户管理\n 用户管理，查看当前平台注册的用户数量，主要特性：\n 支持管理员/用户权限配置 支持从邮箱，手机，微信，Facebook等平台注册用户（见下图）   登录方式配置\n 登录方式配置， 支持配置自己的第三方SNS平台key和secret，特点：\n 支持对每种登录方式进行打开或关闭 支持注册配额限制。 支持多种登录账号的融合。   消息模板配置\n 消息模板配置。 将账户平台所涉及的通知和验证以模版的形式提供自定义接口， 支持“多语言模板配置”， 支持短信发送提供商配置。\n 从界面上可以看到，Serviceless至少从用户管理，登录方法和模板配置三个界面对常见的账户服务进行抽象，但是作为Serviceless的基础，账户的逻辑远没有界面上展示的那样简单，这个完整的账号服务，至少包含了以下逻辑：\n OAuth Password Credentials  用户密码授权逻辑。（包含多客户端，验证码，校验频次限制等） Implicit Credentials.  implicit 授权逻辑。（无需服务器端，可以通过客户端直接获取授权token） 跨域域名配置。账户登录接口作为服务，必须指定可调用域名，否则可能造成请求伪造攻击。 管理员和普通用户配置。 在大多数业务场景下，我们需要管理员去控制统计，数据清理等逻辑。 自定义第三方登录配置。允许用户通过少量的客户端代码，生成自己的第三方登录方法。   implicit 授权方式是一种前端安全的服务器架构的授权方式，这种授权方式，允许旗下多个子域名共享一套账号体系且共用一个登录界面。\n 在某些复杂的场景下，我们需要用户服务的Oauth能力来保证用户数据的开放透明，例如：Google用户体系，他可以用于登录Youtube，Blogger，Google cloud的场景。 就目前技术层面而言，OAuth 2.0 是这方面做的最全面的一套标准。\n3. 数据库存取抽象 数据库管理界面\n 数据库管理界面，特点\n 支持自动生成 “_user” 字段 ID为UUID   数据库权限控制界面\n 数据库权限配置管理界面，特点：\n 将常见的增删改查逻辑在数据库配置层进行处理。   可以从小程序•云开放的截图上粗略看到关于无服务程序在数据层的抽象逻辑是：将云端的Restful 增删改查，抽象为任意集合，这些集合的权限则基于： 管理员，创建者，所有用户三者角色进行设计。这些角色的配置如下：\n 所有用户可读，仅创建者及管理员可写   适用场景：用户评论、用户公开信息等\n  仅创建者及管理员可读写   适用场景：用户个人设置、用户订单管理等\n  所有用户可读，仅管理员可写   适用场景：商品信息等\n  仅管理员可读写   适用场景：后台流水数据等\n 安全相关补充逻辑 当然，我们现实的使用场景中，几乎无可避免地进行关联查询和关联删除，因此，这部分逻辑抽象，可以通过上图中的索引完成，一个完成的无服务数据库逻辑如下：（大部分内容为博主脑补添加，小程序并未实现）\n 自动添加 “_user” 字段，标记用于标记用户权限控制。 允许创建外键删除逻辑。（例如：删除博客时，同时删除对应的评论和文件） 设置集合最大大小。例如：单个集合最大1kb，则用于防止客户端恶意攻击。 设置用户写入频次限制。例如：blog设置为“100条/天/用户”， 则表示：一个用户每天最多可以编写100条博客。  更加复杂的数据库关联索引\n 总结：从这些信息可以看出纯粹的客户端读写数据库是在更粗粒度对数据权限进行控制，例如：只限制单个collection大小，并不会像常见的后端服务对每个字段进行规则描述。 这样的做的好处是，将用户数据过滤放到前端，适当的后端配置，可以使得钱后端开发难度达到平衡。\n 4. 文件存取 小程序文件存取界面\n小程序文件权限管理\n从界面可以看到，文件存取的逻辑和数据操作逻辑类型，在这里不多做描述，在我们实际使用中，我们需要注意以下两点：\n 除了常见的权限管理外，还需要结合数据库存取的外键配置，防止垃圾数据的产生，例如，在当删除commit的集合时，则删除当前数据库文件操作，可以采用关联外键，或在程序中插入以下代码：  //删除评论时，同时删除所关联的文件。 db.commit.onRemove = function() { //删除一条关联数据 files.RemoveID(this.data.file_id) //删除多条关联数据 files.RemoveIDs(this.data.file_ids) }   文件进行CDN绑定，避免主站带宽被占满的情况。  安全相关补充逻辑  允许为应用设置多个bucket 配置一个用户1小时内，最多可新增多少条数据 配置独立bucket 单个文件大小  5. 云函数 微信云函数配置界面\n微信相比与其他Serverless平台的优势在于，依托于完善的微信鉴权体系，在大多数个人数据场景下，你无需创建自己的任何后端，但是不可避免一些复杂跨用户的业务或一些非数据类型的业务需要云端逻辑才能完成，因此这里简单下介绍下云函数的概念。\n云函数是FaaS平台的基础，是将我们后端常见的额服务化思维，抽象到一个个具体的函数，然后由网关配置完成相关权限，频次控制，自动伸缩等内容。 例如：微信一个简单的云函数为：\n// 云函数入口函数 exports.main = (event, context) =\u0026gt; { var user = event.userInfo.openId; console.log(event) console.log(context) return { sum: event.a + event.b } }  例如：以亚马逊的Lambad为例，云函数逻辑大致为：\n\n后端的的业务通过Event Source 进行驱动，在架构设计时，我们会尽量减少“服务”在业务中的比重。那么“服务”应该出现在什么地方呢？ 请看我下一章补充。\n 更多参考开源FaaS平台，https://fission.io\n 6. 架构补充 在普通的互联网应用中，FaaS的实质是将公用的功能模块进行抽象，让技术部门的精力集中在技术本身，例如：今日头条业务，主要职责将集中在推荐算法，迅雷下载，将主要集中在p2p技术的改进和优化，直播业务，主要业务集中在内容分发等。\n在实际生产过程中，不存在单一的结构可以完美适配所有问题，因此给出以下开发建议：\n开发建议：  对于简单的业务，例如：账本，笔记，这类业务完全可以做到0服务器的形式进行开发，如果合理设置数据索引，甚至可以无需自行开发任何fuction。这类业务的特点是，用户只对自己的数据库负责，用户无法影响其他用户数据。 对于支付，直播打赏这类安全性比较高的业务，可以通过传统的微服务的开发模式，与FaaS服务结合的鉴权类型，可以采用 access_token 用户缓存的形式。 对于： 消息推送，短信发送可通过SaaS的单体架构形式开发。然后将服务能力按照用户权限逻辑注册到现有Serverless平台的基础组建。 对于复杂的业务，不建议使用Function架构进行开发，因为架构设计，函数之间通讯等问题，传统的微服务架构更加成熟。  附: Serverless的架构范式参考 实时文件处理Serverless参考架构\n实时文件处理Serverless参考架构\nWeb应用Serverless参考架构\n物联网应用后台参考架构\n实时流处理Serverless参考架构\n","title":"从 小程序•云开发谈谈FaaS架构在互联网公司的落地设计\n"},{"location":"关于/我","text":"本博客，也是MdRest的引擎创建，你也可以将它当作mdrest示例。\n关于我 github: https://github.com/ti\n","title":"又一个程序员的一亩三分地\n"},{"location":"README","text":"采用 MdRest 引擎编写, 编辑文章到 master 分支，十分钟就会被更新一次。\n","title":"个人博客\n"},{"location":"开发/go/在Go语言中，你已经不需要任何框架","tags":["go","框架"],"text":" 经常有做Java的同事问我，说是习惯了 Java的 Spring Cloud生态， 在Go语言下，有没有这种大一统的开发框架呢，答案是肯定的。\n 得益于Go语言的简单自由， Go语言的发展初期，出现过很多我们熟悉的Web开发框架，你可能听说 mux，gin，beego等，在微服务大行其道之时，诞生了 go-micro，go-kit 等， 当然这些框架都是比较优秀的框架，也在很大程度上帮助企业快速上手Go语言开发。这些框架提供的功能主要有：\n Restful API 路由 基于HTTP/2 JOSN的RPC通讯 服务的发现和治理  但是，时至今日，在云端k8s，Service Mesh大行其道之时，Go语言的生态也发生了翻天覆地的变化，很多之前优秀的开发框架逐渐被替代，就目前看来，在Go语言开发中，已经形成了以Google为核心的开发体系，这种模式以决定性的优势让众多的早期框架甚至其他Web开发形式变得暗淡失色。\n GRPC （负责云端业务接口的开发） GrpcGateway (可以在几乎不修改业务代码的情况下，将你的Proto Service直接转换为 HTTP Restful Web API) 各种ES6的前端单页面框架负责UI渲染 Istio (负责Service Mesh的微服务相关工作)  这种开发模式，虽然其他语言也可以实现GRPC相关功能， 但是得益于整个生态都是围绕着Go语言而展开的，在go语言中，你可以做到以下几点。\n GRPC的Service直接在进程内转换为 Restful API，而无需外层代理，也不用担心 JSON-\u0026gt;PB-\u0026gt; Struct 的性能损耗，你可以像之前使用Srping Cloud 那样使用GRPC生态，如果可能，你的服务甚至不用监听任何GRPC端口，你可以像写GRPC那样去编写一套“工整的，完美的” Restful API。  代码示例：\nservice Say { rpc Hello (Request) returns (Response) { option (google.api.http) = { //将你的GRPC转换为Restful API 的URL匹配 post: \u0026quot;/v1/greeter/hello/{id}\u0026quot; body:\u0026quot;*\u0026quot; }; } }  //sayServer 业务的具体实现类 srv := \u0026amp;sayServer{} mux := grpcmux.NewServeMux() //注册到GO的HTTP MUX pb.RegisterSayServerHandlerClient(context, mux.ServeMux, srv) http.ListenAndServe(\u0026quot;:8080\u0026quot;, mux)  curl -X POST -d '{}' http://127.0.0.1:8080/v1/greeter/hello/12  值得一提的是，在这种模式下，GRPC支持将错误返回和Response解耦，错误不属于Reponse中的一个字段，错误属于独立的错误对象，你可以在通过proto文件定义自己的业务错误描述：\n例如：调用成功返回【200】：\n{ \u0026quot;name\u0026quot;:\u0026quot;Lee\u0026quot; }  调用失败则返回【400等】：\n{ \u0026quot;error\u0026quot;: \u0026quot;错误描述\u0026quot;, \u0026quot;code\u0026quot;: 2 }  Google官方也对常见的错误处理做了定义， 具体可以参考：【GRPC标准错误定义】：https://nanxi.li/#/page/%E5%BC%80%E5%8F%91/grpc/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86\n Docker Scratch 自从Docker诞生以来， Go语言就以决定性的优势作为微服务开发的主要语言，一个重要的特征就是Scratch， 这种Docker模式下，允许你的程序以极简的形式发布，不用添加任何系统动态库和依赖，你的Docker镜像就是你的程序文件。 这种模式在其他语言中虽然也可以实现，但是大部分情况下，由于历史原因，我们无法保证它能健康地运行在没有任何依赖的linux环境下， 而go语言中，Scratch 几乎成了 标准。  代码地址：https://github.com/ti/noframe/tree/master/grpcmux/_exmaple\n Istio 一种sidecar形式的服务治理方案，于Go语言架构无关，在这里不做赘述，后期会专门介绍上手教程  其他参考： 代码地址：https://github.com/ti/noframe/tree/master/grpcmux/_exmaple\nGrpcGateway： https://github.com/grpc-ecosystem/grpc-gateway\nIstio: https://istio.io/zh/\n","title":"在Go语言中，你已经不需要任何框架\n"},{"location":"开发/go/Golang优化之路——临时对象池","tags":["go","代码调优"],"text":" 带垃圾回收的语言，虽然对于刚刚上手的程序员是友好的，但是后期随着项目变得越来越巨大，维护的内存问题也会逐渐暴露出来。今天讲一种优化内存申请的方法——临时对象池。\n  写在前面 堆还是栈？ 内存碎片化 临时对象池 结论   写在前面 在高并发的情况下，如果每次请求都需要申请一块用于计算的内存，比如：\nmake([]int64, 0, len(ids))  将会是一件成本很高的事情。为了定位项目中的慢语句，我曾经采用“二分法”的方式打印慢日志，定位程序变慢的代码位置。它并不是每次都慢，而是每过几秒钟就突然变得极其慢，TPS能从2000降到200。引起这个问题就是类似于上面这条语句。\n初始化一个slice，初学者会用：\nmake([]int64, 0)  高级一些的程序员都会知道，这样第一次分配内存相当于没有分配，如果要后续append元素，会引起slice以指数形式扩充，可以参考下面的代码，追加了3个元素，slice扩容了3次。\na := make([]int64, 0) fmt.Println(cap(a), len(a)) for i := 0; i \u0026lt; 3; i++ { a = append(a, 1) fmt.Println(cap(a), len(a)) }  0 0 1 1 2 2 4 3  每一次扩容空间，都是会重新申请一块区域，把就空间里面的元素复制进来，把新的追加进来。那旧空间里面的元素怎么办？等着垃圾回收呗。\n简单的优化方式，就是给自己要用的slice提前申请好空间，类似于最开头的那行代码。\nmake([]int64, 0, len(ids))  这样做避免了slice多次扩容申请内存，但还是有问题的。\n堆还是栈？ 程序会从操作系统申请一块内存，而这块内存也会被分成堆和栈。栈可以简单得理解成一次函数调用内部申请到的内存，它们会随着函数的返回把内存还给系统。\nfunc F() { temp := make([]int, 0, 20) ... }  类似于上面代码里面的temp变量，只是内函数内部申请的临时变量，并不会作为返回值返回，它就是被编译器申请到栈里面。申请到栈内存好处：函数返回直接释放，不会引起垃圾回收，对性能没有影响。\nfunc F() []int{ a := make([]int, 0, 20) return a }  而上面这段代码，申请的代码一模一样，但是申请后作为返回值返回了，编译器会认为变量之后还会被使用，当函数返回之后并不会将其内存归还，那么它就会被申请到堆上面了。申请到堆上面的内存才会引起垃圾回收。\n那么考考大家，下面这三种情况怎么解释？\nfunc F() { a := make([]int, 0, 20) b := make([]int, 0, 20000) l := 20 c := make([]int, 0, l) }  a和b代码一样，就是申请的空间不一样大，但是它们两个的命运是截然相反的。a前面已经介绍过，会申请到栈上面，而b，由于申请的内存较大，编译器会把这种申请内存较大的变量转移到堆上面。即使是临时变量，申请过大也会在堆上面申请。\n而c，对我们而言其含义和a是一致的，但是编译器对于这种不定长度的申请方式，也会在堆上面申请，即使申请的长度很短。\n可以通过下面的命令查看变量申请的位置。详细内容可以参考我之前的文章《【译】优化Go的模式》\ngo build -gcflags='-m' . 2\u0026gt;\u0026amp;1  内存碎片化 实际项目基本都是通过c := make([]int, 0, l)来申请内存，长度都是不确定的。自然而然这些变量都会申请到堆上面了。Golang使用的垃圾回收算法是『标记——清除』。简单得说，就是程序要从操作系统申请一块比较大的内存，内存分成小块，通过链表链接。每次程序申请内存，就从链表上面遍历每一小块，找到符合的就返回其地址，没有合适的就从操作系统再申请。如果申请内存次数较多，而且申请的大小不固定，就会引起内存碎片化的问题。申请的堆内存并没有用完，但是用户申请的内存的时候却没有合适的空间提供。这样会遍历整个链表，还会继续向操作系统申请内存。这就能解释我一开始描述的问题，申请一块内存变成了慢语句。\n临时对象池 如何解决这个问题，首先想到的就是对象池。Golang在sync里面提供了对象池Pool。一般大家都叫这个为对象池，而我喜欢叫它临时对象池。因为每次垃圾回收会把池子里面不被引用的对象回收掉。\n func (p *Pool) Get() interface{}\nGet selects an arbitrary item from the Pool, removes it from the Pool, and returns it to the caller. Get may choose to ignore the pool and treat it as empty. Callers should not assume any relation between values passed to Put and the values returned by Get.\n 需要注意的是，Get方法会把返回的对象从池子里面删除。所以用完了的对象，还是得重新放回池子。\n很快，我写出了第一版对象池优化方案：\nvar idsPool = sync.Pool{ New: func() interface{} { ids := make([]int64, 0, 20000) return \u0026amp;ids }, } func NewIds() []int64 { ids := idsPool.Get().(*[]int64) *ids = (*ids)[:0] idsPool.Put(ids) return *ids }  这样的实现，是把所有slice都放到同一个池子里面了。为了应对变长的问题，都是按照一个较大的值申请的变量。虽然是一种优化，但是使用超大的slice计算，性能并没有怎么提升。\n紧接着参考了达达大神的代码sync_pool.go，又写了一版：\nvar DEFAULT_SYNC_POOL *SyncPool func NewPool() *SyncPool { DEFAULT_SYNC_POOL = NewSyncPool( 5, 30000, 2, ) return DEFAULT_SYNC_POOL } func Alloc(size int) []int64 { return DEFAULT_SYNC_POOL.Alloc(size) } func Free(mem []int64) { DEFAULT_SYNC_POOL.Free(mem) } // SyncPool is a sync.Pool base slab allocation memory pool type SyncPool struct { classes []sync.Pool classesSize []int minSize int maxSize int } func NewSyncPool(minSize, maxSize, factor int) *SyncPool { n := 0 for chunkSize := minSize; chunkSize \u0026lt;= maxSize; chunkSize *= factor { n++ } pool := \u0026amp;SyncPool{ make([]sync.Pool, n), make([]int, n), minSize, maxSize, } n = 0 for chunkSize := minSize; chunkSize \u0026lt;= maxSize; chunkSize *= factor { pool.classesSize[n] = chunkSize pool.classes[n].New = func(size int) func() interface{} { return func() interface{} { buf := make([]int64, size) return \u0026amp;buf } }(chunkSize) n++ } return pool } func (pool *SyncPool) Alloc(size int) []int64 { if size \u0026lt;= pool.maxSize { for i := 0; i \u0026lt; len(pool.classesSize); i++ { if pool.classesSize[i] \u0026gt;= size { mem := pool.classes[i].Get().(*[]int64) // return (*mem)[:size] return (*mem)[:0] } } } return make([]int64, 0, size) } func (pool *SyncPool) Free(mem []int64) { if size := cap(mem); size \u0026lt;= pool.maxSize { for i := 0; i \u0026lt; len(pool.classesSize); i++ { if pool.classesSize[i] \u0026gt;= size { pool.classes[i].Put(\u0026amp;mem) return } } } }  调用例子：\nattrFilters := cache.Alloc(len(ids)) defer cache.Free(attrFilters)  重点在Alloc方法。为了能支持变长的slice，这里申请了多个池子，其大小是从5开始，最大到30000，以2为倍数。也就是5、10、20……\nDEFAULT_SYNC_POOL = NewSyncPool( 5, 30000, 2, )   分配内存的时候，从池子里面找满足容量切最小的池子。比如申请长度是2的，就分配大小为5的那个池子。如果是11，就分配大小是20的那个池子里面的对象； 如果申请的slice很大，超过了上限30000，这种情况就不使用池子了，直接从内存申请； 当然这些参数可以根据自己实际情况调整； 和之前的做法有所区别，把对象重新放回池子是通过Free方法实现的。  结论 为了优化接口，前前后后搞了一年。结果还是不错的，TPS提升了最少30%，TP99也降低很多。\n","title":"Golang优化之路——临时对象池"},{"location":"开发/go/关于Go tools的比较有用的flags","tags":["go","代码调优"],"text":"你刚接触Go tools吗？或者你想扩展下你的知识面？这篇文章是关于Go tools的flags，这些flags每个人都应该知道。\n免责声明：这篇文件可能有一些偏见。这是我个人常用的flags集合。我周边的人很难找到这些falgs的参考文档。如果你有更好的主意，可以在Twitter上私信我。\n$ go build -x -x列出了go build触发的所有命令。\n如果你对Go的工具链、使用跨平台编译器比较好奇，或者对传入外部编译器的flags不清楚，或者怀疑链接器有bug，那么使用-x来查看所有的触发。\n$ go build -x WORK=/var/folders/00/1b8h8000h01000cxqpysvccm005d21/T/go-build600909754 mkdir -p $WORK/hello/perf/_obj/ mkdir -p $WORK/hello/perf/_obj/exe/ cd /Users/jbd/src/hello/perf /Users/jbd/go/pkg/tool/darwin_amd64/compile -o $WORK/hello/perf.a -trimpath $WORK -p main -complete -buildid bbf8e880e7dd4114f42a7f57717f9ea5cc1dd18d -D _/Users/jbd/src/hello/perf -I $WORK -pack ./perf.go cd . /Users/jbd/go/pkg/tool/darwin_amd64/link -o $WORK/hello/perf/_obj/exe/a.out -L $WORK -extld=clang -buildmode=exe -buildid=bbf8e880e7dd4114f42a7f57717f9ea5cc1dd18d $WORK/hello/perf.a mv $WORK/hello/perf/_obj/exe/a.out perf  $go build -gcflags 用来给Go编译器传入参数。go tool compile -help 列出了可以被传入编译器的所有的参数列表。\n比如，为了禁止编译器优化和内联，你可以使用下面的gcfalgs：\n$ go build -gcflags=\u0026quot;-N -l\u0026quot;  比如，为了检查代码中有哪些可以调优的选项，可以运行下面指令：\n$ go build -gcflags=\u0026quot;-m\u0026quot;  $go test -v 它提供了非正式的测试输出，打印了测试的名字、状态（通过或者失败）、耗时、测试用例的日志等。\n不带有-vflag的go test命令非常安静，我经常把-v开关打开。比如输出如下：\n$ go test -v context === RUN TestBackground --- PASS: TestBackground (0.00s) === RUN TestTODO --- PASS: TestTODO (0.00s) === RUN TestWithCancel --- PASS: TestWithCancel (0.10s) === RUN TestParentFinishesChild --- PASS: TestParentFinishesChild (0.00s) === RUN TestChildFinishesFirst --- PASS: TestChildFinishesFirst (0.00s) === RUN TestDeadline --- PASS: TestDeadline (0.16s) === RUN TestTimeout --- PASS: TestTimeout (0.16s) === RUN TestCanceledTimeout --- PASS: TestCanceledTimeout (0.10s) ... PASS ok context 2.426s  $go test -race Go竞争检测工具可以通过--race使用。go test也支持这个flag并且报告竞争。在开发阶段使用这个flag可以检测竞争。\n$go test -run 使用-runflag，你可以通过正则过滤测试用例。下面的命令会只测试test examples：\n$ go test -run=Example  $go test -coverprofile 你可以输出一个覆盖信息，如果你在测试一个包，然后使用go tool来在浏览器上实现可视化：\n$ go test -coverprofile=c.out \u0026amp;\u0026amp; go tool cover -html=c.out  上面的命令会创建一个覆盖信息，然后在浏览器上打开结果页面。可视化后的结果会类似下面的页面：\n\n$go test -exec 这是一个鲜为人知的特性，使用-exec这个flag，你可以用另外的程序和tools交互。这个flag允许你使用Go tool把一些工作代理到另外的程序。\n使用这个flag常用的需求场景是：当你需要做更多的事情，而不是仅仅执行宿主机的程序。Go的Android build，使用了-exec来推送测试二进制文件到Android设备（通过使用adb），并收集测试结果。可以作为一个参考。\n$go get -u 如果你执行go-test命令来获取一个已经在GOPATH中的包，那么go-get不好更新包到最新版本，而-u会强制tool同步这个仓库的最新的版本。\n如果你是一个library的作者，那么你可能喜欢写你的安装说明通过-uflag，比如，golint这样的方式：\n$ go get -u github.com/golang/lint/golint  $go get -d 如果你只想clone一个repo到GOPATH，跳过编译和安装过程，那么使用-d。它会下载包，然后在尝试编译和安装之前停止。\n我经常使用它，作为git clone的替代命令，使用虚假的URLs，因为它会克隆这个repo到它合适的GOPATH。比如：\n$ go get -d golang.org/x/oauth2/...  会克隆包到$GOPATH/src/golang.org/x/ouath2。给出的golang.org/x/oauth2是一个虚假的URL，go-get这个仓库是很有用的，而不是尝试知道知己的repo是什么（go.googlesource.com/oauth2）。\n$go get -t 如果你的包需要额外的包来测试，-t会允许你在go-get过程中下载它们。如果你不传入-t参数，go get会只下载非测试代码的依赖。\n$ go list -f 允许你下载Go包以一种自定义的格式。对写bash脚本非常有用。下面的命令会输出runtime包的依赖：\n$ go list -f '{{.Deps}}' runtime [runtime/internal/atomic runtime/internal/sys unsafe]  英文原文\n 写在后面：虽然我们开发过程中不想被语言层面的东西限制太多，但是一些偶尔熟悉下这些命令的确可以使我们少走一些弯路。\n ","title":"【译】关于Go tools的比较有用的flags\n"},{"location":"开发/grpc/错误处理","tags":["grpc","proto"],"text":"网址： https://github.com/googleapis/googleapis/tree/master/google/rpc\nGoogle 错误定义适用于大多数互联网公司的错误处理， Google 的错误处理简而言有如下处理：\n 如果请求返回成功，则HTTP状态码：200， 并返回请求实体 如果请求失败：则返回非200，并返回：error 表示错误内容 如果返回错误需要进一步处理，则返回：error detail 表示具体处理方式  这种方式通过很简洁的方式定义了错误处理机制， 该错误码的定义，支持GRPC错误到HTTP错误的转换逻辑， 遵循HTTP网关协议规范，常见错误如下：\n 请求中有字段不符合要求，返回 400 权限不足， 返回 403 查询数据库，空指针等内部错误 返回：500 先决条件不足，返回 412 插入数据时和之前数据有冲突，返回 409  GRPC错误码表定义 Google错误码定义方式将原本复杂递增的错误方式，抽象为16种错误内容，也就是说， 无论复杂的业务场景，错误码也是 0 ～16，这样做会大大减少我们查阅文档的频率。\n   错误码 宏 状态码 HTTP宏 描述     0 OK 200 OK 无错误   1 Canceled 408 RequestTimeout 请求取消   2 Unknown 500 InternalServerError 未知错误   3 InvalidArgument 400 BadRequest 参数错误   4 DeadlineExceeded 408 RequestTimeout 请求过期   5 NotFound 404 NotFound 资源未找到   6 AlreadyExists 409 Conflict 插入ID或其他内容已存在   7 PermissionDenied 403 Forbidden 没有权限   16 Unauthenticated 401 Unauthorized 用户未鉴权（鉴权网关保留，业务层不能使用）   8 ResourceExhausted 429 StatusTooManyRequests 资源用尽 请求过于频繁   9 FailedPrecondition 412 PreconditionFailed 先决条件失败失败   10 Aborted 409 Conflict 请求终止，事务异常导致   11 OutOfRange 400 BadRequest 请求超出总长度   12 Unimplemented 501 NotImplemented 服务不支持或未实现   13 Internal 500 InternalServerError 服务器内部错误   14 Unavailable 503 ServiceUnavailable 服务不可用 （网关保留，业务层不能使用）   15 DataLoss 500 InternalServerError 不可恢复的数据丢失或损坏    GRPC 错误码使用举例 对于简单的错误，我们直接返回下面的错误码即可：\n{ \u0026quot;error\u0026quot;: \u0026quot;参数XXX错误\u0026quot;, \u0026quot;code\u0026quot;: 3 }  但是，对于复杂的错误逻辑，例如：表单提交返回哪些字段错误，账户被锁定，返回DEBUG调试信息用于定位问题等，则需要通过详细的规范输出错误详情，就几点错误详情举例，整理如下：\n错误详情示例：\n 参数错误： 请求中有字段不符合要求     错误码 宏 状态码 宏 描述     3 InvalidArgument 400 BadRequest 参数错误    { \u0026quot;error\u0026quot;: \u0026quot;INVALID_ARGUMENT\u0026quot;, \u0026quot;code\u0026quot;: 3, \u0026quot;details\u0026quot;: [ { \u0026quot;field_violations\u0026quot;: [ { \u0026quot;field\u0026quot;: \u0026quot;name\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;姓名不为空\u0026quot; }, { \u0026quot;field\u0026quot;: \u0026quot;sex\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;性别必须为男/女\u0026quot; } ] } ] }   账户被锁定：60秒, 请于60秒后重试     错误码 宏 状态码 宏 描述     7 PermissionDenied 403 Forbidden 权限不足    { \u0026quot;error\u0026quot;: \u0026quot;PERMISSION_DENIED\u0026quot;, \u0026quot;code\u0026quot;: 7, \u0026quot;details\u0026quot;: [ { \u0026quot;retry_delay\u0026quot;: { \u0026quot;seconds\u0026quot;: 60 } } ] }   服务器内部错误，请稍后重试     错误码 宏 状态码 宏 描述     13 Internal 500 InternalServerError 服务器内部错误    { \u0026quot;error\u0026quot;: \u0026quot;INTERNAL\u0026quot;, \u0026quot;code\u0026quot;: 12, \u0026quot;details\u0026quot;: [ { \u0026quot;detail\u0026quot;: \u0026quot;data base check error\u0026quot;, \u0026quot;stack_entries\u0026quot;: [ \u0026quot;select * form user where uid = %d\u0026quot;, \u0026quot;111\u0026quot;, \u0026quot;error\u0026quot;, \u0026quot;dial 192.168.1.1 connection refused\u0026quot; ] } ] }   用户没有同意相关条款     错误码 宏 状态码 宏 描述     9 FailedPrecondition 412 PreconditionFailed 先决条件失败失败    { \u0026quot;error\u0026quot;: \u0026quot;FAILED_PRECONDITION\u0026quot;, \u0026quot;code\u0026quot;: 9, \u0026quot;details\u0026quot;: [ { \u0026quot;violations\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;TOS\u0026quot;, \u0026quot;subject\u0026quot;: \u0026quot;google.com/cloud\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;Terms of service not accepted\u0026quot; } ] } ] }   插入用户时，返回用户冲突，并返回冲突用户的ID     错误码 宏 状态码 宏 描述     6 AlreadyExists 409 Conflict 插入ID或其他内容已存在    { \u0026quot;error\u0026quot;: \u0026quot;ALREADY_EXISTS\u0026quot;, \u0026quot;code\u0026quot;: 6, \u0026quot;details\u0026quot;: [ { \u0026quot;request_id\u0026quot;: \u0026quot;uid-12312434\u0026quot;, \u0026quot;serving_data\u0026quot;: \u0026quot;{\\\u0026quot;name\\\u0026quot;:\\\u0026quot;haha\\\u0026quot;}\u0026quot; } ] }   A用户访问B用户家庭信息，如果无法访问，返回B用户的 email     错误码 宏 状态码 宏 描述     7 PermissionDenied 403 Forbidden 权限不足    { \u0026quot;error\u0026quot;: \u0026quot;PERMISSION_DENIED\u0026quot;, \u0026quot;code\u0026quot;: 7, \u0026quot;details\u0026quot;: [ { \u0026quot;resource_type\u0026quot;: \u0026quot;book\u0026quot;, \u0026quot;resource_name\u0026quot;: \u0026quot;projects/1234/books/5678\u0026quot;, \u0026quot;owner\u0026quot;: \u0026quot;user:leenanxi@gmail.com\u0026quot; }, { \u0026quot;resource_type\u0026quot;: \u0026quot;ype.googleapis.com/google.pubsub.v1.Topic\u0026quot;, \u0026quot;resource_name\u0026quot;: \u0026quot;example.com_4fghdhgsrgh@group.calendar.google.com\u0026quot;, \u0026quot;owner\u0026quot;: \u0026quot;project:gcm\u0026quot; } ] }   访问接口时，如果出现400，或401， 如有必要，给予一定的帮助提示     错误码 宏 状态码 宏 描述     16 Unauthenticated 401 Unauthorized 用户未鉴权   3 InvalidArgument 400 BadRequest 参数错误    { \u0026quot;error\u0026quot;: \u0026quot;UNAUTHENTICATED\u0026quot;, \u0026quot;code\u0026quot;: 16, \u0026quot;details\u0026quot;: [ { \u0026quot;links\u0026quot;: [ { \u0026quot;description\u0026quot;: \u0026quot;Requires authentication\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://developer.github.com/v3/orgs/#get-an-organization\u0026quot; }, { \u0026quot;description\u0026quot;: \u0026quot;Github Organization Documentation\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://developer.github.com/v3/orgs/#get-an-organization\u0026quot; } ] }, { \u0026quot;field_violations\u0026quot;: [ { \u0026quot;field\u0026quot;: \u0026quot;name\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;姓名不为空\u0026quot; }, { \u0026quot;field\u0026quot;: \u0026quot;sex\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;性别必须大于为男/女\u0026quot; } ] } ] }   国际化：对于一些简单的接口，直接在接口层对返回的错误进行国际化, 例如：账户锁定，请于60秒后重试的接口。     错误码 宏 状态码 宏 描述     7 PermissionDenied 403 Forbidden 权限不足    { \u0026quot;error\u0026quot;: \u0026quot;PERMISSION_DENIED\u0026quot;, \u0026quot;code\u0026quot;: 7, \u0026quot;details\u0026quot;: [ { \u0026quot;retry_delay\u0026quot;: { \u0026quot;seconds\u0026quot;: 60 } }, { \u0026quot;locale\u0026quot;: \u0026quot;en\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;account is locked, please retry in {retry_delay.seconds | format : 'time'} \u0026quot; }, { \u0026quot;locale\u0026quot;: \u0026quot;zh\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;账户已被锁定，请于 {retry_delay.seconds | format : 'hh'} 小时后重试\u0026quot; } ] }   模型定义地址：\ngoogle/rpc/code.proto\ngoogle/rpc/error_details.proto\ngoogle/rpc/status.proto\n ","title":"GRPC通用错误码和错误详情详解\n"},{"location":"开发/k8s/kubernetes","tags":["k8s","容器"],"text":"Kubernetes是一个开源系统，它可以被用于自动部署，扩展和管理容器化应用程序，提供跨主机集群的自动部署、扩展以及运行应用程序容器的平台。这篇文章洋洋洒洒地介绍了， kubenetes入门的基础组件和使用方式， 如果你之前没有上手过Kubernetes， 建议直接跳到最后，在自己本地快速搭建k8s和helm开发环境。\n概念和共识一览 1. 什么是 Kubernetes？ Kubernetes 所处的位置 \n什么是容器  容器是一堆孤立的进程 容器有自己的PID，User， UTS，Mount Points, Network, 文件系统。 和VM很像, 但是： 1.基于进程的隔离 2. 没有操作系统，基于宿主机系统 优势: 启动时间更小，只需要启动一个进程，甚至不需要启动OS， 加快资源利用率和可调度性  \n什么是Kubernetes 企业级容器编排技术\n 发布，管理，扩展集群应用 管理应用程序基础组件： 卷，网络，密钥，和其他操作系统所能提供的。 声明模型 应用程序状态保持和触发 名称：K8S，舵手  Kubernetes 的历史 Google的云端伸缩技术 （2014年6月宣布）\n Based on Google\u0026rsquo;s internal \u0026ldquo;Borg\u0026rdquo; project 开源且开放治理  2. Kubernetes 工具程序集架构 \n从以上架构图可以看出：\n kube-apiserver 提供统一接口 kube-scheduler 负责资源与POD匹配 Kube-controller-manger 负责资源管理同步 kube-proxy 负责K8S网络配置 kubelet 管理Pod声明周期 Kubectl 可以看作是基于kube-apiserver的客户端  3. Kubernetes 组件一览 \n Pod 提供容器的抽象层 Service 提供POD群和其他服务的交互途径。（避免动态销毁，动态IP问题） Lables 资源标识符 Deplyment 提供软件的部署生命周期 Volumes 数据持久化，生命周期可自由配置 StatefulSet （宠物）为有状态应用提供支持。（有状态的Set）  3. Kubernetes 架构 - 部署流程 从一行命令说起:\nkubectrl create -f deployment.yml  上手详情：Kubernetes 101\n\n kubectl 部署一个应用 API Server 收到一个请求后，存储到数据库（etcd）。 各种Wathers/controllers 收到资源变化，并开始一定的动作。 ReplicaSet（副本集：具有一组稳定的容器组【pod】） wathers/controllers 收到一个新应用创建， 并创建一个新的 pod （容器组） Scheduler （调度器）绑定一个pod到各个子节点的kubelet （修改数据库，并不真正触发转移动作）(*) kubelet 收到pod并部署运行在容器中。（docker） kubeproxy 管理各个pod的网络  4. Kubelet 架构 - kubelet \nKubelet 是部署在K8S子节点上的组件，从图中可以看出，Kubelet 就是创建和管理各种pod， 并与Master 交互。Kubelet 对 POD 处理方式，是现在云计算平台的关键技术之一。\nKubelet的运行逻辑和原理，可通过以下两个特性进行总结：\nKubelet 对资源的描述包括三个部分：  metadata 名字，命名空间， api version等。 spec 描述配置等，例如L：pod 由哪些container 组成的。 state 资源的状态， 资源当前的状态和行为。  Kubelet 几个共识：  Kublet 跑在各个子节点 Kublet 是子节点的主要 Agent Kuelet 管理各自独立的容器。 Kubelet 创建和管理 pod （容器组），应用容器持久化存储。 Kubelet 根据各个服务和容器的配置图送到Master Kubelet 监听端口， 命令行端口，http服务器接收pod的配置，一般情况下通过 API Server，获取 pod spec Kubelet 可以使用cAdvisor（容器监控）来监控各子节点。 Kubelet 是通过 cgroups 和 linux 的 namespace 等技术来运行一个一个 pod.  5. Kubelet 架构 kube-proxy Kube-proxy 是实现 Service 的关键组件，kube-proxy 会在每台节点上执行，然后监听 API Server 的 Service 与 Endpoint 资源对象的改变，然后来依据变化执行 iptables 来实现网络的转发。\n\nkube-proxy 所在位置\n\n5. Kubelet 架构 容器运行时 Kubenetes 支持所有继承了CNI洗衣的容器，和容器之间使用Containerd 进行通讯\nKubernetes 网络 1. 网络基础  容器网络：   每个容器分配独立的IP 使用网络策略实现访问控制   负载均衡 （Service IP） 外部访问   外部负载均衡 Ingress的反向代理  ###2. 网络架构\n\n pause: kubenets 基础组件，在pod启动之前，为所有的pod设置网络\n 3. Container Network Interface (CNI) (容器网络接口) \n Kubenetes 使用CNI来组建容器网络 当POD销毁是，kubernetes 将调用CNI来生成网络配置。 CNI将生成虚拟网卡(NIC), 将其挂在在网络之上  配置示例：\n// 位置：/etc/cni/net.d/10-bridge.conf { \u0026quot;name\u0026quot;:\u0026quot;net\u0026quot;, \u0026quot;type\u0026quot;:\u0026quot;bridge\u0026quot;, \u0026quot;bridge\u0026quot;:\u0026quot;br-int\u0026quot;, \u0026quot;isGateway\u0026quot;:true, \u0026quot;ipMasq\u0026quot;: false, \u0026quot;ipam\u0026quot;:{ \u0026quot;type\u0026quot;:\u0026quot;host-local\u0026quot;, \u0026quot;subnet\u0026quot;:\u0026quot;10.96.0.64.26/26\u0026quot; } }  3. 虚拟网络实现概览 基础：网络七层结构和应用\n\nCalico 网络 Calico 网络组件\nCalico\n网络架构图\n 网络流程图\n\n 纯粹三层转发实现 通过BGP路由 使用IPTABLES 性能较好  docker-container-lifecycle\nFlannel \n原理（Network Overlay）：\n 数据从源容器中发出后，经由所在主机的docker0虚拟网卡转发到flannel0虚拟网卡，这是个P2P的虚拟网卡，flanneld服务监听在网卡的另外一端。（Flannel 通过Etcd服务维护了一张节点的路由表） 源主机的flanneld服务静原本的数据内容UDP封装后，根据自己的路由表投递给目的节点的flanneld服务，数据到达后被解包， 然后直接进入目的节点的flnnel0虚拟网卡，然后被转发到目的主机的docker0虚拟网卡。 最后就像本地容器通信以下的有docker0路由到达目标容器，这样整个数据包传递就完成了  特性：\n支持跨子网的组网，不需要中间网络设备的硬件需求。\nNSX-t \nNSX-t 是 VMware 提取自vSphere的一种网络转发方式, NSX-t 采用二层网络转发的方式。\n 每个节点有自己的网络交换机。（*Open vSwitch*） NSX-t 的CNI Plugin也会分配IP地址给container， 并且把Container 的网络接入到 vSwitch上 NSX-t有控制器，可以通过打tag的形式做各种转发  Network Policy （网络隔离） \n Network Policy 属于 Resource， 可以通过API创建。 用于网络隔离， 定义不同容器之间的访问模式。 通过lable进行指定，可以允许哪些容器访问哪些容器的端口。（相当于：防火墙） 实现上使用：iptables 和 修改 open vswitch 规则 1.7 以前只支持ingress流入模式， 1.8 加入 egress 控制。控制流出模式。\n负载均衡 IP  \n 通过Service来实现, Service 拥有（CLUSTER-IP） Kube-proxy 检测service改变，并更新iptables  问题：目前使用iptables的形式，可以解决大部分问题，使用NNAT进行进行负载， kube-proxy 运行在每个节点上， 就面临两个问题：\n iptables 使用chain的方式， 如果services 非常多， 会导致reload性能问题。 无法保证ip地址头的一致性  IPVS 组件 （1.9 实验性） Proxy-mode: ipvs\n\n 解决iptables的性能问题 解决iptabels无法保留源ip地址头的问题 提供多种负载均衡算法, 最少链接，和加权路由的访问  使用示例\n\nipvsadm -ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.111.21.136:80 rr persistent 10800 -\u0026gt; 192.168.23.130:80 Masq 1 0 0 -\u0026gt; 192.168.23.134:80 Masq 1 0 0  4. Kube-dns 介绍 kube-dns为Kubernetes集群提供命名服务，一般通过addon的方式部署，从v1.3版本开始，成为了一个内建的自启动服务。\n组件:“Kubedns、DNSmasq、exechealthz”三个\nDNSmasq: 一个小巧且方便地用于配置DNS和DHCP的工具\nExechealthz：健康检查\nKubedns： 接入skydns， 进行缓存，检查等。\n\nkube-dns由三个容器构成：\n kube-dns：DNS服务的核心组件，主要由KubeDNS和SkyDNS组成  KubeDNS负责监听Service和Endpoint的变化情况，并将相关的信息更新到SkyDNS中 SkyDNS负责DNS解析，监听在10053端口(tcp/udp)，同时也监听在10055端口提供metrics kube-dns还监听了8081端口，以供健康检查使用  dnsmasq-nanny：负责启动dnsmasq，并在配置发生变化时重启dnsmasq  dnsmasq的upstream为SkyDNS，即集群内部的DNS解析由SkyDNS负责  sidecar：负责健康检查和提供DNS metrics（监听在10054端口）  \n4. Kubenetes 外部访问 目前提供三种方式：\nNodePort：将服务暴露在节点Ip地址的特定端口范围内（30000， 32767），\nLoadbalancer： 虚拟IP映射\nIngress Controller： 七层反向代理，使用类似nginx的方式实现\n\n附： service 定义方法\n\n\n\n\nkubernetes开发环境快速搭建 install minikube curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/darwin/amd64/kubectl \u0026amp;\u0026amp; chmod +x /bin/darwin/amd64/kubectl curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.24.1/minikube-darwin-amd64 \u0026amp;\u0026amp; chmod +x minikube \u0026amp;\u0026amp; sudo mv minikube /usr/local/bin/  minikube start  kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml  kubectl proxy  http://127.0.0.1:8081/ui/  install helm ui brew install kubernetes-helm  helm init helm repo update  Install with Helm:\nhelm install stable/nginx-ingress  Minikube/Kubeadm:\nhelm install stable/nginx-ingress --set controller.hostNetwork=true  Install monocular\nhelm repo add monocular https://kubernetes-helm.github.io/monocular helm install monocular/monocular  kubectl get pods --watch  等待大概十分钟\nkubectl get ingress  ## get serviceip curl $(minikube service good-mite-nginx-ingress-controller --url) eval $(minikube docker-env)  ","title":"Kubernetes 生态实践\n"},{"location":"项目/mdb","tags":["mongodb","mgo","go"],"text":"Golang 一直缺失官方的Mongodb库， 对于Go开发者，普遍采用mgo库作为go语言的mongodb驱动库，如果你使用过，你可能在每次查询数据库时习惯了以下的用法：\ncopy := session.Clone; defter copy.Close(); copy.DB(\u0026quot;dbname).C(\u0026quot;col\u0026quot;).Find(...)  这样的用法虽然丑陋，但是它解决了我们使用mongodb最大的坑，“当MongoDB断开后，mongodb无法重连\u0026rdquo; 的问题， 但是这样的用法也会造成一些问题：\n 每次查询mongodb库，都会克隆一个新的session，并刷新，造成资源浪费。 当你的程序在高并发时，你会发现你的mongodb链接达到了 上百和上千个。 高并发时，大概会有30%的请求率，会返回 \u0026ldquo;Closed explicitly\u0026rdquo; 或者 \u0026ldquo;EOF\u0026rdquo;  为了解决这个问题，我重新封装了mgo库，叫做mdb，自带重连机制，使用方法也和普通的SQL库有几分相似\n//初始化db对象，db_for_connect 一般为admin， db 为默认数据库名 db, err := mdb.Dial(\u0026quot;mongodb://username:password@127.0.0.1:27017/db_for_connect?db=test\u0026quot;) //向db的people 表添加数据 db.C(\u0026quot;people\u0026quot;).Insert(\u0026amp;Person{\u0026quot;Ale\u0026quot;, \u0026quot;+55 53 8116 9639\u0026quot;})  这样操作会有以下优点：\n 简化monogdb操作的代码量。在业务层，你只需db.C(\u0026quot;people\u0026quot;).Insert(...)，来进行数据操作。 减少长连数量，并提高稳定性。一般情况下，你和mongodb只有一个长连，随着业务量的增加可能会增加2个，3个或更多，这些长连会自我维护和释放。  github地址: https://github.com/ti/mdb\n详情如下：\nmdb A rich mongodb driver based on mgo and auto refresh when \u0026ldquo;Closed explicitly\u0026rdquo; or \u0026ldquo;EOF\u0026rdquo;\nfeature  do not need copy := session.Clone; defter copy.Close(); use db instance in project less tcp connections auto refresh connections when connection is break more simple  why this one if you use copy := session.Clone; defter copy.Close(); copy.DB(\u0026quot;dbname).C(\u0026quot;col\u0026quot;).Find(...)\nyou may got \u0026ldquo;Closed explicitly\u0026rdquo; or \u0026ldquo;EOF\u0026rdquo; when in high concurrency\nquick start type Person struct { Name string Phone string } func main() { //the test is default db db, err := mdb.Dial(\u0026quot;mongodb://127.0.0.1:27017/test\u0026quot;) if err != nil { panic(err) } defer db.Close() c := db.C(\u0026quot;people\u0026quot;) err = c.Insert(\u0026amp;Person{\u0026quot;Ale\u0026quot;, \u0026quot;+55 53 8116 9639\u0026quot;},\u0026amp;Person{\u0026quot;Cla\u0026quot;, \u0026quot;+55 53 8402 8510\u0026quot;}) if err != nil { log.Fatal(err) } result := Person{} err = c.Find(bson.M{\u0026quot;name\u0026quot;: \u0026quot;Ale\u0026quot;}).One(\u0026amp;result) if err != nil { log.Fatal(err) } fmt.Println(\u0026quot;Phone:\u0026quot;, result.Phone) }  when mongo connection string and database name is different? use mongo-connection-string + \u0026amp;db={db_name} use to config your db name\nexample:\ndb, err := mdb.Dial(\u0026quot;mongodb://username:password@192.168.31.5:27017?db=test\u0026quot;)  when username is not an administrator\ndb, err := mdb.Dial(\u0026quot;mongodb://username:password@127.0.0.1:27017/test\u0026quot;) //when you have to connect another db first db, err := mdb.Dial(\u0026quot;mongodb://username:password@127.0.0.1:27017/db_for_connect?db=test\u0026quot;)  new connection string parameter maxRetries : max retries time when network is error, default is 2\ndb : database name when your connection string and database name is different\nFULL Example:\ndb, err := mdb.Dial(\u0026quot;mongodb://username:password@127.0.0.1:27017?db=test\u0026amp;maxRetries=2\u0026quot;)  ","title":"mdb,一个以db为单位，带重连机制的mgo封装\n"},{"location":"开发/IoT/coap/COAP 应用详解","tags":["MQ"],"text":"CoAP是一种应用层协议，它运行于UDP协议之上而不是像HTTP那样运行于TCP之上。\nCOAP 相当于 HTTP Restful 就比如， arm 相当于 x86\nCOAP 应用层解释 coap请求代码示例\ncoapClient, err := coap.Dial(\u0026quot;myhourse.local:5683\u0026quot;) req := coap.Message{ Type: coap.Confirmable, Code: coap.POST, MessageID: 12345, Payload: cbor.MustMarshal(People { Name :\u0026quot;张三丰\u0026quot;, }), } req.SetOption(coap.ContentFormat, coap.AppCBOR) req.SetPathString(\u0026quot;/lock/3/users\u0026quot;) rv, err := coapClient.Send(req)  coap://myhourse.local/lock/3/users  GET POST PUT DELETE\n简介  CoAP协议基于REST 构架，REST 是指表述性状态转换架构，是互联网资源访问协议的一般性设计风格。为了克服HTTP对于受限环境的劣势，CoAP既考虑到数据报长度的最优化，又考虑到提供可靠通信。一方面，CoAP提供URI，REST 式的方法如GET，POST，PUT和DELETE，以及可以独立定义的头选项提供的可扩展性。另一方面，CoAP基于轻量级的UDP协议，并且允许IP多播。而组通信是物联网最重要的需求之一，比如说用于自动化应用中。为了弥补UDP传输的不可靠性，CoAP定义了带有重传机制的事务处理机制。并且提供资源发现机制，并带有资源描述。\n CoAP的特点\n CoAP采用了二进制报头，而不是文本报头(text header)。\n CoAP降低了头的可用选项的数量。\n CoAP减少了一些HTTP的方法。\n CoAP可以支持检测装置。\n  CoAP与Http协议\nCoAP协议采用了双层的结构。事务层(Transaction layer)处理节点间的信息交换，同时，也提供对多播和拥塞控制的支持。请求/响应层(Request/Response layer)用以传输对资源进行操作的请求和相应信息。CoAP协议的REST 构架基于该层的通信，REST请求附在一个CON 或者NON消息上，而REST响应附在匹配的ACK消息上。\n\n CoAP的双层处理方式，使得CoAP没有采用TCP协议，也可以提供可靠的传输机制。利用默认的定时器和指数增长的重传间隔时间实现 CON消息的重传，直到接收方发出确认消息。另外，CoAP的双层处理方式支持异步通信，这是物联网和M2M应用的关键需求之一。\n 报文详情 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Ver| T | TKL | Code | Message ID | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Token (if any, TKL bytes) ... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options (if any) ... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |1 1 1 1 1 1 1 1| Payload (if any) ... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-  Type  Confirmable COAPType = 0 //需要响应，确认 NonConfirmable COAPType = 1 Acknowledgement COAPType = 2 //确认 Reset COAPCode COAPType = 3  请求类型 Confirmable NonConfirmable 0 Confirmable：需要被确认的请求，如果CON请求被发送，那么对方必须做出响应。 （用于同步请求，控制指令等）\n1 NonConfirmable：不需要被确认的请求，如果NON请求被发送，那么对方不必做出回应。（用于属性上报，日志记录等）\n响应类型 Acknowledgement Reset 2 Acknowledgement：应答消息，接受到Confirmable消息的响应。(ACK)\n3 Reset 消息代表的是一个消息（需要应答或者不需要应答的消息）被收到了，但是由于缺少某些上下文信息而无法被正常的处理。这种情况通常是由于接收节点重启了，因而缺失了一些必要的信息，导致当前接收到的消息无法被处理。利用reset消息，也是一种低开销的检查端是否存活的方式（也称作CoAP ping，发送一个空的需应答消息）类似于http响应的：Provisional headers are shown\nCode 请求方法码（Method Code） 类似于 HTTP的请求 METHOD，用于消息请求\n GET COAPCode = 1 POST COAPCode = 2 PUT COAPCode = 3 DELETE COAPCode = 4  响应码（Response Code） 用于消息等响应，类似于HTTP的200，400，404, 401 等\n\t// 2.x CoapCodeCreated CoapCode = 65 // 2.01 CoapCodeDeleted CoapCode = 66 // 2.02 CoapCodeValid CoapCode = 67 // 2.03 CoapCodeChanged CoapCode = 68 // 2.04 CoapCodeContent CoapCode = 69 // 2.05 CoapCodeContinue CoapCode = 95 // 2.31 // 4.x CoapCodeBadRequest CoapCode = 128 // 4.00 CoapCodeUnauthorized CoapCode = 129 // 4.01 CoapCodeBadOption CoapCode = 130 // 4.02 CoapCodeForbidden CoapCode = 131 // 4.03 CoapCodeNotFound CoapCode = 132 // 4.04 CoapCodeMethodNotAllowed CoapCode = 133 // 4.05 CoapCodeNotAcceptable CoapCode = 134 // 4.06 CoapCodeRequestEntityIncomplete CoapCode = 136 // 4.08 CoapCodeConflict CoapCode = 137 // 4.09 CoapCodePreconditionFailed CoapCode = 140 // 4.12 CoapCodeRequestEntityTooLarge CoapCode = 141 // 4.13 CoapCodeUnsupportedContentFormat CoapCode = 143 // 4.15 // 5.x CoapCodeInternalServerError CoapCode = 160 // 5.00 CoapCodeNotImplemented CoapCode = 161 // 5.01 CoapCodeBadGateway CoapCode = 162 // 5.02 CoapCodeServiceUnavailable CoapCode = 163 // 5.03 CoapCodeGatewayTimeout CoapCode = 164 // 5.04 CoapCodeProxyingNotSupported CoapCode = 165 // 5.05  Token 令牌（token） token是用于匹配响应与请求的。token的值有0~8字节（注意，每个信息都携带token，即使其长度为零）。每个请求都携带由客户端生成的token，服务端在响应时必须复制（不能修改）这个token。\ntoken用作client-local标示，用于区分并发请求，也称为“request ID”。\nOptions  +-----+---+---+---+---+----------------+--------+--------+----------+ | No. | C | U | N | R | Name | Format | Length | Default | +-----+---+---+---+---+----------------+--------+--------+----------+ | 1 | x | | | x | If-Match | opaque | 0-8 | (none) | | 3 | x | x | - | | Uri-Host | string | 1-255 | (see | | | | | | | | | | below) | | 4 | | | | x | ETag | opaque | 1-8 | (none) | | 5 | x | | | | If-None-Match | empty | 0 | (none) | | 7 | x | x | - | | Uri-Port | uint | 0-2 | (see | | | | | | | | | | below) | | 8 | | | | x | Location-Path | string | 0-255 | (none) | | 11 | x | x | - | x | Uri-Path | string | 0-255 | (none) | | 12 | | | | | Content-Format | uint | 0-2 | (none) | | 14 | | x | - | | Max-Age | uint | 0-4 | 60 | | 15 | x | x | - | x | Uri-Query | string | 0-255 | (none) | | 17 | x | | | | Accept | uint | 0-2 | (none) | | 20 | | | | x | Location-Query | string | 0-255 | (none) | | 35 | x | x | - | | Proxy-Uri | string | 1-1034 | (none) | | 39 | x | x | - | | Proxy-Scheme | string | 1-255 | (none) | | 60 | | | x | | Size1 | uint | 0-4 | (none) | +-----+---+---+---+---+----------------+--------+--------+----------+  \tIfMatch OptionID = 1 URIHost OptionID = 3 ETag OptionID = 4 IfNoneMatch OptionID = 5 Observe OptionID = 6 URIPort OptionID = 7 LocationPath OptionID = 8 URIPath OptionID = 11 ContentFormat OptionID = 12 MaxAge OptionID = 14 URIQuery OptionID = 15 Accept OptionID = 17 LocationQuery OptionID = 20 ProxyURI OptionID = 35 ProxyScheme OptionID = 39 Size1 OptionID = 60  保留定义：\n +-------------+---------------------------------------+ | Range | Registration Procedures | +-------------+---------------------------------------+ | 0-255 | IETF Review or IESG Approval | | 256-2047 | Specification Required | | 2048-64999 | Expert Review | | 65000-65535 | Experimental use (no operational use) | +-------------+---------------------------------------+  添加Token验证请求， 可用于鉴权 (ietf草稿文档)\n +-----+---+---+---+---+----------------------+--------+--------+------------------ ----+ | No. | C | U | N | R | Name | Format | Length | Default | +-----+---+---+---+---+----------------------+--------+--------+-----------------------+ | 64 | | | | | Authorization | opaque | 1-1034 | (none) | | 65 | x | | | | Authorization-Format | uint | 0-2 | application/cose+cbor | +-----+---+---+---+---+--------------- ------+--------+--------+-----------------------+  application/cose+cbor 可以理解为二进制的json编码格式，比Json更小，但是大部分情况下， Authorization-Format这个值可以写0，即 text/plain;charset=utf-8 格式。\nUri-Host, Uri-Port, Uri-Path, and Uri-Query 例如接口如下：\nGET coap://dc.spotmau.cn:5683/lock/v3/home/2435/users?name=张三丰  查询HOME ID 是 2435 的家庭中，姓名为张三丰的用户的详情。\n对应的参数为:\nUri-Host: dc.spotmau.cn Uri-Port: 5683 Uri-Path: lock/v3/users/dn6426523 Uri-Query: name=张三丰\nIf-Match 字面意思：如果目标数据的ETag和 if-match数值相同，则做某事。用于保护多个客户端在同一资源下进行类似操作时意外覆盖（比如“lost update”问题）。\n例如：多个客户端同时请求修改门锁数据时，添加 if-match aaaaa, 则表示，只有门锁数据的etag为aaaaa的时候才修改，否则忽略。\nETag 资源唯一标识符，用户检测变化。md5, time 等混合。（一般服务器端使用）\nIf-None-Match 字面意思：如果目标数据不存在时，则做某事。否则忽略。\nObserve 用于消息订阅/发布模式，详见：观察者机制代码实现\nLocation-Path和 Location-Query Location-Path和Location-Query选项定义由一个绝对路径、一个请求字符串，或者二者一起组成的相对URI。\nContent-Format \tTextPlain MediaType = 0 // text/plain;charset=utf-8 AppLinkFormat MediaType = 40 // application/link-format AppXML MediaType = 41 // application/xml AppOctets MediaType = 42 // application/octet-stream AppExi MediaType = 47 // application/exi AppJSON MediaType = 50 // application/json AppCBOR MediaType = 60 // application/json  Max-Age Max-Age 定义最大缓存实践， 最多能缓存的时间， 一般为GET到的内容的有效期。\n该选项的值是一个整型的秒数，从0到2**32-1（大约136.1年）。如响应中没有定义这个选项，它的默认值是60秒。\nAccept 类似于 http的Accept，客户端接受服务端返回它指定的格式。如果服务端无法提供客户端指定的格式，服务端必须返回一个4.06“Not Acceptable”，\nProxy-Uri和Proxy-Scheme 和 http的 类似\nSize1 用于限制请求字节数， 如果一个请求返回413 （Request Entity Too Large）， 则该请求所有响应会包含Size1字段。\nCOAP 订阅机制代码实现 观察者模式又称发布订阅模式\n代码演示：\nServer\nfunc periodicTransmitter(l *net.UDPConn, a *net.UDPAddr, m *coap.Message) { subded := time.Now() for { msg := coap.Message{ Type: coap.Acknowledgement, Code: coap.Content, MessageID: m.MessageID, Payload: []byte(fmt.Sprintf(\u0026quot;Been running for %v\u0026quot;, time.Since(subded))), } msg.SetOption(coap.ContentFormat, coap.TextPlain) log.Println(m.Path()) msg.SetOption(coap.LocationPath, m.Path()) log.Printf(\u0026quot;Transmitting %v\u0026quot;, msg) err := coap.Transmit(l, a, msg) if err != nil { log.Printf(\u0026quot;Error on transmitter, stopping: %v\u0026quot;, err) return } time.Sleep(time.Second) } } func main() { coap.ListenAndServe(\u0026quot;udp\u0026quot;, \u0026quot;:5683\u0026quot;, coap.FuncHandler(func(l *net.UDPConn, a *net.UDPAddr, m *coap.Message) *coap.Message { if m.Code == coap.GET \u0026amp;\u0026amp; m.Option(coap.Observe) != nil { //判断如果是Observe类型，则调用订阅事件 if value, ok := m.Option(coap.Observe).(uint32); ok \u0026amp;\u0026amp; value == 1 \u0026amp;\u0026amp; m.Path()[0]== \u0026quot;obs\u0026quot; { go periodicTransmitter(l, a, m) } } return nil })) }  Client\nreq := coap.Message{ Type: coap.NonConfirmable, Code: coap.GET, MessageID: 12345, } req.AddOption(coap.Observe, 1) req.SetPathString(\u0026quot;/obs\u0026quot;) c, err := coap.Dial(\u0026quot;udp\u0026quot;, \u0026quot;localhost:5683\u0026quot;) if err != nil { log.Fatalf(\u0026quot;Error dialing: %v\u0026quot;, err) } rv, err := c.Send(req) if err != nil { log.Fatalf(\u0026quot;Error sending request: %v\u0026quot;, err) } for err == nil { if rv != nil { if err != nil { log.Fatalf(\u0026quot;Error receiving: %v\u0026quot;, err) } log.Printf(\u0026quot;Got %s\u0026quot;, rv.Payload) } rv, err = c.Receive() } log.Printf(\u0026quot;Done...\\n\u0026quot;, err)  从代码分析可看出，发布订阅模式其实是对指定path的轮询Receive，与http轮询不同的是，发送一次请求，没有握手机制。可以设置重试次数。\nCOAP 多播模式实现 CoAP支持在IP多播组中发送请求，这相当于连续的单播CoAP。使用场景类似于我们的APP消息推送，这种场景只推送消息，不需要接受消息应答。\n消息层  多播请求的特点是目的地址由具体的CoAP端地址变成了IP多播地址，多播请求必须是不需应答消息。  请求响应层 如果服务端决定响应一个多播请求，它不应该立即响应。相反它应该会等待一段时间才进行响应。我们把这段时间称为空闲（Leisure）时间。\nCOAP 服务器API最佳实践 API 文档示例: 设备向服务器端请求 向某个家庭添加用户\nPOST coaps://dc.spotmau.cn:5683/lock/v3/home/:id/users  请求参数 Content-Type: application/json     参数 类型 是否必须 描述     name string 是 人员姓名：长度：2～16   image string 否 人员头像的base64编码   desc string 否 人员描述    响应 Code: 0 OK  Code: != 0     状态码 错误类型 描述     4.00 invalid_home 未找到对应家庭   4.00 invalid_phone 被授权用户未绑定手机   5.00 internal_server_error 系统处理错误   4.09 conflict 创建家庭数量超过限制    { \u0026quot;error\u0026quot;: \u0026quot;invalid_home\u0026quot;, \u0026quot;error_description\u0026quot;: \u0026quot;home not found\u0026quot; }  CoAP-HTTP Proxying\nHTTP-CoAP Proxying\nAPI 文档示例: 服务器向设备请求 代理模式\n添加用户\nPOST coaps://[2001:db8::2:1]:5683/device_id/lock/:id/people  { \u0026quot;name\u0026quot;:\u0026quot;张三丰\u0026quot; }  删除用户\nDELETE coaps://[2001:db8::2:1]:5683/device_id/lock/:id/people/:uid  修改用户\nPUT coaps://[2001:db8::2:1]:5683/device_id/lock/:id/people/:uid  { \u0026quot;name\u0026quot;:\u0026quot;张三\u0026quot; }  查询用户\nGET coaps://[2001:db8::2:1]:5683/device_id/lock/:id/people?name=\u0026quot;张三\u0026quot;  GET coaps://[2001:db8::2:1]:5683/device_id/open  请求参数 Authorization: {{wang_guan_token}}  响应 Code: 2.x OK  Code: != 2.x     状态码 错误类型 描述     4.04 not_found 设备不存在   4.01 unauthorized 没有添加验证   4.03 forbidden 操作被拒绝   5.00 internal_server_error 处理错误，会将错误信息返回到结果Body    COAPs 加密传输 COAP 采用 DTLS作为加密手段， PSK 是DTLS 定义的密钥交换方案之一，相对于公钥证书方案(如 ECDHA_RSA) 来说，其具备更加轻量化、高效的优点。\n//服务器端 server.HandlePSK(func(id string) []byte { return []byte(\u0026quot;secretPSK\u0026quot;) }) server.ListenAndServeDTLS(\u0026quot;:5684\u0026quot;) //客户端 conn, err := coap.DialDTLS(\u0026quot;localhost:5684\u0026quot;, \u0026quot;clientId\u0026quot;, \u0026quot;secretPSK\u0026quot;) if err != nil { panic(err.Error()) }  总结 从代码实现可以看出CoAP 是类似于 HTTP Restful API形式， 请求和返回消息格式一致，集成设备订阅模式的物联网解决方案。CoAP可以作为短连和长连处理，支持重连机制的无序消息解决方案。\nCoAP相对于MqTT而言，有以下不同：\n CoAP 允许将设备作为服务器终端，允许在没有长连的情况下向设备发送指令。 MqTT 的思想是将设备集中联网，然后采取订阅发送的模式。 CoAP 的订阅模式不能获取消息的应答。 模式使用场景：以开门为例：开门，则向设备发送 GET coap://cip:cport/lock_id/unlock 方法， 关门则发送 coap://cip:cport/lock_id/lock 方法。消息推送则采取订阅方式。 CoAP 默认采用PSK算法保证数据传输加密。  请求/响应的匹配 见于目前请求响应模型和当前系统差别很大，就请求/响应的匹配做补充说明。\n5.3.1, 令牌（token） token是用于匹配响应与请求的。token的值有0~8字节（注意，每个信息都携带token，即使其长度为零）。每个请求都携带由客户端生成的token，服务端在响应时必须复制（不能修改）这个token。\ntoken用作client-local标示，用于区分并发请求（参见5.3节），也称为“request ID”。\n客户端生成token时需要注意，当前使用的token对给定的源端和目的端应该都是独一无二的。（注意客户端在生成token时，如果要向不同的端（比如源端口号不同）中发送请求，可以使用同样的token）。当只向目的端产生一个token，或者向每个目的端发送的请求都是顺序的，且都是附带响应，token为空也是可行的。有多种策略实现。\n如果客户端不使用传输层安全(TLS，见第9章）发送请求，就需要使用复杂的，随机的token来防止欺诈响应（见11.4节），起到保护功能，这也是token允许使用最多8个字节的原因。token中随机组件的实际长度取决于客户端的安全需求和欺诈响应造成的威胁程度。接入到互联网的客户端至少应该使用32位随机码，记住，没有直接连接互联网也不一定能有效防范欺诈。注意，Message ID几乎没有添加保护，因为它通常是顺序分配的，因此可能被猜测到，并通过欺诈响应绕过。客户端想要优化token长度，可能会向进一步检测正在进行的攻击等级（例如计算接收的token不匹配的消息个数）。[RFC4086]讨论对安全的随机性要求。\n端接收一个不是它生成的token，必须把这个token当做不透明的，不能假设它的内容和结构。\n5.3.2, 请求/响应匹配规则 确切的匹配响应与请求的规则如下：\n响应的源端必须和原始请求的目的端一致。\n在附带响应中，CON请求和ACK的“Message ID”必须匹配，响应和原始请求的“token”必须匹配。在单独响应中，只需响应和原始请求的“token”匹配。万一信息携带异常的响应（不是认定的端，端地址、token和客户端的期望不匹配），这个响应必须被拒绝（见4.2和4.3）。\n注意：客户端接收到CON响应之后，可能想在回复完ACK马上清除这个消息的状态。如果这个ACK丢失，且服务端重传这个CON消息，客户端可能不会再有任何与该响应相关联的状态，会导致这个重传成为异常消息；客户端可能会发送RST信息，这样它就不会再收到更多的重传消息。这个行为是正常的，并不是一个错误（没有积极优化内存使用状态的客户端会将第二个CON认定为重发。客户端事实上期望从服务器[observe]得到更多消息，就必须在任何情况下保持状态）。\n","title":"COAP 应用详解\n"},{"location":"开发/nsq/NSQ入门指南","tags":["MQ"],"text":"NSQ是实时的分布式消息处理平台，用于大规模系统中的实时消息服务，并且每天能够处理数亿级别的消息，其设计目标是为在分布式环境下运行的去中心化服务提供一个强大的基础架构。\n快速入门 NSQ 安装 docker-compose.yml\nversion: '3' services: nsqlookupd: image: nsqio/nsq command: /nsqlookupd ports: - \u0026quot;4160\u0026quot; - \u0026quot;4161\u0026quot; nsqd: image: nsqio/nsq command: /nsqd --lookupd-tcp-address=nsqlookupd:4160 depends_on: - nsqlookupd ports: - \u0026quot;4150\u0026quot; - \u0026quot;4151\u0026quot; nsqadmin: image: nsqio/nsq command: /nsqadmin --lookupd-http-address=nsqlookupd:4161 depends_on: - nsqlookupd ports: - \u0026quot;4171\u0026quot;  docker-compose up -d  docker-compose ps  http://127.0.0.1:4171 (docker 外部映射端口可能不一致，具体查看docker-compose ps中对应的端口地址)  NSQ主要组件  nsqd：一个负责接收、排队、转发消息到客户端的守护进程 nsqlookupd：管理拓扑信息并提供最终一致性的发现服务的守护进程 nsqadmin：一套Web用户界面，可实时查看集群的统计数据和执行各种各样的管理任务 utilities：常见基础功能、数据流处理工具，如nsq_stat、nsq_tail、nsq_to_file、nsq_to_http、nsq_to_nsq、to_nsq  NSQ核心概念  Topic：一个topic就是程序发布消息的一个逻辑键，当程序第一次发布消息时就会创建topic。\n Channels channel组与消费者相关，是消费者之间的负载均衡，channel在某种意义上来说是一个“队列”。每当一个发布者发送一条消息到一个topic，消息会被复制到所有消费者连接的channel上，消费者通过这个特殊的channel读取消息，实际上，在消费者第一次订阅时就会创建channel。\n  Channel会将消息进行排列，如果没有消费者读取消息，消息首先会在内存中排队，当量太大时就会被保存到磁盘中。\n Message 消息构成了我们数据流的中坚力量，消费者可以选择结束消息，表明它们正在被正常处理，或者重新将他们排队待到后面再进行处理。每个消息包含传递尝试的次数，当消息传递超过一定的阀值次数时，我们应该放弃这些消息，或者作为额外消息进行处理。  NSQ是怎样运行的 NSQ在操作期间同样运行着两个程序：\nNsqd ——nsqd守护进程是NSQ的核心部分，它是一个单独的监听某个端口进来的消息的二进制程序。每个nsqd节点都独立运行，不共享任何状态。当一个节点启动时，它向一组nsqlookupd节点进行注册操作，并将保存在此节点上的topic和channel进行广播。\n客户端可以发布消息到nsqd守护进程上，或者从nsqd守护进程上读取消息。通常，消息发布者会向一个单一的local nsqd发布消息，消费者从连接了的一组nsqd节点的topic上远程读取消息。如果你不关心动态添加节点功能，你可以直接运行standalone模式。\nNsqlookupd ——nsqlookupd服务器像consul或etcd那样工作，只是它被设计得没有协调和强一致性能力。每个nsqlookupd都作为nsqd节点注册信息的短暂数据存储区。消费者连接这些节点去检测需要从哪个nsqd节点上读取消息。\nNSQ消息的生命周期 NSQ提倡生产者与nsqd尽量在同一个实例环境中。生产者不需要负责发现其他的nsqd实例, 它们只管往自己的nsqd中投放消息。  NSQ具体的消息流程如下：\n 生产者往本地的nsqd中发送消息，这个过程会开启一个连接，并发送一个带有topic和消息体的PUB的命令到nsqd中。我们假如是发送一个events的topic events topic 会对消息进行copy,并多路发送到各个channel中, 我们假设有三个channel, 那么这个流程会如下图描述所示:  channel中的每条消息会被放进队列中, 直到消息被worker所消费掉, 如果队列占用的内存超出限制, 消息会被写进硬盘 nsqd节点会首先向nsqlookd节点广播它的位置信息, 一旦这些信息被nsqlookupd注册上, workers就会发现这些nsqd节点,包括这些节点的events topic，相关过程如下图  每个worker向每个nsqd主机进行订阅操作，用于表明worker已经准备好接受消息了。这里我们不需要一个完整的连通图，但我们必须要保证每个单独的nsqd实例拥有足够的消费者去消费它们的消息，否则channel会被队列堆着。  NSQ 为什么是可靠的 在生产环境中，我们几乎在我们所有的实例中运行nsqd守护程序，发布者之间协同定位。NSQ在实际生产中运行良好有几个原因：\n简单的协议 ——如果你的队列已经有了一个很好的客户端库，这个不是一个很大的问题，但如果你现在的客户端库存在bug或者过时了，一个简单的协议就能体现出优势了。\nNSQ有一个快速的二进制协议，通过短短的几天工作量就可以很简单地实现这些协议，我们还自己创建了我们的纯JS驱动（当时只存在coffeescript驱动），这个纯JS驱动运行的很稳定可靠。\n运行简单 ——NSQ没有复杂的水印设置或JVM级别的配置，相反，你可以配置保存到内存中的消息的数量和消息最大值，如果队列被消息填满了，消息会被保存到磁盘上。\n分布式 ——因为NSQ没有在守护程序之间共享信息，所以它从一开始就是为了分布式操作而生。个别的机器可以随便宕机随便启动而不会影响到系统的其余部分，消息发布者可以在本地发布，即使面对网络分区。\nNSQ常见部署方式 启动nsqlookupd\n nsqlookupd\n 运行两个测试的nsqd实例\n mkdir -p /tmp/nsq/data1 #正式环境请不要放在临时目录 nsqd --lookupd-tcp-address=localhost:4160 --data-path=/tmp/nsq/data1\n 运行前端监控\n nsqadmin --lookupd-http-address=localhost:4161\n 默认情况下, 可以在浏览器输入: host-name:4171 打开监控面板\n\n由于nsq提供了一个unix-like的工具,所以我们可以在终端使用以下命令进行消息的发送测试:\ncurl -d 'hello world 1' 'http://127.0.0.1:4151/pub?topic=topic_test' curl -d 'hello world 2' 'http://127.0.0.1:4151/pub?topic=topic_test'  发送后, 可以在监控面板观察页面数据的变化。\n简单示例代码 生产者\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;github.com/nsqio/go-nsq\u0026quot; ) func main() { config := nsq.NewConfig() w, _ := nsq.NewProducer(\u0026quot;127.0.0.1:4150\u0026quot;, config) err := w.Publish(\u0026quot;topic_0\u0026quot;, []byte(\u0026quot;test\u0026quot;)) //向topic_0发布消息test if err != nil { log.Panic(\u0026quot;Could not connect\u0026quot;) } w.Stop() }  消费者\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;github.com/nsqio/go-nsq\u0026quot; ) func main() { wg := \u0026amp;sync.WaitGroup{} wg.Add(1) config := nsq.NewConfig() q, _ := nsq.NewConsumer(\u0026quot;topic_0\u0026quot;, \u0026quot;ch\u0026quot;, config) q.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error { log.Printf(\u0026quot;Got a message: %v\u0026quot;, string(message.Body)) wg.Done() return nil })) err := q.ConnectToNSQD(\u0026quot;127.0.0.1:4150\u0026quot;) if err != nil { log.Panic(\u0026quot;Could not connect\u0026quot;) } wg.Wait() }  特性和担保 特性  支持无 SPOF 的分布式拓扑 水平扩展(没有中间件，无缝地添加更多的节点到集群) 低延迟消息传递 (性能) 结合负载均衡和多播消息路由风格 擅长面向流媒体(高通量)和工作(低吞吐量)工作负载 主要是内存中(除了高水位线消息透明地保存在磁盘上) 运行时发现消费者找到生产者服务(nsqlookupd) 传输层安全性 (TLS) 数据格式不可知 一些依赖项(容易部署)和健全的，有界，默认配置 任何语言都有简单 TCP 协议支持客户端库 HTTP 接口统计、管理行为和生产者(不需要客户端库发布) 为实时检测集成了 statsd 健壮的集群管理界面 (nsqadmin)  担保 对于任何分布式系统来说，都是通过智能权衡来实现目标。通过这些透明的可靠性指标，我们希望能使得 NSQ 在部署到产品上的行为是可达预期的。\n 消息不可持久化（默认）  虽然系统支持消息持久化存储在磁盘中（通过 --mem-queue-size ），不过默认情况下消息都在内存中.\n如果将 --mem-queue-size 设置为 0，所有的消息将会存储到磁盘。我们不用担心消息会丢失，nsq 内部机制保证在程序关闭时将队列中的数据持久化到硬盘，重启后就会恢复。\nNSQ 没有内置的复制机制，却有各种各样的方法管理这种权衡，比如部署拓扑结构和技术，在容错的时候从属并持久化内容到磁盘。\n 消息最少会被投递一次  如上所述，这个假设成立于 nsqd 节点没有错误。\n因为各种原因，消息可以被投递多次（客户端超时，连接失效，重新排队，等等）。由客户端负责操作。\n 接收到的消息是无序的  不要依赖于投递给消费者的消息的顺序。\n和投递消息机制类似，它是由重新队列(requeues)，内存和磁盘存储的混合导致的，实际上，节点间不会共享任何信息。\n它是相对的简单完成疏松队列，（例如，对于某个消费者来说，消息是有次序的，但是不能给你作为一个整体跨集群），通过使用时间窗来接收消息，并在处理前排序（虽然为了维持这个变量，必须抛弃时间窗外的消息）。\n 消费者最终找出所有话题的生产者  这个服务(nsqlookupd) 被设计成最终一致性。nsqlookupd 节点不会维持状态，也不会回答查询。\n网络分区并不会影响可用性，分区的双方仍然能回答查询。部署性拓扑可以显著的减轻这类问题。\n不支持的使用场景 nsq大部分情况基本能满足我们作为消息队列的要求,而且性能与单点故障处理能力也比较出色， 但NSQ不能使用于以下场景。\n  有顺序要求的消息 不支持副本集的集群方式   NSQ 性能测试 这篇文章主要对NSQ性能做测试。\n测试环境  硬件环境  处理器名称：Intel Core i5 处理器速度： 3.1 GHz 处理器数目： 1 核总数： 4 L2 缓存（每个核）： 256 KB L3 缓存： 4 MB 内存： 16 GB  软件环境  操作系统：macOS 10.12.4 (16E195) Go 语言版本： 1.8.1 NSQ版本：1.0.0-compat   生产写入性能测试 插入每条数据大小为200字节\n   运行时间 写入数据 写入速度 写入效率 耗时(us)/条     10秒 3,278,200 55.594mb/s 91,474.761/秒 3.431     测试脚本：https://github.com/nsqio/nsq/blob/master/bench/bench_writer/bench_writer.go\n 消费性能测试 每条数据大小为200字节\n   运行时间 读取数据 消费速度 读取效率 耗时(us)/条     10秒 3,278,200 58.922mb/s 308,920.325/秒 3.237     测试脚本：https://github.com/nsqio/nsq/blob/master/bench/bench_reader/bench_reader.go\n 并发单订阅性能测试 插入的数据大小为1字节\n   生产条数 生产耗时（毫秒） 消费耗时（毫秒）     10 1.423013 1.197299   1000 47.938627 51.872540   10,000 460.019361 530.210616   100,000 5976.451920 6466.993025     结论：在当前测试环境，及时消费的情况下每秒可生产消费数据小于2万\n 并发多订阅测试    生产条数 生产耗时（毫秒） 消费者1耗时（毫秒） 消费者2耗时（毫秒）     10 1.570398 1.228455 1.254492   1000 49.56317 60.15104 60.15104   10,000 466.007770 663.163937 663.961094   100,000 6516.490799 7105.19345 7107.097945     结论：多订阅会有一定时间上的损耗，但损耗不大。\n //并发测试脚本 package main import ( \u0026quot;github.com/nsqio/go-nsq\u0026quot; \u0026quot;log\u0026quot; \u0026quot;runtime\u0026quot; \u0026quot;time\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;flag\u0026quot; ) var ( num = flag.Int(\u0026quot;num\u0026quot;, 1000, \u0026quot;number of profuced\u0026quot;) tcpAddress = flag.String(\u0026quot;nsqd-tcp-address\u0026quot;, \u0026quot;127.0.0.1:4150\u0026quot;, \u0026quot;\u0026lt;addr\u0026gt;:\u0026lt;port\u0026gt; to connect to nsqd\u0026quot;) ) func main() { flag.Parse() runtime.GOMAXPROCS(runtime.NumCPU()) test := Tester{} go func() { test.Produce(*num) }() time.Sleep(500 * time.Millisecond) //等待生产一定数量 test.Consume(*num,\u0026quot;ch\u0026quot;) } type Tester struct { } //Produce 测试生产数据， num 生产条数 func (this *Tester) Produce(num int) { config := nsq.NewConfig() w, _ := nsq.NewProducer(tcpAddress, config) start := time.Now() for i := 0; i \u0026lt; num; i++ { err := w.Publish(\u0026quot;mc_topic_test\u0026quot;, []byte(\u0026quot;t\u0026quot;)) if err != nil { log.Panicln(i, err) } } elapsed := time.Since(start) log.Printf(\u0026quot;生产 %d 条数据耗时 %f\u0026quot;, num, float64(elapsed.Nanoseconds()) / 1000000) w.Stop() } //Consume 测试消费 num 生产条数, channel 订阅的 channel func (this *Tester) Consume(num int, channel string) { wg := \u0026amp;sync.WaitGroup{} wg.Add(1) config := nsq.NewConfig() q, _ := nsq.NewConsumer(\u0026quot;mc_topic_test\u0026quot;, channel, config) cnt := num start := time.Now() q.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error { //log.Printf(\u0026quot;Got a message: %v\u0026quot;, string(message.Body)) //wg.Done() cnt -- if cnt == 0 { elapsed := time.Since(start) log.Printf(\u0026quot;消费 %d 条数据耗时 %f\u0026quot;, num, float64(elapsed.Nanoseconds()) / 1000000) wg.Done() } return nil })) err := q.ConnectToNSQD(\u0026quot;127.0.0.1:4150\u0026quot;) if err != nil { log.Panic(\u0026quot;无法连接\u0026quot;) } wg.Wait() }  ","title":"NSQ 快速入门和性能测试\n"},{"location":"项目/mdrest","tags":["golang","markdown"],"text":"从Markdown建站，几乎成了整个技术圈博客标配，但是Markdown的技术存在很多限制，搜索下目前Markdown博客引擎你会发现，所有的博客引擎定制化不是很高，并且目前很多很流行的博客引擎都不太完善。目前流行的Markdown引擎如下，这些东西缺点显而易见。\n流行的markdown引擎\n对于一个技术流而言，这些博客可拓展性太差，对于一个非技术流而言，操作太复杂。一直想写一个restful风格的Markdown引擎，一个偶然的机会，工作中需要改版开发者中心的文档系统，于是一个restful风格的Markdown引擎就应运而生了，耗时：5天。这比我想象的时间少了很多，于是就将其作为一个库进行开源。\nGithub地址：https://github.com/ti/mdrest\n最终展示效果：\n 博客： http://nanxi.li 文档中心：http://accounts.cug.edu.cn/apps/docs.html  先上几张图，说明Markown最终效果，当然，如果你是在我的博客中阅读这篇文章的话，博客本身就是最好的效果展示。\n自适应对手机端效果图\n主页\n全文搜索\n正文排版\n标签页面\n MdRest 本身不做博客，它只是数据生成器。你无需对现有的md文件做任何更改，就可以轻松地将她们转换为可索引，结构化，免服务器，低成本的json数据。md文档的数据化，给前端展示带来无限可能，它可以是文档中心，可能是普通博文，也可能是录音，视频，相册，将数据与展示解绑才能更多可能。\n 特性 1. 自由的目录结构和文章内容 自由的目录结构，你的博客目录可以是这个样子，所有的目录安排，图片资源摆放，完全可以按照你自己的喜好和规则，无需按照特定的约束进行。markdown rest引擎会将所有图片资源转换为以根目录为主目录绝对路径。也意味着，如果你的文章在git中浏览是正常的，那在博客中也会是正常的，无需对文章做转换。\n目录结构\nsample_docs ├── Simple Article.md ├── YAML Article.md ├── _DraftArticle.md ├── first dir │ ├── Hello word.md │ └── img │ └── logo.png └── second\\ dir └── Hello\\ word.md  文档结构：\n# Hello world 这篇文章会自动识别文章标题，自动截取文章简介，自动转换图片相对流经。 ![img1](../folder2/hello.png) ![img2](folder2/hello.png) 查看关联的其他文章, [other reference markdown](../folder2/reference.md)  2. 智能的文档属性 如果你用过其他的博客引擎，可能会要求你的博客是下面这个样子的。\n--- title: Hello world author: leenanxi catalog: blog tags: [tag1, tag2] date: 2016-12-29 draft: true --- # Hello world This is content  Mdrest对Markdown的格式没有要求，你的文章可以是下面这个样子。文章的标题，创建日期，catalog 都可以自动生成。标题生成的的优先级是：yaml -\u0026gt; 第一个# -\u0026gt; 文件名。 草稿文章标题可以是 _filename.md\n# Hello world This is content  3. 自由的JSON输出 MdRest支持任何格式的Yaml标签，它会将您的Ymal标签转换为JSON，例如您的文章可以是下面这个样子的。大多数使用markdown博客引擎主题的时候会使用html和js修改主题的很多功能，mdrest给开发者最大的修改自由，允许完全自由的输出格式。\n--- video: /videos/hello_word.mp4 medias: [video1.mp4, video2.mp4,pic1.jpg] other1: name: \u0026quot;name\u0026quot; x1: [3, 4] --- # Hello world This is content  4. 拓展Markdown渲染 （模仿简书） 我们的博客中图片难免需要插入图片标注，之前很多人的做法是给图片下面添加一个段落或块引用来进行，其实Markdown原生支持 ![img](path.png \u0026quot;title\u0026quot;) 这样的形式，mdrest会自动将title作为题注，进行html渲染，当然，您可以在markdown中使用html进行更复杂的操作。\n# Hello world ![无印良品](../imgs/wulinliangpin.png \u0026quot;无印良品LOGO\u0026quot;)  \n5. 极简的前端组件。  不使用jQuery 不使用任何JS框架 纯粹的html5开发   目前的博客前端完全模仿angularjs的路由和API风格，但是整体架构却使用原生JS自行编写，因此体积很小，前端所有的业务逻辑JS和框架JS加起来只有：83.1 KB， 作为对比，流行的框架体积如下，可以看到应用的全部代码都比任何一个js库小。\n    Library/Framework size (min)     jQuery 3.2 86kb   React 147kb/**   Angular 1 159kb/235kb   Polymer 222kb/302kb   Aurelia 287kb/352kb   Ember 433kb   Angular 2 623kb/1023kb      大部分小应用场景下，我们不需要任何框架来开发前端组件，体积，效率，自由度各方面都有影响。了解基础的js知识 + 各框架基本原理，可以给我们的应用带来意想不到的时间和空间上的收获。\n 写在最后 推荐使用typora作为markdown的主要编辑工具，可以给你带来更简单的输入体验。\n","title":"MdRest 关于Markdown博客，你所期望的都在这里\n"},{"location":"设计/不存在的“白”","tags":["设计"],"text":"1.“‘白’这样的东西是不存在的。” \n漂白的骨头让我们与死亡相连，但奶和蛋的白，又对我们述说着生命，衣服的白，又让我们感觉到了温暖与舒适。母乳的哺育对所有的哺乳动物来说都是重要行为，但无论动物还是人类，所有的乳汁都是白色的。大多数蛋也都是白色的，无论下这些蛋的鸟是什么颜色，白鸟下白蛋，蓝鸟也是，黑鸟也是，蛇也是，甚至鳄鱼也是。真正的生命居于白之中。蛋壳就像是构成这个世界与另一个世界边界的膜。当其打开，出来的就不在是白的，而是该种动物之本色。\n 世间本没有“白”，而我们经常感觉到了“它”的存在。在这个现实世界中，白总是被污染的、不纯的。它只是一道痕迹，一道其指向本源的标志而已,我们可能感觉到了白，但那只是一种幻觉。“白””包含了所有颜色，又褪去了所有颜色，是负熵的极限，是生命的起始，是信息的“边缘”。当我们获得了与“白”的这种联系，我们的世界发出的光就更亮了，投出的影也就更深了。\n 白的纯洁是短暂的，因为他很容易被玷污，也正是人们意识`到了美的转瞬即逝，才异常珍惜，这也就是人的本性吧，即得不到的才是最美的，是不是有点贱啊，嘿嘿嘿。\n2.清理思绪，还原事物的本质。 \n一座花园的美不在于一位有才华的设计师所创造出的那些精彩特征，实际上，它的美是通过不断的清理过程揭开的。优雅之美并非短期努力所能成就，其建立只能通过漫长的清理和打磨过程。\n自然一直在自我转化，其内在力量远比我们想象的强大。岩石、苔藓和落叶经过一段漫长的时间化为泥土，树皮的颜色褪去，而后又重生一新，池塘里的水则是一种净蓝。\n人们一方面试图通过有意识地运用创造力自然之美竞争。这种意识体现在各个公共场合的花园中，花园中的鹅卵石要求不断打理，如遭忽视，白色很快被热成土地的颜色，花园的白色地面很快就会被自然落叶和泥土所覆盖。为保持其白，鹅卵石之间自然累积的泥土必须清理掉，这是一件需要大量时间和力气的工作。花园的维护靠的是人类与自然的衰败过程无休止的斗争，保住人类创造出自认为美的东西，努力保持其事物（人类创造出的）本来面貌。\n 但作为“自然”角度，它做的事亦是如此，清理掉不必要的东西，保持事物的本质。\n 纸质出版的一个特点就是油墨，一旦印上去了就再也擦不掉了，这种情况就容许了大跃进完善信息的原则，换句话说，由于其不可逆性意味着，我们必须不断挑战自己，克服自己在上面的失误。因此，当我们在上面得到了某种东西，我们的情感就会不断被打动。就在书不断地被修改打磨，错误点不断被清理掉的过程中，我们遇到了“白”，尝到了清理思绪的美。\n3.思与空 \n空其实提供了一个让我们想象力自由发挥的空间，大大丰富了我们的想象力。陕西岐山当地（不是现在一大碗的这种哈）有一种臊子面，客人几乎一口一碗，客人吃完，服务员再上一份，如客人又吃完，服务员马上又上一份。由于上的量小的一口就能吞下，上与吃的循环就要无数次重复，客人很难控制它吃的份量，因为看着空碗越摞越高，感觉很有成就，所以就不停的吃，上涨的碗垛就是他们成就的证明。\n思的行为很像吃臊子面的颠倒，客人看着摞起的空碗，以其“思”而非“面”填入其中。他这样做也是遵循一定节奏的，先是一个想法填入一个碗，然后一瞬间，又一个，然后又一个……如此这般，就像一个条件反射，“想法”在他眼前堆积起来，空面碗的例子反映了思的总体机制。简言之，我们的大脑自动讲“答案”插入小的设置空间，以此方式，空带着我们思的过程前行。\n","title":"不存在的“白”\n"},{"location":"开发/Golang context简单示例","tags":["go","context"],"text":"对于 Golang 开发者来说 context （上下文）包一定不会陌生。但很多时候，我们懒惰的只是见过它，或能起到什么作用，并不会去深究它。\n应用场景：在 Go http 包的 Server 中，每一个请求在都有一个对应的 goroutine 去处理。请求处理函数通常会启动额外的 goroutine 用来访问后端服务，比如数据库和 RPC 服务。用来处理一个请求的 goroutine 通常需要访问一些与请求特定的数据，比如终端用户的身份认证信息、验证相关的 token、请求的截止时间。当一个请求被取消或超时时，所有用来处理该请求的goroutine 都应该迅速退出，然后系统才能释放这些 goroutine 占用的资源。\nContext 原理 Context 的调用应该是链式的，通过 WithCancel ， WithDeadline ， WithTimeout 或 WithValue 派生出新的 Context。当父 Context 被取消时，其派生的所有 Context 都将取消。\n通过 context.WithXXX 都将返回新的 Context 和 CancelFunc。调用 CancelFunc 将取消子代，移除父代对子代的引用，并且停止所有定时器。未能调用 CancelFunc 将泄漏子代，直到父代被取消或定时器触发。 go vet 工具检查所有流程控制路径上使用 CancelFuncs。\n遵循规则 遵循以下规则，以保持包之间的接口一致，并启用静态分析工具以检查上下文传播。\n 不要将 Contexts 放入结构体，相反 context 应该作为第一个参数传入，命名为 ctx 。 func DoSomething（ctx context.Context，arg Arg）error { // ... use ctx ... } 即使函数允许，也不要传入 nil 的 Context。如果不知道用哪种 Context，可以使用 context.TODO() 。 使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数 相同的 Context 可以传递给在不同的 goroutine ；Context 是并发安全的。  Context 包 结构体\n// A Context carries a deadline, cancelation signal, and request-scoped values // across API boundaries. Its methods are safe for simultaneous use by multiple // goroutines. type Context interface { // Done returns a channel that is closed when this Context is canceled // or times out. Done() \u0026lt;-chan struct{} // Err indicates why this context was canceled, after the Done channel // is closed. Err() error // Deadline returns the time when this Context will be canceled, if any. Deadline() (deadline time.Time, ok bool) // Value returns the value associated with key or nil if none. Value(key interface{}) interface{} }   Done()，返回一个channel。当times out或者调用cancel方法时，将会close掉。 Err()，返回一个错误。该context为什么被取消掉。 Deadline()，返回截止时间和ok。 Value()，返回值。  所有方法\nunc Background() Context func TODO() Context func WithCancel(parent Context) (ctx Context, cancel CancelFunc) func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) func WithValue(parent Context, key, val interface{}) Context  上面可以看到Context是一个接口，想要使用就得实现其方法。在context包内部已经为我们实现好了两个空的Context，可以通过调用Background()和TODO()方法获取。一般的将它们作为Context的根，往下派生。\nWithCancel 例子 WithCancel 以一个新的 Done channel 返回一个父 Context 的拷贝。\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, \u0026amp;c) return \u0026amp;c, func() { c.cancel(true, Canceled) } } // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{ Context: parent, done: make(chan struct{}), } }  此示例演示使用一个可取消的上下文，以防止 goroutine 泄漏。示例函数结束时，defer 调用 cancel 方法，gen goroutine 将返回而不泄漏。\nackage main import ( \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { // gen generates integers in a separate goroutine and // sends them to the returned channel. // The callers of gen need to cancel the context once // they are done consuming generated integers not to leak // the internal goroutine started by gen. gen := func(ctx context.Context) \u0026lt;-chan int { dst := make(chan int) n := go func() { for { select { case \u0026lt;-ctx.Done(): return // returning not to leak the goroutine case dst \u0026lt;- n: n++ } } }() return dst } ctx, cancel := context.WithCancel(context.Background()) defer cancel() // cancel when we are finished consuming integers for n := range gen(ctx) { fmt.Println(n) if n == { break } } }  WithDeadline 例子 func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) { if cur, ok := parent.Deadline(); ok \u0026amp;\u0026amp; cur.Before(deadline) { // The current deadline is already sooner than the new one. return WithCancel(parent) } c := \u0026amp;timerCtx{ cancelCtx: newCancelCtx(parent), deadline: deadline, }  可以清晰的看到，当派生出的子 Context 的deadline在父Context之后，直接返回了一个父Context的拷贝。故语义上等效为父。\nWithDeadline 的最后期限调整为不晚于 d 返回父上下文的副本。如果父母的截止日期已经早于 d，WithDeadline （父，d） 是在语义上等效为父。返回的上下文完成的通道关闭的最后期限期满后，返回的取消函数调用时，或当父上下文完成的通道关闭，以先发生者为准。\n看看官方例子：\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { d := time.Now().Add(50 * time.Millisecond) ctx, cancel := context.WithDeadline(context.Background(), d) // Even though ctx will be expired, it is good practice to call its // cancelation function in any case. Failure to do so may keep the // context and its parent alive longer than necessary. defer cancel() select { case \u0026lt;-time.After(1 * time.Second): fmt.Println(\u0026quot;overslept\u0026quot;) case \u0026lt;-ctx.Done(): fmt.Println(ctx.Err()) } }  WithTimeout 例子 WithTimeout 返回 WithDeadline(parent, time.Now().Add(timeout))。\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) }  看看官方例子：\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { // Pass a context with a timeout to tell a blocking function that it // should abandon its work after the timeout elapses. ctx, cancel := context.WithTimeout(context.Background(), *time.Millisecond) defer cancel() select { case \u0026lt;-time.After( * time.Second): fmt.Println(\u0026quot;overslept\u0026quot;) case \u0026lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints \u0026quot;context deadline exceeded\u0026quot; } }  WithValue 例子 func WithValue(parent Context, key, val interface{}) Context { if key == nil { panic(\u0026quot;nil key\u0026quot;) } if !reflect.TypeOf(key).Comparable() { panic(\u0026quot;key is not comparable\u0026quot;) } return \u0026amp;valueCtx{parent, key, val} }  WithValue 返回的父与键关联的值在 val 的副本。\n使用上下文值仅为过渡进程和 Api 的请求范围的数据，而不是将可选参数传递给函数。\n提供的键必须是可比性和应该不是字符串类型或任何其他内置的类型以避免包使用的上下文之间的碰撞。WithValue 用户应该定义自己的键的类型。为了避免分配分配给接口 {} 时，上下文键经常有具体类型结构 {}。另外，导出的上下文关键变量静态类型应该是一个指针或接口。\n看看官方例子：\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { type favContextKey string f := func(ctx context.Context, k favContextKey) { if v := ctx.Value(k); v != nil { fmt.Println(\u0026quot;found value:\u0026quot;, v) return } fmt.Println(\u0026quot;key not found:\u0026quot;, k) } k := favContextKey(\u0026quot;language\u0026quot;) ctx := context.WithValue(context.Background(), k, \u0026quot;Go\u0026quot;) f(ctx, k) f(ctx, favContextKey(\u0026quot;color\u0026quot;)) }  ","title":"Golang context 包，简单示例\n"},{"location":"设计/读懂《设计的觉醒》","tags":["设计","日本"],"text":"《设计的觉醒》作者田中一光用平实的语言向我们娓娓道说了他这一生设计思考的觉醒过程。 田中一光， 是日本著名的设计师，是平面设计领域的教父级人物， 在书中我们可以详尽的体会到他的生活、设计构思、以及对整个设计界的认知，而且读了那本书之后，感觉不只是在讲日本近代设计理论，而是在讲一个二战后自我奋发觉醒的国家，他们探究着日本人真正的需求，真正的设计，反思设计与社会的碰撞和 带来的影响。跟着这本书的文字，让我们进入了设计解决现实问题的世界，感受到设计工作与生活间的共鸣和无处不在的设计灵感， 田中一光用他一生坎坷的经历以及辉煌的设计历程来诠释设计思考的觉醒过程。 现在，设计日益为大家所重视，同时又出现了各种困惑，本书试图让大家通过田中一光的设计思考，去了解那些平日里司空见惯的、在普通不过的日常我们其实是多么“不了解”，进而让我们站在新知识的肩膀上，邂逅新鲜的“设计”，让“设计”在自己的身体中觉醒。\n1.无印良品 无印良品LOGO\n\n 早晨，你可以穿着“无印良品”的睡袍，在“无印良品”的床上醒来，然后用“无印良品”的牙刷刷牙，喝“无印良品”咖啡机煮出来的咖啡，坐在“无印良品”的沙发上，听“无印良品”的音响送出音乐……所有的一切，简简单单，不矫揉，不造作，却又认真贴切地照顾到我们的生活需要。对，就是这样，无印良品从最初的几十种商品发展到今日约5000种商品，从牙刷到汽车（是的，汽车，与日产合作的Muji March），食物到电器，从眼镜铺到Meal Muji餐厅，从实品商店到网络世界中的Muji.Net，成为完整的生活提案店，从早到晚生活中的一切都可以是无印良品的。\n \n 在无印良品专卖店里，除了红色的“MUJI”方框，顾客几乎看不到任何鲜艳的颜色，大多数产品的主色调都是白色、米色、蓝色或黑色。以前也听过无印良品，我一直对无印良品很好奇，其实也是最熟悉的。 “无印良品(MUJI)”创始于日本，其本意是“没有商标与优质”。虽然极力淡化品牌意识，但它遵循统一设计理念所生产出来的产品无不诠释着“无印良品”的品牌形象，它倡导自然、简约、质朴的生活方式， 那种简单的设计所带来的人类新的认知，很简单很干净，是我喜欢的那种设计，我一直就喜欢干净的设计，不复杂。其实越简单反而越难。\n ​\n2.永远的琳派 \n 众多日本画的流派中，琳派是充满日本特色而且比较特别的一派。许多流派如狩野派都受到中国的水墨画技法的影响，琳派的基础则是建立于日本传统的《大和绘》之上，具有非常强的装饰性，画面设计华丽。只要看一看琳派的著名作品《风神雷神图屏风》，便能对其特色一目了然。琳派以俵屋宗达、尾形光琳和酒井抱一为代表，在日本绘画史上绽放了灿烂的光辉。\n \n 田中一光说：“我尽量和琳派保持一定的距离，因为我怕有被琳派的这种伟大的生命力吞没的危险，它让我直想躺在它的怀抱里。\n ” 它既像温柔的琴声，又像是日本传统的戏剧”能“那尖锐的笛子声，有一种让日本人的血液沸腾起来的东西。那是典雅、自由、豁达而灿烂的世界，它并不炫耀自己的美质，展现像早春的阳光似的温暖世界。 琳派的自然描写一边隐藏着自然生态具有的丑陋侧面，一边通过明亮颜色的滤器，将其投影、转移到宫廷式的典雅舞台上。肉感通过形式化被净化，月亮因秋草增添趣味，深深的铭刻在人的心里，而这些表现又通过理性的批评精神被研究和创新。功能一点都没有被美质损坏，反而以用法本身起了让作品唤起新的美感的核心作用。 ​\n3.每日设计赏  \n战后的日本百废待兴，为了经济的迅速发展，创设了每日设计赏。在作者看来，每日设计赏的成长，也是日本经济成长和社会变动的一个缩影。 每日设计赏从1955年就开始举办。如果说五六十年代的每日设计赏是设计的“功劳奖”，那七十年代就是“作品奖”，而八十年代则是“作家奖”。从这个明显的特征可以看出，日本设计界发生了巨大的变化，设计的成熟度显而易见。 从此奖项最初创设的1955年至1960年代末的十五年间，正是日本设计的启蒙时期。最初在获奖理由的抬头里多是运动、贡献和确立等词语，而这些词语在八十年代以后就很难见到踪影了。由此我们可以感觉到，这个奖项在创办之初其实是具有启蒙和鼓励之意的。 ​\n4.二战后的日本  日本，常常被认为是一个精神十足的国家，因为日本人拥有贪婪的好奇心和旺盛的咀嚼力。在日本，中学生没有不知道莎士比亚的，因为《罗密欧与朱丽叶》和《哈姆雷特》早已不知上演了多少次。战败后的35年里，日本人从欧美学到了很多东西。不仅在科技上，在文化思想领域也勤奋地吸收着欧美的长处. \u0026lsquo;设计来源于生活，并应用于生活。二战后的日本为了孕育出新的生活文化，贪婪的吸收着欧美的生活文化，不管能否消化，西安吞下去再说，人民生活中处处存在“和与洋”的结合，筷子和叉子、和服和西服、和室和西室房间、日本画和西洋画等等。在两者的相遇过程中，曾有过痛苦的经历和操作失误，也有过不可思议的体验。不少日本设计师把欧美的现代主义原样照搬过来，但这些在具有浓郁日本文化的土地上发育不良，这就是促使他们开始反思到底什么样的东西才是“日本的”。 今天的日本，其实是以东西方两条腿在前进，这样一对矛盾体，却反而使日本显现出令世界感到惊叹的无限活力。 ​\n5.东方和西方的金色感觉  对于欧洲人来说，不论上流阶级还是贫民百姓，不论民主主义还是社会主义，他们对金色都有着共同的执着和信仰，不管是列宁广场的俄罗斯国立美术馆，还是Piotr宫殿的黄金喷水雕像，当然还有维也纳的国立美术历史博物馆，巴黎的歌剧院，伦敦的女王广场，都是在黄金豪华的世界里展开他们多彩的艺术展出和演出的。\n\n 而对于日本，金色并不是炫耀权力、象征财富的东西，而是被日本人更多的作为一种带有神秘感的色彩，夕阳西下，稻穗泛着金光，也许这就是日本膜拜金色的开端。他们喜欢在金箔上厚厚地涂上蓝绿色或者各种蓝色，形成鲜明的对比，将神圣和华丽在感官上完美地平衡。\n ​\n6.过剩的包装  一个非常漂亮的瓶子，打开一看发现里面只有几个用真空包装的泡菜，还有那些特意一个一个放入厚纸板箱的罐头，以及为了不那么快被扔掉而用金色或者银色印刷的豪华外包装盒等，各式各样华丽的礼品外表包裹着内里的空虚，它们一点也传达不了送礼人的用心。那原本送礼物的美好用心，就这样被商业主义歪曲，变成了这种让人一看就很豪华的表演，而实质上更显现出内心的贫乏。\n 我相信那些头脑灵活的工厂以及商店老板不可能对这些资源浪费毫无觉察，消费者也是很聪明的，然而这种现象却在大家默许的惰性推动下保持着一种均衡，没有任何一个群体提出抗议，一切都在依旧进行着，真是可悲可叹。 ​\n7.文字与设计 \n 如果说插图和图片是一首歌曲，那么文字就是伴奏。歌曲会因为伴奏而变得更加优美，而伴奏不可能因为歌曲而变得好听。以前的平面设计中，文字与非文字的关系非常简单，文字一直从属于画面，但对画面产生不了影响，基本就是将斗大的字粗糙的印在画面之中。\n 但在经历了鲁巴林和杜鲁夫斯曼的创作后，文字第一次成为真正的主角，以穆勒-布洛克曼为中心的瑞士平面运动也在此加快了前进的步伐。对于日本，其影响不仅没有停留在表面的造型上，而且渐渐出现在了以逻辑为主的编排设计。可以这样理解，没有文字的海报是存在的，因为超语言“一看即懂”的视觉沟通是存在的，但总给人一种缺乏现实感，很容易失去社会性，从而只属于作者的个人世界。文字则不同，即使离开了设计它也依然可以作为语言独立的存在。但在作品中，如果文字偏离了本意，这个设计作品就难逃沦为废纸的宿命，文字的主角光环显而易见。 由此，文字与设计作品的交叉很难用一句话来概括的，但即使为文字设计编排倾尽灵魂和心血，也是非常值得的，现在报纸杂志、电视、海报、包装等广阔的世界都充满了文字与设计，可以说我们的世界都被文字包围着。 ​\n8.Loft店铺 \n作者田中一光写到：“今年入春以来，我就一直沉浸在店铺设计和视觉策划的工作中。众所周知，Loft是以新潮而丰富的货品著称的，它拥有将近二十万种日用杂货。所以自1987年初创以来，很快就成为了东京的知名店铺。据关西的一些报纸报道，这次的Loft大阪梅田店，在开店第一天就迎来了五万多顾客，这使得我也不由得开始对年轻人的”限量商品“抱有浓厚兴趣了。 ​Loft带给人的，是如\u0026rdquo;城市超市”般的功能美，它很好体现出“合理性至上”的原则。装饰性的物品被撕下，露出了建筑材料本来面目。而在这样一个纯粹而功能性的空间里，又如何能展现出其中的“乐趣”？这正是这次策划需要解答的。涩谷店的墙壁都是钢筋混凝土原本的面貌，这当然不是最初的设计，而是在经过多次商讨之后最终作出的决定：将建筑材料原原本本的展现出来，回归自然。我们告诉施工单位，墙壁涂抹了混凝土后就可以收工了，现场的工人们听后非常吃惊和抵触。 而事实上，裸露着管线的天花板有着抽象画般的形式，粗糙的混凝土墙也拥有漂亮的纹路和质地，他们是相当具有Loft感觉的。店铺的货架满满当当地向着天花板伸展而上，就连库存的商品也成了组成空间的重要角色。可以说Loft的这一设计和那些做作的百货商店装潢完全相左，它将原来绝不会示人的仓库几乎完全的展现在人们面前。 而在视觉策划上也是一样，它一反目前流行的后现代主义中间色，果断地使用了被百货商店和零售业视为禁忌的“铭黄”，更大胆地运用“大红”等醒目的原色。在散发着野性美的材料空间中，这鲜明锐利的黄色发挥出了生动的作用，立刻显现了现代主义的氛围。” ​\n9. 床之间和西洋的墙壁  如果说日本的床之间是严格选择而凝视于一点的艺术，那么西方的墙壁则集中了各种各样的视觉，是一种拼贴的美。 床之间就像是家里的一个小画廊，只需安上一幅挂轴，再在地板上搭配几个具有立体造型的物件。虽然说是几个物件，但最好还要一个重点，所以对所有的点都要进行严格的选择。 季节的变化，装饰品的由来典故、为客人准备的小心意、搭配的手法、对藏品的自豪等许多想法，由于要在床之间这个小画廊里进行简洁的展示，因而会被浓缩成一个一个点。而当天主人与客人的话题便会从床之间的艺术品开始，这是一个在第一时刻传达主人所拥有的教养及情绪感觉的地方。 在这一点上，西方的室内空间会带有些阿拉伯风格。相比较床之间的艺术所追求的孤立感，西方的墙壁会将很多的东西用同一感觉进行整合将人包围起来，墙壁上装满各种各样的艺术品、肖像画或风景画这类小小的绘画作品，还有那些具有纪念意味的东西，就像在这里展示着家庭的经历和故事，油彩、素描画、版画、照片、刺绣等各种制作方法和表现形式都在一面墙壁上构成了一个整体，不可思议的是竟然有一种调和的装置美术感。 ​\n10.浮世绘  浮世绘是日本的一种绘画艺术形式，起源于17世纪，主要描绘人们日常生活、风景、和戏剧。浮世绘常被认为专指彩色印刷的木版画（日语称为锦绘），但事实上也有手绘的作品。日本的浮世绘是在平民的爱戴下发展起来的，那时，歌舞伎与作为宫廷艺术的雅乐、作为武士家族的能乐就有着本质的不同，浮世绘也是如此，最初只是为了满足贫民世俗的好奇心。当时从中国传入的水墨画作为一种翻译型文化成为了知识分子修养的表现，而浮世绘却是与贫民的歌舞伎、游玩的欢乐场面紧密相连的，它是非常煽情的。师宣、春信、歌糜就是当时著名的浮世绘画师，可以说当时没有哪个画师没有描写过色情场面。 在江户时代，无论多么复杂的东西，绘画师都会将色彩的样本交给上色师进行参考。当作者田中一光来到工厂，将自己用绘图笔绘制的原画交给上色师时，突然恍然大悟。他们并不使用自己调好的颜色，而是每次用蓝色的时候就用一点点蓝颜料放在台面上，再用水刷毛将颜色舒展开，瞬间调出几乎没有偏差的中间色。他们早已练就了那种完全不需要思考的熟练手感。同时也深切的感受到，原来图画的生死都取决于上色师的手指，与其说他们是在上色还不如说是在绘画。 ​ ​ ​ 书的后半部分是朱鄂对田中一光的传记。可以看出，一位设计师，不是有些人认为的，两耳不闻窗外事，一心只走设计路的艺术魔，田中一光喜欢戏剧、音乐、舞蹈、做菜，并且他在这几方面都很擅长，据说，从他的工作室走出去了好多准新娘，姑娘们到了这里，多多少少都会几道拿手的好菜。他也好环球旅行，好奇心极强,一生未婚。 \u0026hellip;\u0026hellip; 还有许多日常的东西，就写到这里吧。 ​\n附录 ​ 第一章\n 无印良品考 我的二十一世纪 “传达”与“记录”的分离 海报的昌盛 文字与设计 图案与设计 单纯化与设计 海外声誉渐高的日本广告和设计 东方和西方的黄金感觉 一次性纸杯 用眼睛去发现森林 永远的琳派 宗达与设计 纹样美学 缟与色 白与黑中显现的红 饥饿与过饱 海报 日本 中国与汉字 民族的椅子 每日设计赏的四十年 木纹之美 琳派和设计 我眼中的任清 过剩包装 待客的美学 ​ 第二章 一个人的创想之旅 玻璃窗边的版面设计 三宅一生、高田贤三、森英惠 平面艺术的时间 书桌上的三个商标 年历的变迁 店铺设计 从平面艺术的“植物园”说起 通向“茶美会 然”之道 接近浮世绘 泰然的质感 ​ 第三章 我的古典 美丽而封闭的故乡 绢制樱花 来自日记 我的歌舞伎 俯瞰的风景 日本人的审美观 设计与日本文化 日本的城市与色彩 日本与平面设计 写乐的大首绘 信贵山的缘起 日本画的文学性 爵士乐与色彩 关于火 品尝设计 集中的美学 回想爵士乐 印象派的色彩 床之间和西洋的墙壁 在京都俵屋感受日式清凉 对于通俗的认识 后混合文化  ","title":"读懂《设计的觉醒》\n"},{"location":"开发/跨语言对话 (python \u0026 go)","tags":["编译","跨平台"],"text":"因为go可以调用c，python 可以调用c，所以 go 也可以调用 python\n编译过程（编译语言） \npython 等解释性语言执行过程(php,nodejs, chrome javascript) \nchrome js \n动态库和静态库(系统级支持) \n运行过程 \nPython And GO Do You Go  Simple syntax that is easy to learn Compiles superfast Statically typed Statically linked binaries Cross-compiles to ~every platform Easy concurrency Great standard library (!important)  Python go import os os.system(\u0026quot;go run main.go\u0026quot;)  (Just kiding)\nFun Facts  Python speaks with C Go speaks with C Therefore, Python speaks with Go?  Challenges  Runtime barriers  Garbage Collectors (GC) （垃圾回收） Global Interpreter Lock (GIL) (全局编译锁) Just In Time compiling (JIT) （即时编译器） Resource Pools (Threads)（线程，进程，内存..）  Syntax and feature barriers  Go: Interface, Goroutines, etc. Python: Classes, Generators, etc. Oodles of other language-specific constructs   Runtime Boundaries \n看看我们需要做些什么？ [Running a Webserver in Go] package main import ( \u0026quot;fmt\u0026quot; \u0026quot;net/http\u0026quot; ) func index(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \u0026quot;Hello, world.\\n\u0026quot;) } func main() { http.HandleFunc(\u0026quot;/\u0026quot;, index) http.ListenAndServe(\u0026quot;127.0.0.1:5000\u0026quot;, nil) }  [Running a Webserver in Python] from flask import Flask app = Flask(__name__) @app.route('/') def index(): return 'Hello, world!\\n' if __name__ == '__main__': app.run(host='127.0.0.1', port=5000)  [Running a Go Webserver in Python??] from gohttp import route, run @route('/') def index(w, req): w.write(\u0026quot;Hello, world.\\n\u0026quot;) if __name__ == '__main__': run(host='127.0.0.1', port=5000)  Compare\nfrom flask import Flask app = Flask(__name__) @app.route('/') def index(): return 'Hello, world!\\n' if __name__ == '__main__': app.run(host='127.0.0.1', port=5000)  Comparing handlers Go (net/http)\nfunc index(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \u0026quot;Hello, world.\\n\u0026quot;) }  Go in Python (gohttplib)\ndef index(w, req): w.write(\u0026quot;Hello, world.\\n\u0026quot;)  python\ndef index(): return'Helo,world!\\n'  [Yo--whaa???]  C／C++ 至今没有一个现代化的web server 大部分解释型语言web server 很慢。（主要原因是运行时机制）  https://github.com/shazow/gohttplib\nHere\u0026rsquo;s how it works\u0026hellip;  Go: Export Go functions to a C shared library C: Python: Call C and wrap it in a Python-shaped bow Make it actually work ̄_(ツ)_/ ̄  let\u0026rsquo;s hack it World of Go Let\u0026rsquo;s explore how to call C from Go and Go from C.\n[Calling C from Go] package main /* int the_answer() { return 42; } */ import \u0026quot;C\u0026quot; import \u0026quot;fmt\u0026quot; func main() { r := C.the_answer() fmt.Println(r) }  $ go build-o answer $./answer 42  [Calling Go from C] package main import \u0026quot;C\u0026quot; //export TheAnswer func TheAnswer() C.int { return C.int(42) } func main() {}  go build -buildmode=c-shared -o libanswer.so  #include \u0026lt;stdio.h\u0026gt; #include \u0026quot;libanswer.h\u0026quot; int main() { int r = TheAnswer(); printf(\u0026quot;%d\\n\u0026quot;, r); return 0; }  $ gcc -o answer main.c -L. -lanswer $ ./answer 42  World of Python Now onto the Python side of this business. Same idea, so let\u0026rsquo;s look at how to call Python from C and C from Python.\nCalling C from Python  CPython Extension Interface: no dependencies, butlots of boilerplate\n CFFI: a little more magic but does more work for usand more portable\n  Calling C from Python 源码\n# answer_build.py: from cffi import FFI ffi = FFI() ffi.cdef(\u0026quot;int the_answer();\u0026quot;) ffi.set_source(\u0026quot;_answer\u0026quot;, \u0026quot;\u0026quot;\u0026quot; int the_answer() { return 42; } \u0026quot;\u0026quot;\u0026quot;) if __name__ == \u0026quot;__main__\u0026quot;: ffi.compile()  编译\n$ python answer_build.py $ ls _answer.c _answer.o _answer.so answer_build.py  源码\n# answer.py: from _answer import lib r = lib.the_answer() print(r)  运行\n$ python answer.py 42  Calling Python from C Simple function pointer that can be used in C:\nPYTHON\n@fi.callback(\u0026quot;int(int,int)\u0026quot;) def ad(x,y): return x+y  C\nstatic int(*ad)(int x,int b);  Challenges  Runtime barriers  Garbage Collectors (GC) （垃圾回收） Global Interpreter Lock (GIL) (全局编译锁) Just In Time compiling (JIT) （即时编译器） Resource Pools (Threads)（线程，进程，内存..）  Syntax and feature barriers  Go: Interface, Goroutines, etc. Python: Classes, Generators, etc. Oodles of other language-specific constructs   Overcoming Challenges \nChallenge 1: 基本架构 http.HandleFunc(pattern,func(w http.ResponseWriter,req *http.Request){ ... })  我们不能直接在python中调用golang 的 *http.Request, 因此需要建立一个C类。\ntypedef struct Request_ { const char *Method; const char *Host; const char *URL; ... } Request;  然后在Go语言中：\n//export HandleFunc func HandleFunc(cpattern *C.char, cfn *C.FuncPtr) { pattern := C.GoString(cpattern) http.HandleFunc(pattern, func(w http.ResponseWriter, req *http.Request) { // 转换请求对象到C. creq := C.Request{ Method: C.CString(req.Method), Host: C.CString(req.Host), URL: C.CString(req.URL.String()), } ... }) }  Overcoming Challenges  基本架构 翻译层  Challenge 2: 翻译层 http.HandleFunc(pattern,func(w http.ResponseWriter,req *http.Request){ ... })  我们需要的代码\nResponseWriter.Write([]byte) (int, error) ResponseWriter.WriteHeader(int)  实现逻辑\n//导出 ResponseWriter_Write func ResponseWriter_Write(wPtr C.uint, cbuf *C.char, length C.int) C.int { buf := C.GoBytes(unsafe.Pointer(cbuf), length) ... n, err := (*(*http.ResponseWriter)(w)).Write(buf) .. return C.int(n) } //导出 ResponseWriter_WriteHeader func ResponseWriter_WriteHeader(wPtr C.uint, header C.int) { ... (*(*http.ResponseWriter)(w)).WriteHeader(int(header)) }  Challenge 2: 翻译层 (Cont.) 导出以下两个Go方法\nfunc ResponseWriter_Write(wPtr C.uint, cbuf *C.char, length C.int) func ResponseWriter_WriteHeader(wPtr C.uint, header C.int)  转换为python中应该是：\nlib = ffi.dlopen(os.path.join(os.path.dirname(__file__), \u0026quot;libgohttp.so\u0026quot;)) class ResponseWriter: def __init__(self, w): self._w = w //第一个方法： ResponseWriter_Write def write(self, body): n = lib.ResponseWriter_Write(self._w, body, len(body)) if n != len(body): raise IOError(\u0026quot;Failed to write to ResponseWriter.\u0026quot;) //第一个方法：ResponseWriter_WriteHeader def set_status(self, code): lib.ResponseWriter_WriteHeader(self._w, code)  Challenge 2: 翻译层(Cont.) 原始Go代码\ntype http.ResponseWriter interface { WriteHeader(int) }  导出的方法\nfunc ResponseWriter_WriteHeader(wPtr C.uint, header C.int)  导出的c 头文件\nvoid ResponseWriter_WriteHeader(unsigned int p0, int p1);  从Python中访问C\nResponseWriter_WriteHeader(w, header)  Challenge 3: 对象传递  Wait, what\u0026rsquo;s a Go interface? To use it, we need to pass a pointer through Go ⇢ C ⇢ Python ⇢ C ⇢ Go Solution: 指针代理  Pointer Proxy \ntype ptrProxy struct { sync.Mutex count uint lookup map[uint]unsafe.Pointer } // Ref 注册给定的指针并返回可以用于稍后检索它的对应id。 func (p *ptrProxy) Ref(ptr unsafe.Pointer) C.uint { ... } // Deref 接受一个id并返回相应的指针（如果存在）。 func (p *ptrProxy) Deref(id C.uint) (unsafe.Pointer, bool) { ... } // Free 清空给定指针 func (p *ptrProxy) Free(id C.uint) { ... }  Quick flashback: Translation layer One pointer proxy to rule them all.\nvar cpointers = PtrProxy()  In the callback, reference to bind them.\nhttp.HandleFunc(pattern, func(w http.ResponseWriter, req *http.Request) { // Wrap relevant request fields in a C-friendly datastructure. creq := C.Request{ ... } wPtr := cpointers.Ref(unsafe.Pointer(\u0026amp;w)) ... cpointers.Free(wPtr) })  With pointer proxy, dereference to find them.\nfunc ResponseWriter_WriteHeader(wPtr C.uint, header C.int) { w, _ := cpointers.Deref(wPtr) (*(*http.ResponseWriter)(w)).WriteHeader(int(header)) }  完整代码(Go http lib) https://github.com/shazow/gohttplib/\nlolbenchmarks It\u0026rsquo;s fun to take a look at the performance characteristics of this kind of approach. Yes, yes, of course, this isn\u0026rsquo;t *Production Ready* or anything, but for the sake of some laughs:\n\nThese are all basic \u0026ldquo;Hello, world\\n\u0026rdquo; handlers. The first one is straight-up Go, then it\u0026rsquo;s Go-to-C, then it\u0026rsquo;s Go-to-C-to-Python (gohttp-python). It does pretty well.\nKeep in mind that this is with 10 concurrent requests, so werkzeug-flask probably chokes more on the concurrency than the response time being slow.\n   Name Total Req/Sec Time/Req     go-net/http 1.115 8969.89 0.111   gohttp-c 1.181 8470.97 0.118   gohttp-python 1.285 7779.87 0.129   gunicorn-flask 7.826 1277.73 0.783   werkzeug-flask 15.029 665.37 1.503    What\u0026rsquo;s left? We\u0026rsquo;ve discussed 80% of what\u0026rsquo;s involved, but the remaining 80% is still available as an exercise for the reader (or maybe a future blog post):\n The gohttp Python dependency comes pre-published to PyPI for your convenience, but you\u0026rsquo;ll need build and distribute the dependency yourself if you want to tweak it further. Play whack-a-mole with memory leaks. The current prototype is not safe or battle-tested by any means. Any time a C variable gets declared, we\u0026rsquo;ll need to free it. Implement the rest of the interfaces that we need. Right now there are only a couple of functions available but there is much more to build a full server. Pull requests welcome!  总结\n If our languages can speak with C, they can speak with each other. Be careful going in and out of runtimes. Be super-careful with sharing memory. We\u0026rsquo;ll need a translation layer to use non-trivial language constructs.  Other Considerations  Memory leaks Race conditions Context switching overhead security issues because C is hard Architecture campanelle  ","title":"跨语言对话 (python \u0026 go)\n"},{"location":"项目/context_router","tags":["golang","router"],"text":"GitHub: https://github.com/ti/ctxrouter\nFeatures  Context Append on Current Function Best Performance (no regexp match) Wildcards Router Support (PathPrefix) Decode request body before business layer (JSON, xml or other) Decode request url before business layer Zero Garbage  Examples Basic Example package main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;strconv\u0026quot; ) //context style func (ctx *Context) Hello(id string) { //ctx.Request ... ctx.Writer.Write([]byte(\u0026quot;hello \u0026quot; + id)) } //normal style func NormalHello(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;hello \u0026quot; + ctxrouter.Params(r)[0])) } //func style func Hello(ctx *ctxrouter.Context, name string, id int) { ctx.Text(\u0026quot;hello \u0026quot; + name + \u0026quot;, id is \u0026quot; + strconv.Itoa(id)) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/basic/:name\u0026quot;, (*Context).Hello) r.Get(\u0026quot;/normal/:name\u0026quot;, NormalHello) r.Get(\u0026quot;/func/:name/:id\u0026quot;,Hello) r.Get(\u0026quot;/\u0026quot;, (*Context).Index) //auto decode url with string or int r.Get(\u0026quot;/basic/:name/json/:age\u0026quot;, (*Context).Json) //match path prefixes /all/*: r.All(\u0026quot;/basic/*path\u0026quot;,(*Context).All) //a simple func without implement ctxrouter.Context http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type Context struct { ctxrouter.Context } func (c *Context) Index() { c.Text(\u0026quot;index\u0026quot;) } func (c *Context) All(path string) { c.Text(\u0026quot;all router goes here \u0026quot; + path) } func (c *Context) Json(name string, age int) { type Person struct { Name string Age int } c.JSON(Person{Name:name,Age:age}) }  With Powerful Context //do something Workflow with ctx router package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) type Context struct { ctxrouter.Context Data map[string]string } func (c *Context) Start() { c.Data = make(map[string]string) c.Data[\u0026quot;context\u0026quot;] = \u0026quot;0\u0026quot; c.Step() } func (c *Context) Step() { c.Data[\u0026quot;context1\u0026quot;] = \u0026quot;1\u0026quot; c.End() } func (c *Context) End() { c.Data[\u0026quot;context2\u0026quot;] = \u0026quot;2\u0026quot; c.JSON(c.Data) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/context/\u0026quot;,(*Context).Start) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  Decode Request Before Business Layer package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) //decode request sample type User struct { Id int `json:\u0026quot;int\u0026quot;` Name string `json:\u0026quot;name\u0026quot;` } type UserContext struct { ctxrouter.Context Data *User } //Auto Decode Json or other request func (ctx *UserContext) DecodeRequest() error { ctx.Data = new(User) ctx.Context.Data = ctx.Data return ctx.Context.DecodeRequest() } func (ctx *UserContext) SayHello() { ctx.Text(\u0026quot;Hello \u0026quot;+ ctx.Data.Name) } func main() { r := ctxrouter.New() r.Post(\u0026quot;/users/hello\u0026quot;,(*UserContext).SayHello) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  curl -i -X POST \\ -H \u0026quot;Content-Type:application/json\u0026quot; \\ -d \\ '{\u0026quot;name\u0026quot;:\u0026quot;leenanxi\u0026quot;}' \\ 'http://localhost:8081/users/hello'  Normal HTTP Handler Alert: This is Not recommended if you start a new project.\npackage main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; ) func NormalHelloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;HELLO\u0026quot;)) } func NormalHandler(w http.ResponseWriter, r *http.Request) { params := ctxrouter.Params(r) w.Write([]byte(\u0026quot;Name:\u0026quot; + params[0] + \u0026quot;\\nAge:\u0026quot; + params[1] )) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/normal/hello\u0026quot;,NormalHelloHandler) r.Get(\u0026quot;/normal/v1/:name/:age\u0026quot;,NormalHandler) //support any http.Handler interface r.Get(\u0026quot;/404\u0026quot;,http.NotFoundHandler()) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  How Middleware X? The router is http.Handler, so you can chain any http.Handler compatible middleware before the router, for example http://www.gorillatoolkit.org/pkg/handlers\npackage main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;github.com/gorilla/handlers\u0026quot; \u0026quot;os\u0026quot; \u0026quot;net/http\u0026quot; ) //context style func (ctx *Context) Hello(name string) { ctx.Text(\u0026quot;hello \u0026quot; + name) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/hello/:name\u0026quot;, (*Context).Hello) http.ListenAndServe(\u0026quot;:8081\u0026quot;, (handlers.LoggingHandler(os.Stdout, r))) } type Context struct { ctxrouter.Context }  Static Files package main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; ) func main() { var dir = \u0026quot;/your/static/dir/path\u0026quot; r := ctxrouter.New() r.All(\u0026quot;/static/*path\u0026quot;,http.StripPrefix(\u0026quot;/static/\u0026quot;, http.FileServer(http.Dir(dir)))) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  Restful Api package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) func main() { r := ctxrouter.New() r.Get(\u0026quot;/apps\u0026quot;, (*AppContext).GetApps) r.Get(\u0026quot;/apps/:id\u0026quot;, (*AppContext).GetApp) r.Post(\u0026quot;/apps\u0026quot;, (*AppContext).PostApps) r.Patch(\u0026quot;/apps/:id\u0026quot;, (*AppContext).PatchApp) r.Put(\u0026quot;/apps/:id\u0026quot;, (*AppContext).PutApp) r.Delete(\u0026quot;/apps/:id\u0026quot;, (*AppContext).DeleteApp) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type AppContext struct { ctxrouter.Context } func (ctx *AppContext) GetApps() { ctx.Text(\u0026quot;get apps\u0026quot;) } func (ctx *AppContext) GetApp(id string) { ctx.Text(\u0026quot;get app \u0026quot; + id) } func (ctx *AppContext) PostApps() { ctx.Text(\u0026quot;post apps\u0026quot;) } func (ctx *AppContext) DeleteApp(id string) { ctx.Text(\u0026quot;delete app \u0026quot; + id) } func (ctx *AppContext) PutApp(id string) { ctx.Text(\u0026quot;put app \u0026quot; + id) } func (ctx *AppContext) PatchApp(id string) { ctx.Text(\u0026quot;patch app \u0026quot; + id) }  Full Example //full example with all features in one file, you can read sections above package main import ( \u0026quot;net/http\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) func main() { r := ctxrouter.New() r.Get(\u0026quot;/\u0026quot;, (*Controller).Index) r.Get(\u0026quot;/basic/:name\u0026quot;, (*Controller).Hello) //match path prefixes /all/*: r.All(\u0026quot;/basic/*path\u0026quot;,(*Controller).All) //auto decode url with string or int r.Get(\u0026quot;/basic/:name/json/:age\u0026quot;, (*Controller).Json) //a simple func without implement ctxrouter.Context r.Get(\u0026quot;/basic/:name/simple\u0026quot;,Simple) r.Post(\u0026quot;/users/hello\u0026quot;,(*UserContext).PrintHello) //do something Workflow with ctx router r.Get(\u0026quot;/context/\u0026quot;,(*Context).Start) r.Get(\u0026quot;/normal/hello\u0026quot;,NormalHelloHandler) r.Get(\u0026quot;/normal/v1/:name/:age\u0026quot;,NormalHandler) //support any http.Handler interface r.Get(\u0026quot;/404\u0026quot;,http.NotFoundHandler()) //static files var dir = \u0026quot;/your/static/dir/path\u0026quot; r.All(\u0026quot;/static/*path\u0026quot;,http.StripPrefix(\u0026quot;/static/\u0026quot;, http.FileServer(http.Dir(dir)))) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type Controller struct { ctxrouter.Context } func (c *Controller) Index() { c.Text(\u0026quot;index\u0026quot;) } func (c *Controller) Hello(name string) { fmt.Fprintln(c.Writer, \u0026quot;hello \u0026quot;+name) } func (c *Controller) All(path string) { c.Text(\u0026quot;all router goes here \u0026quot; + path) } //input json and output json func (c *Controller) Json(name string, age int) { type Person struct { Name string Age int } c.JSON(Person{Name:name,Age:age}) } func Simple(ctx *ctxrouter.Context, name string) { ctx.Text(\u0026quot;simple \u0026quot; + name) } //decode request sample type User struct { Id int `json:\u0026quot;int\u0026quot;` Name string `json:\u0026quot;name\u0026quot;` } type UserContext struct { ctxrouter.Context Data *User } //Auto Decode Json or other request func (ctx *UserContext) DecodeRequest() error{ ctx.Data = new(User) ctx.Context.Data = ctx.Data return ctx.Context.DecodeRequest() } func (ctx *UserContext) PrintHello() { ctx.Text(\u0026quot;Hello \u0026quot;+ ctx.Data.Name) } type Context struct { ctxrouter.Context Data map[string]string } func (c *Context) Start() { c.Data = make(map[string]string) c.Data[\u0026quot;context\u0026quot;] = \u0026quot;0\u0026quot; c.Step() } func (c *Context) Step() { c.Data[\u0026quot;context1\u0026quot;] = \u0026quot;1\u0026quot; c.End() } func (c *Context) End() { c.Data[\u0026quot;context2\u0026quot;] = \u0026quot;2\u0026quot; c.JSON(c.Data) } func NormalHelloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;HELLO\u0026quot;)) } func NormalHandler(w http.ResponseWriter, r *http.Request) { //get router Params from \u0026quot;X-Ctxrouter-Params\u0026quot; without any extra function params := ctxrouter.Params(r) w.Write([]byte(\u0026quot;Name:\u0026quot; + params[0] + \u0026quot;\\nAge:\u0026quot; + params[1] )) }  Thanks  tree.go \u0026amp; tree_test.go is edited from httprouter https://github.com/julienschmidt/httprouter  ","title":"CtxRouter A High performance HTTP request router with Context\n"},{"location":"开发/SOA架构和微服务架构有什么区别？","tags":["微服务","架构","SOA"],"text":"相信大家在阅读这篇文章之前都对两个架构有所了解，首先让大家看张图来理解各自对区别。\n使用SOA架构和微服务构建对购物应用\n接下来理解起来就更佳容易。\n各自概念 SOA 架构  SOA架构, （英语：service-oriented architecture）, 面向服务的体系结构， 面向服务的体系结构（英语：service-oriented architecture）是构造分布式计算的应用程序的方法。它将应用程序功能作为服务发送给最终用户或者其他服务。\nSOA的原则\n 可重复使用, 粒度, 模组性, 可组合型, 物件化原件, 构件化以及具交互操作性 符合开放标准(通用的或行业的) 服务的识别和分类，提供和发布，监控和跟踪。   微服务架构  微服务(Microservices) ，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模组化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通讯。微服务架构运用于软件架构风格的其中一项概念是甘露运算 (Dew Computing)，意指由许多的小露水 (代表微服务的功能元件) 汇集而成的运算能力。\n微服务特性；\n 独立数据库访问。（独立存储，或不相关表格，服务之间数据库不共享） 数据库的可弃性。（服务将数据库作为短期的储存空间而不是储存长期的资料） 架构是对称而非分层（即生产者与消费者的关系）。 适用于具持续交付 (Continuous Delivery) 的软件开发流程。   以下内容转自知乎：https://www.zhihu.com/question/37808426\n微服务架构强调的第一个重点就是业务系统需要彻底的组件化和服务化，原有的单个业务系统会拆分为多个可以独立开发，设计，运行和运维的小应用。这些小应用之间通过服务完成交互和集成。每个小应用从前端web ui，到控制层，逻辑层，数据库访问，数据库都完全是独立的一套。在这里我们不用组件而用小应用这个词更加合适，每个小应用除了完成自身本身的业务功能外，重点就是还需要消费外部其它应用暴露的服务，同时自身也将自身的能力朝外部发布为服务。\n如果一句话来谈SOA和微服务的区别，即微服务不再强调传统SOA架构里面比较重的ESB企业服务总线，同时SOA的思想进入到单个业务系统内部实现真正的组件化。\n把这个核心搞清楚后，再来看下网上找到的对微服务架构的一些定义和阐述：\n 微服务可以在“自己的程序”中运行，并通过“轻量级设备与HTTP型API进行沟通”。关键在于该服务可以在自己的程序中运行。通过这一点我们就可以将服务公开与微服务架构（在现有系统中分布一个API）区分开来。在服务公开中，许多服务都可以被内部独立进程所限制。如果其中任何一个服务需要增加某种功能，那么就必须缩小进程范围。在微服务架构中，只需要在特定的某种服务中增加所需功能，而不影响整体进程。\n微服务不需要像普通服务那样成为一种独立的功能或者独立的资源。定义中称，微服务是需要与业务能力相匹配，这种说法完全正确。不幸的是，仍然意味着，如果能力模型粒度的设计是错误的，那么，我们就必须付出很多代价。如果你阅读了Fowler的整篇文章，你会发现，其中的指导建议是非常实用的。在决定将所有组件组合到一起时，开发人员需要非常确信这些组件都会有所改变，并且规模也会发生变化。服务粒度越粗，就越难以符合规定原则。服务粒度越细，就越能够灵活地降低变化和负载所带来的影响。然而，利弊之间的权衡过程是非常复杂的，我们要在配置和资金模型的基础上考虑到基础设施的成本问题。\n 再强调下即：\n首先对于应用本身暴露出来的服务，是和应用一起部署的，即服务本身并不单独部署，服务本身就是业务组件已有的接口能力发布和暴露出来的。了解到这点我们就看到一个关键，即我们在进行单个应用组件设计的时候，本身在组件内部就会有很大接口的设计和定义，那么这些接口我们可以根据和外部其它组件协同的需要将其发布为微服务，而如果不需要对外协同我们完全可以走内部API接口访问模式提高效率。\n其次，微服务架构本身来源于互联网的思路，因此组件对外发布的服务强调了采用HTTP Rest API的方式来进行。这个也可以看到在互联网开放能力服务平台基本都采用了Http API的方式进行服务的发布和管理。从这个角度来说，组件超外部暴露的能力才需要发布为微服务，其本身也是一种封装后的粗粒度服务。而不是将组件内部的所有业务规则和逻辑，组件本身的底层数据库CRUD操作全部朝外部发布。否则将极大的增加服务的梳理而难以进行整体服务管控和治理。\n微服务的基本思想在于考虑围绕着业务领域组件来创建应用，这些就应用可独立地进行开发、管理和加速。在分散的组件中使用微服务云架构和平台使部署、管理和服务功能交付变得更加简单。\n对于互联网谈到微服务架构一定会谈到Devops即开发测试和部署运维的一体化。当我们的单体应用以及拆分为多个小应用后，虽然整体架构可以松耦合和可扩展，但是如果拆分的组件越多，这些组件之间本身的集成和部署运维就越复杂。即任何一个组件，当他依赖的外部其它应用组件越多的时候，整个集成，部署和联调测试的过程就越复杂。这些如果完全靠我们手工去完成一是增加工作量，一是增加出错概率。\n原来谈组件化开发谈的最多的是单个组件的持续集成，包括配置环境集成，自动打包部署，自动化的冒烟测试等。对于微服务架构下首先仍然是要做好单个组件本身的持续集成，其次在这个基础上增加了多个组件的打包部署和组件间的集成。里面的核心思想就是Devops的思路，希望能够实现开发设计到部署运维的一体化。\n由于微服务架构里面强调了单个组件本身是可以在独立的进程里面运行，各个组件之间在部署的时候就能够做到进程级别的隔离。那么一台服务器我们可能需要初始化几十个甚至更多的进程来进行应用组件的部署。为了保持进程的隔离性，我们可以用虚拟机，但是当几十个进程都完全用独立的虚拟机就不现实的，而这个问题的解决刚好就是利用PaaS平台里面的轻量Docker容器来做这个事情，每个Docker是独立的容器刚好又完全做到进程级别的隔离，资源占用率又最小，这些特点刚好满足微服务架构的开发测试和自动化部署。\n前面这些问题思考清楚后就是考虑所有暴露的微服务是否需要一个统一的服务管控和治理平台，按照当前微服务架构的整体思路，虽然单个服务的实现和发布仍然是在组件内部完成的，但是这些组件暴露的服务本身的调用情况，服务本身的安全，日志和流量控制等仍然需要一个统一的SOA服务管理平台来完成。\n由于微服务尽量都是通过HTTP API的方式暴露出去的，因此这种服务管理平台不需要像传统企业内部的ESB服务总线这么重。但是最基本的服务注册，服务代理，服务发布，服务简单的路由，安全访问和授权，服务调用消息和日志记录这些功能还是需要具备。类似淘宝的Dubbo架构，即可以做为微服务架构下的服务管控平台。\n对于这种服务管控平台，核心需要讨论的就是服务每次调用本身的消息传递，输入和输出日志是否需要记录，当前就有两种做法，一种是不记录，管理平台只负责服务注册和目录发布，安全授权，实际的服务访问仍然是两个组件之间的点对点连接完成，这种方式下整个架构下获取更高的性能，同时服务管理平台也不容易成为大并发服务访问下的单点瓶颈；另外一种方式就是完全记录，在这种方式下就需要考虑服务管理平台本身的集群化不是，高并发下的性能问题。而个人建议最好的方式还是SOA服务管理平台应该提供两种管理能力，同时仅仅对核心的需要Log日志的服务进行日志记录，而其它服务只提供服务目录和访问控制即可。\n《Chris Richardson 微服务系列》的阅读笔记 本文为阅读《Chris Richardson 微服务系列》的阅读笔记，具体原文参考：「Chris Richardson 微服务系列」服务发现的可行方案以及实践案例** ， 里面有另外四篇的链接，当前daocloud已经更新到第5篇事件驱动架构。\n第一篇 微服务架构的优势和不足 文中强调的单体应用的场景，我在前面很多谈组件化和服务化的文章里面已经都谈到过了，即一个应用系统里面的模块没有办法做到彻底解耦，如果要实现按组件单独部署是不可能的，相互之间仍然有大量内部不可见依赖而导致了模块间无法拆分。\n那么单体应用本身带来的问题主要有哪些？\n1.系统复杂：内部多个模块紧耦合，关联依赖复杂，牵一发而动全身。 2.运维困难：变更或升级的影响分析困难，任何一个小修改都可能导致单体应用整体运行出现故障。 3.无法扩展：无法拆分部署，出现性能瓶颈后往往只能够增加服务器或增加集群节点，但是DB问题难解决\n正是由于这些原因需要考虑引入微服务架构（实质仍然是单个应用本身的组件化和服务化），对于微服务文章里面有一个详细说明如下：一个微服务一般完成某个特定的功能，比如订单管理、客户管理等。每个微服务都是一个微型应用，有着自己六边形架构，包括商业逻辑和各种接口。有的微服务通过暴露 API 被别的微服务或者应用客户端所用；有的微服务则通过网页 UI 实现。在运行时，每个实例通常是一个云虚拟机或者 Docker 容器。\n从这个定义和说明仍然需要做一些关键理解，即在我前面谈微服务的文章里面谈到过的，即核心的几点包括了，其一足够构成一个独立小应用（从DB到UI），其二微服务应用之间只能通过Service API进行交互，其三一般运行在云虚拟机或更轻的Docker容器上。\nAPI Gateway，这实际上微服务架构里面的很重要的内容，其作用类似于传统企业内部的ESB服务总线，只是更加轻量和高性能来解决微服务的管控和治理问题。而对于负载均衡，缓存，路由，访问控制，服务代理，监控，日志等都属于基本的服务管控内容，也是API Gateway需要考虑的核心能力。\nScale Cube的3D模型，描述的相当好，即通过微服务架构实施后扩展性的变化。\n1. Y轴：本质是应用的分解，即将传统的单体应用分解为多个微服务应用。 2. X轴：水平弹性扩展能力，即通过负载均衡来实现水平弹性扩展，但是DB问题无法解决，引入3 3. Z轴：当单个微服务应用引入了DB弹性扩展能力要解决的时候，我们引入了对数据库进行拆分和DaaS\n对于微服务架构的好处前面在讲单体应用的问题的时候已经谈到了，微服务架构正好是解决这些问题。而对于微服务架构的不足，简单总结如下：\n1. CAP原则：由于服务无状态和引入了分布式，较难解决事务一致性问题。 2. 集成复杂：任何彻底的分解都将带来集成的复杂度，即模块在集成时候需要外部微服务模块更多的配合。 3. 部署问题：稍大项目都涉及到上100个服务节点部署，还涉及到部署后的配置，扩展和监控问题。\n第二篇 使用API网关构建微服务 首先说下这篇文章的引入场景，以一个亚马逊购物网站的手机APP订单查看界面来举例，如果是一个单体应用，那么所有的界面需要获取信息都通过单体应用统一一个地址提供的多个Service API获取。但是转变为微服务架构后可以看到对于会员管理，商品管理，订单管理，财务结算管理等都已经拆分为了不同的微服务模块，需要从不同的服务提供地址调用不同的微服务模块提供的Service API来返回数据。\n在原文里面我们看到对于客户端和微服务模块间点对点直接通讯提了三个问题，如下：\n1. 问题一：客户端需求和每个微服务暴露的细粒度 API 不匹配 2. 问题二：部分服务使用的协议对 web 并不友好，如二进制RPC或AMQP消息等。 3. 问题三：会使得微服务难以重构，如服务拆分或服务组合的场景。\n那么我们从传统的ESB能力来对上面三个问题进行一个说明，第一个问题即可能涉及到细粒度的API组合，类似组合服务无法做；其二是可能存在协议转换的问 题要解决；其三即服务透明的问题，即需要对客户端提供一个统一的服务目录以使底层服务透明。由于以上问题，引入了API服务网关的概念，再次强调，对于API服务网关即使微服务架构里面的轻量服务总线，解决服务管控和治理相关问题。文中对API Gateway给出如下说明：\nAPI 网关是一个服务器，也可以说是进入系统的唯一节点。这与面向对象设计模式中的 Facade 模式很像。API 网关封装内部系统的架构，并且提供 API 给各个客户端。它还可能还具备授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等功能。\nAPI 网关负责服务请求路由、组合及协议转换。客户端的所有请求都首先经过 API 网关，然后由它将请求路由到合适的微服务。API 网关经常会通过调用多个微服务并合并结果来处理一个请求。它可以在 web 协议（如 HTTP 与 WebSocket）与内部使用的非 web 友好协议之间转换。\nAPI 网关还能为每个客户端提供一个定制的 API。通常，它会向移动客户端暴露一个粗粒度的 API。以产品详情的场景为例，API 网关可以提供一个端点（/productdetails?productid=xxx），使移动客户端可以通过一个请求获取所有的产品详情。API 网关通过调用各个服务（产品信息、推荐、评论等等）并合并结果来处理请求。\nAPI网关的优点和缺点 对于API网关的优点，其实是类似传统ESB企业服务总线的优点，即实现服务透明，同时对于服务运行过程中的日志，安全，路由，缓存等问题进行统一配置和处理，而不需要每个微服务API实现时都去考虑。如开源的Dubbo服务总线即可以看作是一个API网关的实现。\nAPI网关和ESB的一些重要区别点在于API网关更加轻量和高性能，它不需要去考虑太多遗留系统和诸多协议的适配，其次也不需要考虑服务集成过程中的大 量数据转换和映射。同时为了提升服务网关的性能，一般API网关在实现过程中不会去记录详细的数据传输日志，或者类似Dubbo架构数据传输根本就不会通 过API网关。 使用 API 网关的最大优点是，它封装了应用程序的内部结构。客户端只需要同网关交互，而不必调用特定的服务。API 网关也有一些不足。它增加了一个我们必须开发、部署和维护的高可用组件。还有一个风险是，API 网关变成了开发瓶颈。\n简单来说，在我们期望的去中心化和全分布式架构中，网关又成了一个中心点或瓶颈点，正是由于这个原因我们在网关设计的时候必须考虑即使API Gateway宕机也不要影响到服务的调用和运行。\nAPI网关的设计和实现\n对于大多数应用程序而言，API 网关的性能和可扩展性都非常重要。因此，将 API 网关构建在一个支持异步、I/O 非阻塞的平台上是合理的。有多种不同的技术可以实现一个可扩展的 API 网关。在 JVM 上，可以使用一种基于 NIO 的框架，比如 Netty、Vertx、Spring Reactor 或 JBoss Undertow 中的一种。一个非常流行的非 JVM 选项是 Node.js，它是一个基于 Chrome JavaScript 引擎构建的平台。\n另一个方法是使用 NGINX Plus。NGINX Plus 提供了一个成熟的、可扩展的、高性能 web 服务器和一个易于部署的、可配置可编程的反向代理。NGINX Plus 可以管理身份验证、访问控制、负载均衡请求、缓存响应，并提供应用程序可感知的健康检查和监控。\n对于API网关需要实现底层多个细粒度的API组合的场景，文章推荐采用响应式编程模型进行而不是传统的异步回调方法组合代码。其原因除了采用回调方式导致的代码混乱外，还有就是对于API组合本身可能存在并行或先后调用，对于采用回调方式往往很难控制。\n基于微服务的应用程序是一个分布式系统，必须使用一种进程间通信机制。有两种类型的进程间通信机制可供选择。一种是使用异步的、基于消息传递的机制。有些实现使用诸如 JMS 或 AMQP 那样的消息代理，而其它的实现（如 Zeromq）则没有代理，服务间直接通信。另一种进程间通信类型是诸如 HTTP 或 Thrift 那样的同步机制。通常，一个系统会同时使用异步和同步两种类型。它甚至还可能使用同一类型的多种实现。总之，API 网关需要支持多种通信机制。\n注：如果服务是同步调用可以看到微服务模块之间本身是没有彻底解耦的，即如果A依赖B提供的API，如果B提供的服务不可用将直接影响到A不可用。除非同步服务调用在API网关层或客户端做了相应的缓存。因此为了彻底解耦，在微服务调用上更建议选择异步方式进行。\n对于大多数基于微服务的应用程序而言，实现 API 网关，将其作为系统的唯一入口很有必要。API 网关负责服务请求路由、组合及协议转换。它为每个应用程序客户端提供一个定制的 API。API 网关还可以通过返回缓存数据或默认数据屏蔽后端服务失败。\n第三篇 微服务架构中的进程间通信 基于微服务的分布式应用是运行在多台机器上的；一般来说，每个服务实例都是一个进程。因此，如下图所示，服务之间的交互必须通过进程间通信（IPC）来实现。\n对于微服务架构的交互模式，文章从两个维度进行了描述，即\n一对一：每个客户端请求有一个服务实例来响应。 一对多：每个客户端请求有多个服务实例来响应。\n同步模式：客户端请求需要服务端即时响应，甚至可能由于等待而阻塞。 异步模式：客户端请求不会阻塞进程，服务端的响应可以是非即时的。\n对于分为这两个维度进行描述意义不太大，对于同步模式往往只能是1对1，而且还需要同步等待容易引起阻塞，而对于异步模块往往采用消息机制来实现，同时配合消息中间件可以进一步实现消息的发布订阅。而对于EDA事件驱动架构要看到其本质也是伊布消息中间件和消息的发布订阅。\n异步消息机制可以做到最大化的解耦，对于数据CUD的场景可以看到是比较容易通过异步消息机制实现的，但是会进一步引入事务一致性问题，即在采用异步消息 机制后往往通过BASE事务最终一致性来解决事务层面的问题。而对于查询功能可以看到是比较难通过异步消息API实现的，在引入这个之前可以看到需要考虑 两方面的问题并解决。\n其一是服务网关需要有数据缓存能力，以解决无法从源端获取数据的场景。其二是前端开发框架本身需要支持异步调用和数据装载模式，特别是对于数据查询功能对于用户来讲，在前端的感受仍然需要时同步的。即通过异步方式返回了查询数据后可以动态刷新前端展示界面。\n服务版本的问题：这是不可避免要遇到的问题，特别是对于RestAPI调用，由于Json格式本身无Schema返回更加容易忽视了对服务 版本的管理和控制。要知道对于Json数据格式变化仍然会导致RestAPI调用后处理失败。因此服务版本仍然采用大小版本管理机制比较好，对于小版本变 更则直接对原有服务进行覆盖同时对所有受影响的服务消费端进行升级；而对于大版本升级则本质是新增加了一个新服务，而对于旧版本服务逐步迁移和替代。\n处理局部失败：文中提到了Netfilix的服务解决方案，对于失败问题的解决要注意常用的仍然是服务超时设置，断路器机制，流量控制，缓存数据或默认值返回等。不论采用哪种失败处理策略，都需要考虑应该尽量减少服务调用失败或超时对最终用户造成的影响。\n基于请求/响应的同步 IPC\n使用同步的、基于请求/响应的 IPC 机制的时候，客户端向服务端发送请求，服务端处理请求并返回响应。一些客户端会由于等待服务端响应而被阻塞，而另外一些客户端可能使用异步的、基于事件驱动的客户端代码，这些代码可能通过 Future 或者 Rx Observable 封装。然而，与使用消息机制不同，客户端需要响应及时返回。这个模式中有很多可选的协议，但最常见的两个协议是 REST 和 Thrift。\nThrift 也能够让你选择传输协议，包括原始 TCP 和 HTTP。原始 TCP 比 HTTP 更高效，然而 HTTP 对于防火墙、浏览器和使用者来说更友好。文中对于两种实现方式已经描述的相当详细，可以看到当前互联网OpenAPI平台和微服务架构实现中仍然是大量以采用Rest API接口为主。而对于消息格式的选择，可以看到在使用RestAPI接口的时候，更多的是采用了Json消息格式而非XML，对于SOAP WebService则更多采用了XML消息格式。如果采用Thrift则还可以采用二进制消息格式以提升性能。第四篇 服务发现的可行方案以及实践案例 首先还是先说场景，看似简单的服务注册和服务目录库管理为何会变复杂，其主要的原因还是在结合了云端PaaS和Docker容器部署后，对于微服务模块部 署完成后提供出来的IP地址是动态在变化的，包括模块在进行动态集群扩展的时候也需要动态接入新的服务提供IP地址。正是由于这个原因引入了服务发现和管 理的困难度。\n在文章中提到了两种服务发现模式，即客户端发现模式和服务端发现模式，分开描述如下：\n服务客户端发现模式\n使用客户端发现模式时，客户端决定相应服务实例的网络位置，并且对请求实现负载均衡。客户端查询服务注册表，后者是一个可用服务实例的数据库；然后使用负 载均衡算法从中选择一个实例，并发出请求。客户端从服务注册服务中查询，其中是所有可用服务实例的库。客户端使用负载均衡算法从多个服务实例中选择出一 个，然后发出请求。\n注：这是类似Dubbo实现机制一样的两阶段模式，即任何一个服务的消费都需要分两个步骤进行，第一步首先是访问服务注册库（更多是API GateWay提供的一个能力）返回一个已经动态均衡后的服务可用地址，第二步即客户端和该地址直接建立连接进行服务消费和访问。\n在这种模式的实现中有两个重点，其一是动态负载均衡算法，其二是服务网关需要能够对原始服务提供点进行实时的心跳检测以确定服务提供的可用性。\nNetflix OSS 是客户端发现模式的绝佳范例。Netflix Eureka 是一个服务注册表，为服务实例注册管理和查询可用实例提供了 REST API 接口。Netflix Ribbon 是 IPC 客户端，与 Eureka 一起实现对请求的负载均衡。\n缺点：底层的IP虽然动态提供出去了，但是最终仍然暴露给了服务消费方，再需要进一步做安全和防火墙隔离的场景下显然是不能满足要求的。\n服务端发现模式\n客户端通过负载均衡器向某个服务提出请求，负载均衡器查询服务注册表，并将请求转发到可用的服务实例。如同客户端发现，服务实例在服务注册表中注册或注销。在原文中有图示，基本看图就清楚了，即在服务注册库前新增加了一个Load Balancer节点。注：这两个节点感觉是可以合并到API GateWay的能力中去的。\n服务端发现模式兼具优缺点。它最大的优点是客户端无需关注发现的细节，只需要简单地向负载均衡器发送请求，这减少了编程语言框架需要完成的发现逻辑。并且 如上文所述，某些部署环境免费提供这一功能。这种模式也有缺点。除非负载均衡器由部署环境提供，否则会成为一个需要配置和管理的高可用系统组件。 服务注册表\n服务注册表需要高可用而且随时更新。客户端能够缓存从服务注册表中获取的网络地址，然而，这些信息最终会过时，客户端也就无法发现服务实例。因此，服务注册表会包含若干服务端，使用复制协议保持一致性。\n首先可以看到服务注册表本身不能是单点，否则存在单点故障，当服务注册表有多台服务器的时候同时需要考虑服务注册库信息在多台机器上的实时同步和一致。我们操作和配置服务注册信息的时候往往只会在一个统一的服务管控端完成。\n其次如果服务注册服务器宕机是否一定影响到服务本身的消费和调用，如果考虑更高的整体架构可用性，还可以设计对于服务注册库信息在客户端本地进行缓存，当服务注册表无法访问的时候可以临时读取本地缓存的服务注册库信息并发起服务访问请求。\n对于服务注册表，文章提供了三种选择，感觉最常用的实现仍然是基于ZooKeeper进行的。\nEtcd – 高可用、分布式、一致性的键值存储，用于共享配置和服务发现。 Consul – 发现和配置的服务，提供 API 实现客户端注册和发现服务。 Apache ZooKeeper – 被分布式应用广泛使用的高性能协调服务。\n如前所述，服务实例必须在注册表中注册和注销。注册和注销有两种不同的方法。方法一是服务实例自己注册，也叫自注册模式（self-registration pattern）；另一种是采用管理服务实例注册的其它系统组件，即第三方注册模式。（原文有详细机制描述，不再累述）\n虽然方法一把服务实例和服务注册表耦合，必须在每个编程语言和框架内实现注册代码。但是在自己实现完整微服务架构中，考虑到PaaS平台下微服务模块的动 态部署和扩展，采用方法1相当来说更加容易实现。但是方法1仍然不能代替服务注册库本身应该具备的服务节点的心跳检测能力。\n","title":"SOA架构和微服务架构有什么区别？\n"},{"location":"项目/nasync","tags":["golang"],"text":"a customizable async task pool for golang, (event bus, runtime)\ngithub: https://github.com/ti/nasync\nFetures  less memory more effective max gorutines and memory customizable more safe  Simple Usage nasync.Do(function)  Advanced Usage go get github.com/ti/nasync  import \u0026quot;github.com/ti/nasync\u0026quot; func main() { //new a async pool in max 1000 task in max 1000 gorutines async := nasync.New(1000,1000) defer async.Close() async.Do(doSometing,\u0026quot;hello word\u0026quot;) nasync.Do(func() { http.Get(\u0026quot;https://github.com/ti/\u0026quot;) }) } func doSometing(msg string) string{ return \u0026quot;i am done by \u0026quot; + msg }  WHY golang is something easy but fallible language, you may do this\nfunc yourfucntion() { go dosomething() // this will got error on high load }  you may get \u0026ldquo;too many open files\u0026rdquo; error, when your application in High load, so you need this, you can do any thing in async by this, it is trusty。your can use this for:\n http or file writer logging improve main thread speed limited background task pool  What if something callback ? import \u0026quot;github.com/ti/nasync\u0026quot; func main() { nasync.Do(func() { result := doSometing(\u0026quot;msg\u0026quot;) fmt.Println(\u0026quot;i am call back by \u0026quot;,result) }) } func doSometing(msg string) string{ return \u0026quot;i am done by \u0026quot; + msg }  ","title":"NASYNC 可自定义容量的异步库\n"},{"location":"开发/弹性伸缩部署","text":"本文转载和补充目前弹性伸缩架构模型，旨在让初学同学们更佳清晰地认识弹性伸缩。\n从业务生命周期而言，正处上升期的应用，访问量可能每月甚至每周成指数倍数地增长，当你在为业务快速发展、脱颖而出而畅想自high：哥写得一手牛逼代码即将要支撑起阿里未来五年的腾飞了！！啪，程序运行FGC，啪，调用方超时，啪，触发限流~也许这已经是最近第N次的报警，也许这是最近第N次调用方打电话过来投诉，也许这是最近第N次的扩容……还能不能好好玩耍，专心把代码撸到极致？！业务下降期的应用或许已经不再投入开发，你是否曾想过线上其实早已不需要那么多的机器资源了，如果折算成RMB，这每天到底是有多少张毛爷爷从口袋白白飞走？不能再任性了，快让应用弹起来，让有限的计算资源服务到优质的业务上吧！\n一、弹性伸缩的原理 弹性伸缩（Auto Scaling）是根据不同的业务需求与策略，自动调整应用的弹性计算资源，最终达到优化资源组合的服务能力。通过 自动伸缩 和 计划伸缩 这两种工作模式，应用便能在无运维人员介入的情况下实现自动调整计算资源，当访问量上涨时增加计算能力，而当访问量下降时减小计算能力，既保障了系统的稳定性与高可用性，又节约了计算资源成本。\n弹性伸缩在业界有两个方向，一个是垂直化的扩展（Scale up），一个水平化的扩展（Scale out）。从业务发展的角度来看应该是水平扩展的能力，这要求业务都是无状态的，通过负载均衡技术将访问请求分配到集群每一台机器上，不管是增加还是减少机器，业务的连续性都不应受到影响。\n垂直扩展\n 在垂直扩展模型中，想要增加系统负荷就意味着要在系统现有的部件上下工夫，即通过提高系统部件的能力来实现。例如，假设你现在负责一批木材采伐的操作。 在这个例子中，我们假设有3辆卡车，每辆车一次可以运25根木材，计算花费1小时的情况下可以运送到指定地点等待处理的木材数量。通过这些数字我们可以算出我们系统最大的负荷量： 3辆卡车 * 25根木材 * 1小时=75根木材／小时 如果我们选择垂直扩展模型，那么我们将怎么做来使我们每小时可以处理150根木材？我们需要至少做以下两件事中的一件： 使每辆卡车的运输量增加一倍（50棵树每小时），或者使每辆卡车的运输时间减半（每辆卡车30分钟）。 3辆卡车 * 50棵树 * 1小时 = 150棵树／每小时 或者 3辆卡车 * 25棵树 * 30分钟 = 150棵树／每小时 我们没有增加系统的成员数，但是我们通过增加系统成员的生产效率来获得期望的负荷量。\n 水平拓展\n 在水平扩展模型中，我们不是通过增加单个系统成员的负荷而是简单的通过增加更多的系统成员来实现。也就是说，在以上运送木材的例子中，通过增加卡车的数量来运送木材。因此，当我们需要将负荷从75棵树每小时增加到150棵树每小时，那么只需要增加3辆卡车。 6辆卡车 * 25棵树 * 1小时 = 150棵树／每小时 假如我们已经选择了垂直扩展方式，那么我们想要每小时处理150棵被砍伐的树时需要怎么做呢？我们需要做到以下两方面之一：要么使每辆卡车的运输量翻倍(50棵木材一次)，要么使每辆开车的运输时间减半(30分钟)。 3辆卡车 * 50棵树 * 1小时 = 150棵树／每小时 或者 3辆卡车 * 50棵树 * 30分钟 = 150棵树／每小时 在这个例子中，系统每个成员的生产力依然没变，我们通过增加更多的卡车来提高系统的能力。\n 二、基于弹性伸缩的系统运维架构图 \n在此模型中，展示层为用户交互，接受和呈现信息，主要表现为： 弹性伸缩监控大盘：用于全局监控接入弹性平台应用的运行状态，以及配置应用的弹性伸缩规则； 应用成本分析展示：用于呈现应用使用的资源成本，包括计算资源、存储资源、网络与带宽资源、CDN资源等； 虚拟计费（待定）：通过虚拟货币形式来衡量应用运行的费用开销情况。\n逻辑层为运维自动化的核心，主要表现为： 弹性伸缩系统：应用弹性伸缩、虚拟化计算资源调度的智能规则引擎； 自动化部署：新应用上线、集群扩容和缩容的自动化工具； 计算资源分配：虚拟化计算资源的创建与回收的虚拟化基础设施。\n资源层为计算、存储、网络、CDN等基础设施资源。\n三、计算资源弹性伸缩模型 \n四、弹性伸缩策略 观察模式\n模拟弹性伸缩的过程，弹性伸缩系统将会通过旺旺和邮件通知应用负责人以及运维人员什么时候要扩容或缩容、涉及的机器数，但是不会真正触发扩容和缩容的这个动作，此外，还可以在人工确认的情况下，手动触发扩容和缩容。简而言之，观察模式可以理解为应用接入弹性伸缩系统的一重保障。\n自动伸缩\n根据日常负载情况，计算应用所需的计算资源，以此达到降低成本、提升稳定性的目的。\n\n 伸缩范围 最大实例数: 接入弹性前，集群的机器总数 （说明：当前应用有充足机器容量） 最小实例数: max(前七天qps峰值) / 单机QPS极限值 * 60% （说明：最小实例数，前期阶段不会直接探底，会留有一部分余量）\n 伸缩规则 扩容条件: （1）集群水位超过40% （2）每个CPU的等待队列长度大于0.5 或 cpu_avg超过50% 或 rt升高百分比超过300% 持续时间超过2分钟  缩容条件: （1）集群水位低于13% （2）每个CPU的等待队列长度小于0.2 与 cpu_avg小于15% 持续时间超过5分钟\n 期望水位: 35%\n  备注： 集群水位 = 集群QPS / （单机QPS极限值 * 机器数） 单机QPS极限能力: csp单机压测值\n计划伸缩\n计划伸缩也称作定时伸缩，应用场景主要是根据计划提前做好各个系统的容量准备，以便承受可预见的瞬间访问高峰。举个例子，运营同学A准备今天要一次广告投放引流，一大波流量正在逼近！！假如A将预计引流PV总量事前告知弹性伸缩系统，提前将应用容量准备好，多少的流量过来都妥妥的了，真是深藏功与名~\n全链路伸缩\n复用自动化备战平台功能，根据预计交易创建笔数以及机房流量分配进行系统容量准备\n\n机器下线规则\n首先计算出应用缩容的机器数量； 通过CMDB获取到下线机器列表，同时调用发布系统接口将beta机器加入到下线排除机器列表，如果有特殊需要排除的机器，需要在弹性伸缩系统上手动添加； 分批下线机器，以尽可能减小对业务访问造成抖动。\n补充： 弹性伸缩必备条件：\n 业务之间无状态。（统一token验证，统一用户中心） 数据库弹性，业务弹性，nginx，数据库，rpcX QoS（Quality of Service，服务质量）(·丢失数据包,延迟,传输顺序出错,出错)  弹性调度算法 1、bully算法\n2、环算法\n","title":"弹性伸缩部署\n"},{"location":"开发/Redis事务介绍","tags":["redis"],"text":"写在前面：一般情况下，我们不建议将数据可用性内容放在redis中进行操作，例如转账，关系建立等，redis被认为是一个较不可靠的数据库，一般用作数据缓存，pubsub机制，session保持等使用场景，本文介绍redis事务，并不代表它可以处理常见的事务需求。常见nosql中事务处理机制类似，可做参考。\n相信学过MySQL等其他数据库的同学对事务这个词都不陌生，事务表示的是一组动作，这组动作要么全部执行，要么全部不执行。为什么会有这样的需求呢？看看下面的场景：\n  微博是一个弱关系型社交网络，用户之间有关注和被关注两种关系，比如两个用户A和B，如果A关注B，则B的粉丝中就应该有A。关注这个动作需要两个步骤完成：在A的关注者中添加B；在B的粉丝中添加A。 这两个动作要么都执行成功，要么都不执行。否则就可能会出现A关注了B，但是B的粉丝中没有A的不可容忍的情况。 转账汇款，假设现在有两个账户A和B，现在需要将A中的一万块大洋转到B的账户中，这个动作也需要两个步骤完成：从A的账户中划走一万块；在B的账户中增加一万块。这两个动作要么全部执行成功，要么全部不执行，否则自会有人问候你的！！！   Redis作为一种高效的分布式数据库，同样支持事务。\nRedis事务 Redis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。Redis事务的实现需要用到** MULTI 和 EXEC 两个命令，事务开始的时候先向Redis服务器发送 MULTI 命令，然后依次发送需要在本次事务中处理的命令，最后再发送 EXEC **命令表示事务命令结束。\n举个例子，使用redis-cli连接redis，然后在命令行工具中输入如下命令：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set url http://qifuguang.me QUEUED 127.0.0.1:6379\u0026gt; set title winwill2012 QUEUED 127.0.0.1:6379\u0026gt; set desc java QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) OK 3) OK 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; get url \u0026quot;http://qifuguang.me\u0026quot; 127.0.0.1:6379\u0026gt; get title \u0026quot;winwill2012\u0026quot; 127.0.0.1:6379\u0026gt; get desc \u0026quot;java\u0026quot; 127.0.0.1:6379\u0026gt;  从输出中可以看到，当输入MULTI命令后，服务器返回OK表示事务开始成功，然后依次输入需要在本次事务中执行的所有命令，每次输入一个命令服务器并不会马上执行，而是返回”QUEUED”，这表示命令已经被服务器接受并且暂时保存起来，最后输入EXEC命令后，本次事务中的所有命令才会被依次执行，可以看到最后服务器一次性返回了三个OK，这里返回的结果与发送的命令是按顺序一一对应的，这说明这次事务中的命令全都执行成功了。\n再举个例子，在命令行工具中输入如下命令：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set a a QUEUED 127.0.0.1:6379\u0026gt; sett b b (error) ERR unknown command 'sett' 127.0.0.1:6379\u0026gt; set c c QUEUED 127.0.0.1:6379\u0026gt; EXEC (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379\u0026gt; get a (nil) 127.0.0.1:6379\u0026gt; get b (nil) 127.0.0.1:6379\u0026gt; get c (nil) 127.0.0.1:6379\u0026gt;  和前面的例子一样，先输入MULTI最后输入EXEC表示中间的命令属于一个事务，不同的是中间输入的命令有一个错误(set写成了sett)，这样因为有一个错误的命令导致事务中的其他命令都不执行了(通过后续的get命令可以验证)，可见事务中的所有命令式同呼吸共命运的。\n如果客户端在发送EXEC命令之前断线了，则服务器会清空事务队列，事务中的所有命令都不会被执行。而一旦客户端发送了EXEC命令之后，事务中的所有命令都会被执行，即使此后客户端断线也没关系，因为服务器已经保存了事务中的所有命令。\n除了保证事务中的所有命令要么全执行要么全不执行外，Redis的事务还能保证一个事务中的命令依次执行而不会被其他命令插入。试想一个客户端A需要执行几条命令，同时客户端B发送了几条命令，如果不使用事务，则客户端B的命令有可能会插入到客户端A的几条命令中，如果想避免这种情况发生，也可以使用事务。\nRedis事务错误处理 如果一个事务中的某个命令执行出错，Redis会怎样处理呢？要回答这个问题，首先要搞清楚是什么原因导致命令执行出错：\n语法错误 就像上面的例子一样，语法错误表示命令不存在或者参数错误 这种情况需要区分Redis的版本，Redis 2.6.5之前的版本会忽略错误的命令，执行其他正确的命令，2.6.5之后的版本会忽略这个事务中的所有命令，都不执行，就比如上面的例子(使用的Redis版本是2.8的)\n运行错误 运行错误表示命令在执行过程中出现错误，比如用GET命令获取一个散列表类型的键值。 这种错误在命令执行之前Redis是无法发现的，所以在事务里这样的命令会被Redis接受并执行。如果食物里有一条命令执行错误，其他命令依旧会执行（包括出错之后的命令）。比如下例：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set key 1 QUEUED 127.0.0.1:6379\u0026gt; SADD key 2 QUEUED 127.0.0.1:6379\u0026gt; set key 3 QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) (error) WRONGTYPE Operation against a key holding the wrong kind of value 3) OK 127.0.0.1:6379\u0026gt; get key \u0026quot;3\u0026quot;  Redis中的事务并没有关系型数据库中的事务回滚(rollback)功能，因此使用者必须自己收拾剩下的烂摊子。不过由于Redis不支持事务回滚功能，这也使得Redis的事务简洁快速。\n回顾上面两种类型的错误，语法错误完全可以在开发的时候发现并作出处理，另外如果能很好地规划Redis数据的键的使用，也是不会出现命令和键不匹配的问题的。\nWATCH命令 从上面的例子我们可以看到，事务中的命令要全部执行完之后才能获取每个命令的结果，但是如果一个事务中的命令B依赖于他上一个命令A的结果的话该怎么办呢？就比如说实现类似java中的i++的功能，先要获取当前值，才能在当前值的基础上做加一操作。这种场合仅仅使用上面介绍的MULTI和EXEC是不能实现的，因为MULTI和EXEC中的命令是一起执行的，并不能将其中一条命令的执行结果作为另一条命令的执行参数，所以这个时候就需要引进Redis事务家族中的另一成员：WATCH命令\n换个角度思考上面说到的实现i++的方法，可以这样实现：\n  监控i的值，保证i的值不被修改 获取i的原值 如果过程中i的值没有被修改，则将当前的i值+1，否则不执行   这样就能够避免竞态条件，保证i++能够正确执行。\nWATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，EXEC命令执行完之后被监控的键会自动被UNWATCH）\n举个例子：\n127.0.0.1:6379\u0026gt; set mykey 1 OK 127.0.0.1:6379\u0026gt; WATCH mykey OK 127.0.0.1:6379\u0026gt; set mykey 2 OK 127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set mykey 3 QUEUED 127.0.0.1:6379\u0026gt; EXEC (nil) 127.0.0.1:6379\u0026gt; get mykey \u0026quot;2\u0026quot; 127.0.0.1:6379\u0026gt;  上面的例子中，首先设置mykey的键值为1，然后使用WATCH命令监控mykey，随后更改mykey的值为2，然后进入事务，事务中设置mykey的值为3，然后执行EXEC运行事务中的命令，最后使用get命令查看mykey的值，发现mykey的值还是2，也就是说事务中的命令根本没有执行（因为WATCH监控mykey的过程中，mykey被修改了，所以随后的事务便会被取消）。\n有了WATCH命令，我们就可以自己实现i++功能了，伪代码如下：\ndef incr($key): WATCH $key $value = GET $key if not $value $value = 0 $value = $value + 1 MULTI SET $key $value result = EXEC return result[0]  因为EXEC返回的是多行字符串，使用result[0]表示返回值的第一个字符串。\n注意：由于WATCH命令的作用只是当被监控的键被修改后取消之后的事务，并不能保证其他客户端不修改监控的值，所以当EXEC命令执行失败之后需要手动重新执行整个事务。\n执行EXEC命令之后会取消监控使用WATCH命令监控的键，如果不想执行事务中的命令，也可以使用UNWATCH命令来取消监控。\n声明 原创文章，转载请注明出处，本文链接：http://qifuguang.me/2015/09/30/Redis事务介绍/\n","title":"Redis事务介绍\n"},{"location":"开发/12factor_十二因子應用程式","tags":["程序","12因子"],"text":"The 12 Factor App “十二因子应用程式”源自于Heroku开发团队在收集及观察大量的SaaS(Software as a Service)应用程式开发与执行过程之后，所整理出来的十二条开发SaaS应用程式时的方针。\n遵守这些方针可以增进应用程式本身的稳定性及扩充性(Scalibility)，从程式开发的到系统上线过程也会快捷很多。\n原文：The 12 Factor App\ni. 程式码(Codebase) 一对一的程式码版本管理 “十二因子”的程式码必须储存在原始码版本管理系统，例如Git, Subversion. 程式码(codebase)与应用程式(application) 应该以“ㄧ对一”的关系储存着：\n 如果你的系统需要有多个原始码管理系统，那你的系统就是个分散式系统(Distributed System)， 分散式系统由多个应用程式(application)组成，而这些应用程式都应各别套用“十二因子”。 “十二因子”反对一套程式的原始码有多个应用程式在使用。如果需要分享部分的程式码，正确的解决方式应该为把共享的程式码包装成程式库(library, 例如JAVA的.jar档案)， 然后有需要的其他应用程式以“相依性”(dependency)的程式库来使用。  每个\u0026rdquo;十二因子应用程式“都有属于它专属的程式码，透过专有的原始码版本管理，可以清楚的安装(deploy)在不同的环境。也许每个环境有不同的版本，但每个系统的所拥有的程式码还是非常清楚干净的。有问题出现时，也可以简单的回朔到之前的版本去。\nii. 相依性(dependencies) 明确定义所有相依的程式库(library) 程式语言通常都会有专属的包装(packaging)与相依性程式库管理系统，例如Java的Maven，或是Ruby的Rubygems。“十二因子”要求应用程式必须使用类似的管理系统，而且所有的第三方程式库必须都明确定义出来，即使有些来自系统的程式库也应列出来管理。这样一来当新的工程师加入开发时，随时都可以透过管理系统简单的安装该程式在自己的环境，无论是任何平台都不会有冲突。\n一般来说容易被疏忽的部分是系统本身的程式库或是工具，“十二因子应用程式”必须将这些有相依性的程式以第三方程式库的方式安装，以避免应用程式被安装在不支援的系统上。例如Linux的curl command如果直接在程式码里面使用，那这个应用程式有无法轻易的安装在windows的环境。\niii. 配置变数(Config) 将配置变数(Config)储存在环境变数(Environment Variables) 配置变数(Config)所指的是每个应用软体在不同的安装环境(例如production vs QA)会设定的变数。\n一般常见的例子：\n 资料库的连结设定，例如URL，帐号，密码。 第三方服务的连结设定，例如Facebook API的URL，帐号，密码等。  “十二因子应用程式”反对将这些配置变数储存在原始码里面。建议的所有的配置变数应该储存在环境变数(Environment Variables)中。将配置变数储存在原始码中会有安全性的问题，一但程式码开放给其他团体或个人时，这些机密的帐号密码也容易不小心外泄。另外配置变数是随着环境在改变的，而应用程式的程式码跟版本的关系是固定的，同版本的应用程式在任何安装的环境都是一样的， 所以配置变数需要另外管理。一般来说要个别定义在伺服器的环境变数中，如此也可以改善应用程式的扩充性(Scalability)。\n有些应用程式有属于该程式结构使用的变数，例如Java Spring的config。这类的变数必须和程式码共生，而不在以上提到的“十二因子”的规范内。\niv. 后端支援服务(Backing Services) 所有后端支援系统都应视为外接的资源 所谓的后端支援服务(backing service)是指于应用程式透过网路传输得到的服务，例如资料库，SMTP，快速储存记忆体(cache)，API(Facebook,Google)之类的服务。\n负责管理这些支援服务的种类主要有本地的(local)跟第三方(3rd party)，例如资料库通常是同公司的系统工程师在管理。但如果主机架在云端，大多数服务就都是透过第三方提供的了。“十二因子”的程式码对待所有这些服务的种类必须是一致的，所有的后端支援系统，无论是本地管理或是第三方管理， 都一律视为外接的资源，用一样的程式码来执行。唯一不同的地方只有连线的方式，url，帐号，密码透过Config来管理。\n由于程式码一致，“十二因子应用程式“可以简单的切换提供服务的来源。例如：如果要把MySQL提供者从自己local的换到Amazon提供的，只要改连结的资料可以了。或是要把Gmail 的SMTP 换成Yahoo! 的，也只要改连结的资料。关键就在于”十二因子“的程式码一律视这些后端支援服务为外接的资源，无论是本地管理还是第三方管理的。\nv. 构建，发行，执行(Build,Release,Run) 确实分离建构与执行的阶段 应用程式的从程式码到发行(Release)与执行可以分为以下三阶段：\n第一阶段：“构建”(Build)，所指的是透过构建系统将程式码及有相依性的程式库包装起来在一起。例如将package JAVA程式为.jar或是.war档。\n第二阶段：“发行”(Release)，将包装好的程式库，加上环境特有的配置变数(Config)，透过发行管理系统将档案上传至要执行的环境里面。一般来说发行管理系统另的一个主要工作是将每个发行版本(Release Version)规范定义好。每一个不同版本的程式码都应有对应的发行版本， 版本定义可以用日期(2012-1-1-11:59:01)或是渐进的数字(v1.1.3)来定义。\n第三阶段：“执行”(Run)，所指的是发行的版本(包含code+config)，在该环境中执行。\n“十二因子应用程式”强调这三个阶段必须清楚地分开与定义好。例如在执行阶段不容许有任何的程式码改变。如果这三个阶段可以分别设定好， 应用程式就可以进入自动化的发行与执行，工程师开发新的功能，构建系统自动包装，发行系统自动定义版本，然后新版本的应用程式跟config一起发行到执行的环境中。出问题时也可以在发行系统中选择之前的版本回朔回去。\nvi. 处理序(Processes) 应用程式必须以“无状态”的方式在处理序上执行 一般应用程式会在一个或多个处理序(Process)上执行，例如在工程师的local开发环境通常会用一个处理序，而正式上线时系统通常会有多个处理序来执行。\n”无状态“(Stateless)指的是应用程式不会有预设任何的状态，每个request在执行完后，执行过程中所用到的状态(State)都不会被储存下来。\n执行”十二因子应用程式“的处理序绝对是”无状态“且不直接分享资料的，每个处理序之间不会有任何的沟通，也不会预设互通的状态。有需要互通的资料一律由后端支援服务(Backing Service)储存，例如资料库或是快速储存记忆体(cache)。因为应用程式会由多个处理序执行，而无法预期下个request来时会由哪一个处理序执行。唯有透过共通的Backing Service，才可以确保资料的完整性。\n另外应用程式可以在上线(Live)的状态下随时增加处理序甚至是新的硬体，如果依靠暂存的记忆体，则无法保证执行所需的资料的完整性。例如说一般常见的http session，就不应该直接储存在记忆体里面，而应该利用可设定自动失效的Memcached或是Redis来储存。\nvii. 连接埠(Port Binding) 透过连接埠提供对外服务 ”十二因子应用程式“的服务一律都已完整定义在程式码中，要对外提供服务时，只要网路伺服器透过连接埠就可以执行。例如一般的Java的网页通常是透过Tomcat或是Jetty之类的伺服器，将连接埠绑在8080上，对外就可以透过对外路径设定(Route)到该应用程式上。如果在本地一般就是直接连上http://localhost:8080/。由于是透过伺服器的连接埠来定义上线的程式，一个伺服器也可以同时拥有多个应用程式。一个常见的例子就是一个伺服器同时有客户(Customer)使用的应用程式跟管理者(Admin)使用的应用程式，只是绑在不同的连接埠上罢了。\n连接埠的应用不只限于网页程式，也可以是各种的网路服务，例如FTP，或是各种客制的服务。”十二因子应用程式“也可以成为其他应用程式的”后端支援服务“(Backing Service)，例如很多应用程式本生的服务只有有提供Restful API，而没有任何使用者界面。\nviii. 同步执行(Concurrency) 透过同步执行来加速应用程式 一般程式的执行环境都支援使用多数处理序(Process)来执行应用程式，例如JAVA的JVM就是透过Thread让软体同步执行多项作业(Task)。\n“十二因子应用程式”利用这些同步执行的工能来增进应用程式的效率跟扩充性(Scalability)。例如Http Request由一个处理序执行， 需要定期执行的作业由另一个处理序执行。\n这样的设计配合“十二因子”中的无状态(Stateless)跟不直接分享执行资源的原则，应用程式则可以简单地透过增加硬体资源或云端上的执行单位来最佳化(Optimize)执行的效能。\nix. 快捷启用与终止(Disposability) 达到快速启用与安全终止服务 “十二因子应用程式”在开发的任何阶段，都要确实的保持程式启动的速度，同时要确保程式终止时不会有无法复原或失去重要资料的状况。如果可以保持这两个原则，应用程式本身就可以简单的达到扩充性(Scalibility)，或者是硬体迁移(Migration)的过程也会简化很多。\n应用程式的启用时间应该要可以在几秒内完成，这样除了当流量变大时，可以快速的增加执行的单位，另外在构建跟发行的过程也会快速很多， 更新的版本可以快速的上线。\n应用程式在终止时要确认资料跟作业的完整度，透过后端支援服务(Backing Service)来分享状态，这样当一个处理序终止后，其他执行中的处理序也可以接着完成作业。例如有些程式有很多在后端执行的作业，可以透过Queuing Service(例如RabbitMQ)来分配要执行的工作， 而无论哪一个处理序都可以分别的执行，这样应用程式才可以个别安全的终止服务。\nx. 环境的一致性(Dev/Prod Parity) 保持不同环境(Dev，QA，Staging，Production)的一致性 传统应用软体的开发环境(Dev)通常会跟Production环境不同，通常原因可能是资源跟人员的分配的差异性。这差异性会造成三个软体开发的落差：\n 时间：从工程师的软体开发环境到可以发行到production需要很长的时间，有时候要几周甚至几个月才可以发行新的版本。 人力资源：软体工程师负责开发软体，需要透过系统工程师来发行软体到production环境。 工具：软体工程师在开发时使用较轻便的工具，而production环境则使用功能较完整的工具。例如工程师用SQLite开发，而production用MySQL  “十二因子应用程式” 强调“无间断的发行环境”(Continous Deployment)，发行的环境设定一律自动化，测试过的新功能会包装成米你的版本自动发行到production， 有时一天发行一个版本，有时甚至可以一天发行多个版本。\n另外“十二因子应用程式” 强调任何环境都应该使用相同的工具或后端支援服务(Backing Service)，例如资料库或是Cache。如果工具不同，会发生新版本在开发环境测试都通过了，但发行到production就出现问题的状况。如果真正要确保“无间断发行”的稳定性，就要尽量达到在各环境都使用与production一样的工具或后端服务。\n谨守“十二因子”的原则，则应用程式开发的环境就会稳定很多，且之前提到的落差就会减低：\n 时间：从开发到发行时间减为一天内。 人力资源：发行环境设定好后，软体工程师就可以自行发行新版本，不需要透过系统工程师。 工具：任何环境的工具都与production的一样。  xi. 记录(Logs) 透过外接服务将记录整合起来 应用程式的执行过程通常都是透过记录(Logs)储存起来，一般的储存方式为将记录写在伺服器的档案内，一旦记录档(Log file)开启后， 应用程式的执行内容就会一行一行的写在档案内，在程式终止前都会不断的记录着程式开发者认为重要的讯息，例如错误资讯或是未来可以用来分析的资料。由于SAAS的应用程式通常会在多个主机上执行，造成记录档案很可能处于不连续的状态，所以需要有额外的服务来将记录整合起来。\n“十二因子应用程式”本身不管理任何关于整合记录的服务，将这类整合的任务交给执行环境去处理。“十二因子”只负责将记录写入该执行环境的记录档内。\n目前已有很多整合记录档的工具(例如Logplex或是Fluent)，这些工具可以将每个主机上的记录档传输到在单一伺服器上，将每笔记录的内容依据发生时间整合起来， 提供未来除错或是分析使用。\nxii. 系统管理者(Admin Processes) 在相同环境下执行管理者作业(Task) 应用程式在上线一段时间过后，难免需要执行一些管理者(Admin)的作业，例如资料库迁移，或是需要登录控制台(Admin Console)之类的界面管理系统资料之类的。有时候工程师为了方便，在local环境执行更新其他环境的工作，这样的结果会造成应用程式本身的不稳定，且严重影响程式码版本的一致性。\n“十二因子应用程式”的管理者作业必须跟程式本身在同一个环境执行，例如在QA的环境执行QA的管理作业，production的管理作业就在production环境执行。关于管理者作业的程式码必须跟应用程式本身的程式码以同一个版本发行(Release)到该环境，配合该环境的配置变数(Config)来执行。\n","title":"十二因子应用程式\n"},{"location":"开发/Redis高并发问题","tags":["redis"],"text":"Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：\n1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。\n2.服务器角度，利用setnx实现锁。\n对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。\nSETNX命令（SET if Not eXists） 语法： SETNX key value\n功能： 将 key 的值设为 value ，当且仅当 key 不存在；若给定的 key 已经存在，则 SETNX 不做任何动作。\n时间复杂度： O(1) 返回值： 设置成功，返回 1 。 设置失败，返回 0 。\n模式：将 SETNX 用于加锁(locking)\nSETNX 可以用作加锁原语(locking primitive)。比如说，要对关键字(key) foo 加锁，客户端可以尝试以下方式：\nSETNX lock.foo 如果 SETNX 返回 1 ，说明客户端已经获得了锁， key 设置的unix时间则指定了锁失效的时间。之后客户端可以通过 DEL lock.foo 来释放锁。\n如果 SETNX 返回 0 ，说明 key 已经被其他客户端上锁了。如果锁是非阻塞(non blocking lock)的，我们可以选择返回调用，或者进入一个重试循环，直到成功获得锁或重试超时(timeout)。\n但是已经证实仅仅使用SETNX加锁带有竞争条件，在特定的情况下会造成错误。\n处理死锁(deadlock)\n上面的锁算法有一个问题：如果因为客户端失败、崩溃或其他原因导致没有办法释放锁的话，怎么办？\n这种状况可以通过检测发现——因为上锁的 key 保存的是 unix 时间戳，假如 key 值的时间戳小于当前的时间戳，表示锁已经不再有效。\n但是，当有多个客户端同时检测一个锁是否过期并尝试释放它的时候，我们不能简单粗暴地删除死锁的 key ，再用 SETNX 上锁，因为这时竞争条件(race condition)已经形成了：\nC1 和 C2 读取 lock.foo 并检查时间戳， SETNX 都返回 0 ，因为它已经被 C3 锁上了，但 C3 在上锁之后就崩溃(crashed)了。 C1 向 lock.foo 发送 DEL 命令。 C1 向 lock.foo 发送 SETNX 并成功。 C2 向 lock.foo 发送 DEL 命令。 C2 向 lock.foo 发送 SETNX 并成功。 出错：因为竞争条件的关系，C1 和 C2 两个都获得了锁。\n幸好，以下算法可以避免以上问题。来看看我们聪明的 C4 客户端怎么办：\nC4 向 lock.foo 发送 SETNX 命令。 因为崩溃掉的 C3 还锁着 lock.foo ，所以 Redis 向 C4 返回 0 。 C4 向 lock.foo 发送 GET 命令，查看 lock.foo 的锁是否过期。如果不，则休眠(sleep)一段时间，并在之后重试。 另一方面，如果 lock.foo 内的 unix 时间戳比当前时间戳老，C4 执行以下命令： GETSET lock.foo 因为 GETSET 的作用，C4 可以检查看 GETSET 的返回值，确定 lock.foo 之前储存的旧值仍是那个过期时间戳，如果是的话，那么 C4 获得锁。 如果其他客户端，比如 C5，比 C4 更快地执行了 GETSET 操作并获得锁，那么 C4 的 GETSET 操作返回的就是一个未过期的时间戳(C5 设置的时间戳)。C4 只好从第一步开始重试。 注意，即便 C4 的 GETSET 操作对 key 进行了修改，这对未来也没什么影响。\n这里假设锁key对应的value没有实际业务意义，否则会有问题，而且其实其value也确实不应该用在业务中。\n为了让这个加锁算法更健壮，获得锁的客户端应该常常检查过期时间以免锁因诸如 DEL 等命令的执行而被意外解开，因为客户端失败的情况非常复杂，不仅仅是崩溃这么简单，还可能是客户端因为某些操作被阻塞了相当长时间，紧接着 DEL 命令被尝试执行(但这时锁却在另外的客户端手上)。\nGETSET命令 语法： GETSET key value\n功能： 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。当 key 存在但不是字符串类型时，返回一个错误。\n时间复杂度： O(1)\n返回值： 返回给定 key 的旧值；当 key 没有旧值时，也即是， key 不存在时，返回 nil 。\n","title":"Redis并发问题\n"},{"location":"开发/MySQL索引背后的数据结构及算法原理","tags":["mysql","算法"],"text":"MySQL索引背后的数据结构及算法原理 本文以MySQL数据库为研究对象，讨论与数据库索引相关的一些话题。特别需要说明的是，MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。为了避免混乱，本文将只关注于BTree索引，因为这是平常使用MySQL时主要打交道的索引，至于哈希索引和全文索引本文暂不讨论。\n文章主要内容分为三个部分。\n第一部分主要从数据结构及算法理论层面讨论MySQL数据库索引的数理基础。\n第二部分结合MySQL数据库中MyISAM和InnoDB数据存储引擎中索引的架构实现讨论聚集索引、非聚集索引及覆盖索引等话题。\n第三部分根据上面的理论基础，讨论MySQL中高性能使用索引的策略。\n数据结构及算法基础 索引的本质 MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。\n我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。\n看一个例子：\n\n图1\n图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)O(log2n)的复杂度内获取到相应数据。\n虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。\nB-Tree和B+Tree 目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。\nB-Tree 为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：\nd为大于1的一个正整数，称为B-Tree的度。\nh为一个正整数，称为B-Tree的高度。\n每个非叶子节点由n-1个key和n个指针组成，其中d\u0026lt;=n\u0026lt;=2d。\n每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。\n所有叶节点具有相同的深度，等于树高h。\nkey和指针互相间隔，节点两端是指针。\n一个节点中的key从左到右非递减排列。\n所有节点组成树结构。\n每个指针要么为null，要么指向另外一个节点。\n如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)v(key1)，其中v(key1)v(key1)为node的第一个key的值。\n如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)v(keym)，其中v(keym)v(keym)为node的最后一个key的值。\n如果某个指针在节点node的左右相邻key分别是keyikeyi和keyi+1keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)v(keyi+1)且大于v(keyi)v(keyi)。\n图2是一个d=2的B-Tree示意图。\n\n图2\n由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：\nBTree_Search(node, key) { if(node == null) return null; foreach(node.key) { if(node.key[i] == key) return node.data[i]; if(node.key[i] \u0026gt; key) return BTree_Search(point[i]-\u0026gt;node); } return BTree_Search(point[i+1]-\u0026gt;node); } data = BTree_Search(root, my_key);  关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为\nlogd((N+1)/2)logd((N+1)/2)\n，检索一个key，其查找节点个数的渐进复杂度为\nO(logdN)O(logdN)\n。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。\n另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。\nB+Tree B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。\n与B-Tree相比，B+Tree有以下不同点：\n每个节点的指针上限为2d而不是2d+1。\n内节点不存储data，只存储key；叶子节点不存储指针。\n图3是一个简单的B+Tree示意。\n\n图3\n由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。\n一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。\n带有顺序访问指针的B+Tree 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。\n\n图4\n如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。\n这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。\n为什么使用B-Tree（B+Tree） 上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。\n一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。\n主存存取原理 目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。\n\n图5\n从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。\n主存的存取过程如下：\n当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。\n写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。\n这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。\n磁盘存取原理 上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。\n图6是磁盘的整体结构示意图。\n\n图6\n一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。\n图7是磁盘结构的示意图。\n\n图7\n盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。\n当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。\n局部性原理与磁盘预读 由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：\n当一个数据被用到时，其附近的数据也通常会马上被使用。\n程序运行期间所需要的数据通常比较集中。\n由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。\n预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\nB-/+Tree索引的性能分析 到这里终于可以分析B-/+Tree索引的性能了。\n上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。\nB-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n综上所述，用B-Tree作为索引结构效率是非常高的。\n而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。\n上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：\ndmax=floor(pagesize/(keysize+datasize+pointsize))dmax=floor(pagesize/(keysize+datasize+pointsize))\nfloor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。\n这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。\nMySQL索引实现 在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。\nMyISAM索引实现 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：\n\n图8\n这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：\n\n图9\n同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。\nMyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。\nInnoDB索引实现 虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。\n第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。\n\n图10\n图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。\n第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：\n\n图11\n这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。\n下一章将具体讨论这些与索引有关的优化策略。\n索引使用策略及优化 MySQL的优化主要分为结构优化（Scheme optimization）和查询优化（Query optimization）。本章讨论的高性能索引策略主要属于结构优化范畴。本章的内容完全基于上文的理论基础，实际上一旦理解了索引背后的机制，那么选择高性能的策略就变成了纯粹的推理，并且可以理解这些策略背后的逻辑。\n示例数据库 为了讨论索引策略，需要一个数据量不算小的数据库作为示例。本文选用MySQL官方文档中提供的示例数据库之一：employees。这个数据库关系复杂度适中，且数据量较大。下图是这个数据库的E-R关系图（引用自MySQL官方手册）：\n\n图12\nMySQL官方文档中关于此数据库的页面为http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法，如果有兴趣导入此数据库到自己的MySQL可以参考文中内容。\n最左前缀原理与相关优化 高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。\n这里先说一下联合索引的概念。在上文中，我们都是假设索引只引用了单个的列，实际上，MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组，其中各个元素均为数据表的一列，实际上要严格定义索引需要用到关系代数，但是这里我不想讨论太多关系代数的话题，因为那样会显得很枯燥，所以这里就不再做严格定义。另外，单列索引可以看成联合索引元素数为1的特例。\n以employees.titles表为例，下面先查看其上都有哪些索引：\nSHOW INDEX FROM employees.titles; +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type | +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ | titles | 0 | PRIMARY | 1 | emp_no | A | NULL | | BTREE | | titles | 0 | PRIMARY | 2 | title | A | NULL | | BTREE | | titles | 0 | PRIMARY | 3 | from_date | A | 443308 | | BTREE | | titles | 1 | emp_no | 1 | emp_no | A | 443308 | | BTREE | +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+  从结果中可以到titles表的主索引为，还有一个辅助索引。为了避免多个索引使事情变复杂（MySQL的SQL优化器在多索引时行为比较复杂），这里我们将辅助索引drop掉：\nALTER TABLE employees.titles DROP INDEX emp_no;  这样就可以专心分析索引PRIMARY的行为了。\n情况一：全列匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26'; +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ | 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | | +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+  很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：\nEXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26' AND emp_no='10001' AND title='Senior Engineer';+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+  效果是一样的。\n情况二：最左前缀匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001';+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+  当查询条件精确匹配索引的左边连续一个或几个列时，如或，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。\n情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'; +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+ | 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where | +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+  此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。\n首先我们看下title一共有几种不同的值：\nSELECT DISTINCT(title) FROM employees.titles; +--------------------+ | title | +--------------------+ | Senior Engineer | | Staff | | Engineer | | Senior Staff | | Assistant Engineer | | Technique Leader | | Manager | +--------------------+  只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager') AND from_date='1986-06-26'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 7 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较：\nSHOW PROFILES; +----------+------------+-------------------------------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-------------------------------------------------------------------------------+ | 10 | 0.00058000 | SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'| | 11 | 0.00052500 | SELECT * FROM employees.titles WHERE emp_no='10001' AND title IN ... | +----------+------------+-------------------------------------------------------------------------------+  “填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。\n情况四：查询条件没有指定索引第一列。 EXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26'; +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+ | 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where | +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+  由于不是最左前缀，索引这样的查询显然用不到索引。\n情况五：匹配某列的前缀字符串。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 56 | NULL | 1 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  此时可以用到索引，但是如果通配符不是只出现在末尾，则无法使用索引。（原文表述有误，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀）\n情况六：范围查询。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no \u0026lt; '10010' and title='Senior Engineer'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no \u0026lt; '10010'AND title='Senior Engineer'AND from_date BETWEEN '1986-01-01' AND '1986-12-31';+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  可以看到索引对第二个范围索引无能为力。这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询：\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no BETWEEN '10001' AND '10010'AND title='Senior Engineer'AND from_date BETWEEN '1986-01-01' AND '1986-12-31';+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。\n情况七：查询条件中含有函数或表达式。 很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior';+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+  虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1='10000';+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+  显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。\n索引选择性与前缀索引 既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。\n第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。\n另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：\nIndex Selectivity = Cardinality / #T\n显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，上文用到的employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：\nSELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;+-------------+| Selectivity |+-------------+| 0.0000 |+-------------+  title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。\n有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。\n从图12可以看到employees表只有一个索引，那么如果我们想按名字搜索一个人，就只能全表扫描了：\nEXPLAIN SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido';+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+| 1 | SIMPLE | employees | ALL | NULL | NULL | NULL | NULL | 300024 | Using where |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+  如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建或，看下两个索引的选择性：\nSELECT count(DISTINCT(first_name))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.0042 |+-------------+SELECT count(DISTINCT(concat(first_name, last_name)))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.9313 |+-------------+  显然选择性太低，选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如，看看其选择性：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.7879 |+-------------+  选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.9007 |+-------------+  这时选择性已经很理想了，而这个索引的长度只有18，比短了接近一半，我们把这个前缀索引 建上：\nALTER TABLE employees.employeesADD INDEX `first_name_last_name4` (first_name, last_name(4));  此时再执行一遍按名字查询，比较分析一下与建索引前的结果：\nSHOW PROFILES;+----------+------------+---------------------------------------------------------------------------------+| Query_ID | Duration | Query |+----------+------------+---------------------------------------------------------------------------------+| 87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' || 90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' |+----------+------------+---------------------------------------------------------------------------------+  性能的提升是显著的，查询速度提高了120多倍。\n前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。\nInnoDB的主键选择与插入优化 在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。\n经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。\n上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。\n如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：\n\n图13\n这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。\n如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：\n\n图14\n此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。\n因此，只要可以，请尽量在InnoDB上采用自增字段做主键。\n后记 这篇文章断断续续写了半个月，主要内容就是上面这些了。不可否认，这篇文章在一定程度上有纸上谈兵之嫌，因为我本人对MySQL的使用属于菜鸟级别，更没有太多数据库调优的经验，在这里大谈数据库索引调优有点大言不惭。就当是我个人的一篇学习笔记了。\n其实数据库索引调优是一项技术活，不能仅仅靠理论，因为实际情况千变万化，而且MySQL本身存在很复杂的机制，如查询优化策略和各种引擎的实现差异等都会使情况变得更加复杂。但同时这些理论是索引调优的基础，只有在明白理论的基础上，才能对调优策略进行合理推断并了解其背后的机制，然后结合实践中不断的实验和摸索，从而真正达到高效使用MySQL索引的目的。\n另外，MySQL索引及其优化涵盖范围非常广，本文只是涉及到其中一部分。如与排序（ORDER BY）相关的索引优化及覆盖索引（Covering index）的话题本文并未涉及，同时除B-Tree索引外MySQL还根据不同引擎支持的哈希索引、全文索引等等本文也并未涉及。如果有机会，希望再对本文未涉及的部分进行补充吧。\n","title":"MySQL索引背后的数据结构及算法原理"}]